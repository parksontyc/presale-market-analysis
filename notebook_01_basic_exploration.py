# é å”®å±‹å¸‚å ´åˆ†æžç³»çµ± - 01_åŸºç¤Žè³‡æ–™æŽ¢ç´¢
# åŸºæ–¼ PRD v2.3 è¦æ ¼é€²è¡Œè³‡æ–™æŽ¢ç´¢èˆ‡é©—è­‰
# ================================================================================

# %% [markdown]
# # é å”®å±‹å¸‚å ´åˆ†æžç³»çµ± - åŸºç¤Žè³‡æ–™æŽ¢ç´¢
# 
# ## ðŸ“‹ ç›®æ¨™
# - âœ… è¼‰å…¥ä¸¦æª¢è¦–åŽŸå§‹è³‡æ–™çµæ§‹
# - âœ… é©—è­‰PRDæ–‡ä»¶ä¸­çš„è³‡æ–™æè¿°  
# - âœ… è­˜åˆ¥è³‡æ–™å“è³ªå•é¡Œ
# - âœ… å»ºç«‹åŸºç¤Žåˆ†æžæ¡†æž¶
# 
# ## ðŸ“Š è³‡æ–™æª”æ¡ˆ
# - `lvr_community_data_test.csv`: é å”®ç¤¾å€è³‡æ–™ (8,452ç­†, 19æ¬„)
# - `lvr_presale_test.csv`: é€ç­†æˆäº¤äº¤æ˜“è³‡æ–™ (43,007ç­†, 21æ¬„)

# %% [markdown]
# ## 1. ç’°å¢ƒè¨­å®šèˆ‡å¥—ä»¶è¼‰å…¥

# %%
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# è¨­å®šé¡¯ç¤ºé¸é …
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', 100)
pd.set_option('display.width', None)
pd.set_option('display.max_colwidth', 50)

# è¨­å®šä¸­æ–‡å­—åž‹
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'Arial Unicode MS', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False

# è¨­å®šåœ–è¡¨æ¨£å¼
sns.set_style("whitegrid")
plt.style.use('default')

print("âœ… ç’°å¢ƒè¨­å®šå®Œæˆ")
print(f"ðŸ“… åˆ†æžæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

# %% [markdown]
# ## 2. è³‡æ–™è¼‰å…¥èˆ‡åŸºæœ¬è³‡è¨Šæª¢è¦–

# %%
# è¼‰å…¥è³‡æ–™æª”æ¡ˆ
print("ðŸ”„ è¼‰å…¥è³‡æ–™æª”æ¡ˆ...")

try:
    # è¼‰å…¥é å”®ç¤¾å€è³‡æ–™
    community_df = pd.read_csv('../data/raw/lvr_community_data_test.csv', encoding='utf-8')
    print(f"âœ… é å”®ç¤¾å€è³‡æ–™è¼‰å…¥æˆåŠŸ: {community_df.shape}")
    
    # è¼‰å…¥é€ç­†äº¤æ˜“è³‡æ–™  
    transaction_df = pd.read_csv('../data/raw/lvr_presale_test.csv', encoding='utf-8')
    print(f"âœ… é€ç­†äº¤æ˜“è³‡æ–™è¼‰å…¥æˆåŠŸ: {transaction_df.shape}")
    
except FileNotFoundError as e:
    print(f"âŒ æª”æ¡ˆè¼‰å…¥å¤±æ•—: {e}")
    print("ðŸ“ è«‹ç¢ºèªæª”æ¡ˆæ˜¯å¦æ”¾ç½®åœ¨ ../data/raw/ è³‡æ–™å¤¾ä¸­")
except Exception as e:
    print(f"âŒ è¼‰å…¥éŽç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")

# %%
# è³‡æ–™åŸºæœ¬è³‡è¨Šæª¢è¦–
print("=" * 80)
print("ðŸ“Š è³‡æ–™åŸºæœ¬è³‡è¨Šç¸½è¦½")
print("=" * 80)

print("\nðŸ˜ï¸ é å”®ç¤¾å€è³‡æ–™ (lvr_community_data_test.csv)")
print(f"   è³‡æ–™å½¢ç‹€: {community_df.shape}")
print(f"   è¨˜æ†¶é«”ä½¿ç”¨: {community_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")

print("\nðŸ  é€ç­†äº¤æ˜“è³‡æ–™ (lvr_presale_test.csv)")  
print(f"   è³‡æ–™å½¢ç‹€: {transaction_df.shape}")
print(f"   è¨˜æ†¶é«”ä½¿ç”¨: {transaction_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")

# %%
# æª¢è¦–æ¬„ä½è³‡è¨Š
print("\nðŸ“‹ é å”®ç¤¾å€è³‡æ–™æ¬„ä½è³‡è¨Š:")
print("-" * 50)
community_info = pd.DataFrame({
    'æ¬„ä½åç¨±': community_df.columns,
    'è³‡æ–™åž‹åˆ¥': community_df.dtypes,
    'éžç©ºå€¼æ•¸é‡': community_df.count(),
    'ç¼ºå¤±å€¼æ•¸é‡': community_df.isnull().sum(),
    'ç¼ºå¤±çŽ‡(%)': (community_df.isnull().sum() / len(community_df) * 100).round(2)
})
print(community_info)

# %%
print("\nðŸ“‹ é€ç­†äº¤æ˜“è³‡æ–™æ¬„ä½è³‡è¨Š:")
print("-" * 50)
transaction_info = pd.DataFrame({
    'æ¬„ä½åç¨±': transaction_df.columns,
    'è³‡æ–™åž‹åˆ¥': transaction_df.dtypes,
    'éžç©ºå€¼æ•¸é‡': transaction_df.count(),
    'ç¼ºå¤±å€¼æ•¸é‡': transaction_df.isnull().sum(),
    'ç¼ºå¤±çŽ‡(%)': (transaction_df.isnull().sum() / len(transaction_df) * 100).round(2)
})
print(transaction_info)

# %% [markdown]
# ## 3. è³‡æ–™æ¨£æœ¬æª¢è¦–èˆ‡æ ¼å¼åˆ†æž

# %%
# æª¢è¦–é å”®ç¤¾å€è³‡æ–™æ¨£æœ¬
print("ðŸ” é å”®ç¤¾å€è³‡æ–™å‰5ç­†æ¨£æœ¬:")
print("=" * 80)
display(community_df.head())

# %%
print("\nðŸ” é€ç­†äº¤æ˜“è³‡æ–™å‰5ç­†æ¨£æœ¬:")
print("=" * 80)
display(transaction_df.head())

# %%
# é—œéµæ¬„ä½æ ¼å¼åˆ†æž
print("\nðŸ“Š é—œéµæ¬„ä½æ ¼å¼åˆ†æž")
print("=" * 50)

# 1. æª¢æŸ¥ç·¨è™ŸåŒ¹é…æ¬„ä½
print("1ï¸âƒ£ è³‡æ–™é—œè¯æª¢æŸ¥:")
community_ids = set(community_df['ç·¨è™Ÿ'].dropna())
transaction_ids = set(transaction_df['å‚™æŸ¥ç·¨è™Ÿ'].dropna())

print(f"   é å”®ç¤¾å€å”¯ä¸€ç·¨è™Ÿæ•¸: {len(community_ids)}")
print(f"   äº¤æ˜“è¨˜éŒ„å”¯ä¸€å‚™æŸ¥ç·¨è™Ÿæ•¸: {len(transaction_ids)}")
print(f"   å¯åŒ¹é…ç·¨è™Ÿæ•¸: {len(community_ids & transaction_ids)}")
print(f"   åŒ¹é…çŽ‡: {len(community_ids & transaction_ids) / max(len(community_ids), len(transaction_ids)) * 100:.2f}%")

# %%
# 2. æª¢æŸ¥éŠ·å”®èµ·å§‹æ™‚é–“æ ¼å¼
print("\n2ï¸âƒ£ éŠ·å”®èµ·å§‹æ™‚é–“æ ¼å¼æª¢æŸ¥:")
sales_start_sample = community_df['éŠ·å”®èµ·å§‹æ™‚é–“'].dropna().head(10)
for i, time_val in enumerate(sales_start_sample):
    print(f"   æ¨£æœ¬{i+1}: {time_val} (é¡žåž‹: {type(time_val)})")

# %%
# 3. æª¢æŸ¥äº¤æ˜“å¹´å­£æ ¼å¼
print("\n3ï¸âƒ£ äº¤æ˜“å¹´å­£æ ¼å¼æª¢æŸ¥:")
year_season_counts = transaction_df['äº¤æ˜“å¹´å­£'].value_counts().sort_index()
print(f"   äº¤æ˜“å¹´å­£æ•¸é‡: {len(year_season_counts)}")
print(f"   å¹´å­£ç¯„åœ: {year_season_counts.index.min()} ~ {year_season_counts.index.max()}")
print("\n   å‰10å€‹å¹´å­£åˆ†å¸ƒ:")
for ys, count in year_season_counts.head(10).items():
    print(f"   {ys}: {count:,}ç­†")

# %%
# 4. æª¢æŸ¥è§£ç´„æƒ…å½¢æ ¼å¼
print("\n4ï¸âƒ£ è§£ç´„æƒ…å½¢æ ¼å¼æª¢æŸ¥:")
cancellation_counts = transaction_df['è§£ç´„æƒ…å½¢'].value_counts()
print(f"   è§£ç´„æƒ…å½¢é¡žåˆ¥æ•¸: {len(cancellation_counts)}")
print(f"   ç©ºå€¼(æ­£å¸¸äº¤æ˜“): {transaction_df['è§£ç´„æƒ…å½¢'].isnull().sum():,}ç­†")

# æª¢æŸ¥è§£ç´„è¨˜éŒ„æ¨£æœ¬
cancellation_samples = transaction_df[transaction_df['è§£ç´„æƒ…å½¢'].notna()]['è§£ç´„æƒ…å½¢'].head(10)
print("\n   è§£ç´„è¨˜éŒ„æ¨£æœ¬:")
for i, cancel in enumerate(cancellation_samples):
    print(f"   æ¨£æœ¬{i+1}: {cancel}")

# %% [markdown]
# ## 4. åœ°ç†åˆ†å¸ƒåˆ†æž

# %%
# åœ°ç†åˆ†å¸ƒçµ±è¨ˆ
print("ðŸ—ºï¸ åœ°ç†åˆ†å¸ƒåˆ†æž")
print("=" * 50)

# ç¸£å¸‚åˆ†å¸ƒ - é å”®ç¤¾å€
print("1ï¸âƒ£ é å”®ç¤¾å€ç¸£å¸‚åˆ†å¸ƒ:")
community_city_dist = community_df['ç¸£å¸‚'].value_counts()
for city, count in community_city_dist.head(10).items():
    percentage = count / len(community_df) * 100
    print(f"   {city}: {count:,}å€‹å»ºæ¡ˆ ({percentage:.1f}%)")

# %%
# ç¸£å¸‚åˆ†å¸ƒ - äº¤æ˜“è¨˜éŒ„
print("\n2ï¸âƒ£ äº¤æ˜“è¨˜éŒ„ç¸£å¸‚åˆ†å¸ƒ:")
transaction_city_dist = transaction_df['ç¸£å¸‚'].value_counts()
for city, count in transaction_city_dist.head(10).items():
    percentage = count / len(transaction_df) * 100
    print(f"   {city}: {count:,}ç­†äº¤æ˜“ ({percentage:.1f}%)")

# %%
# è¡Œæ”¿å€åˆ†å¸ƒçµ±è¨ˆ (å‰20å)
print("\n3ï¸âƒ£ ä¸»è¦è¡Œæ”¿å€åˆ†å¸ƒ (å‰20å):")
print("\né å”®ç¤¾å€:")
community_district = community_df.groupby(['ç¸£å¸‚', 'è¡Œæ”¿å€']).size().sort_values(ascending=False)
for (city, district), count in community_district.head(20).items():
    print(f"   {city} {district}: {count}å€‹å»ºæ¡ˆ")

# %% [markdown]
# ## 5. æ™‚é–“ç¯„åœåˆ†æž

# %%
# æ™‚é–“ç¯„åœåˆ†æž
print("ðŸ“… æ™‚é–“ç¯„åœåˆ†æž")
print("=" * 50)

# 1. éŠ·å”®èµ·å§‹å¹´å­£åˆ†å¸ƒ
print("1ï¸âƒ£ éŠ·å”®èµ·å§‹å¹´å­£åˆ†å¸ƒ:")
sales_start_season = community_df['éŠ·å”®èµ·å§‹å¹´å­£'].value_counts().sort_index()
print(f"   èµ·å§‹å¹´å­£ç¯„åœ: {sales_start_season.index.min()} ~ {sales_start_season.index.max()}")
print(f"   ç¸½å¹´å­£æ•¸: {len(sales_start_season)}")

print("\n   å„å¹´å­£å»ºæ¡ˆæ•¸é‡:")
for season, count in sales_start_season.items():
    print(f"   {season}: {count}å€‹å»ºæ¡ˆ")

# %%
# 2. äº¤æ˜“å¹´å­£åˆ†å¸ƒ
print("\n2ï¸âƒ£ äº¤æ˜“å¹´å­£åˆ†å¸ƒ:")
transaction_season = transaction_df['äº¤æ˜“å¹´å­£'].value_counts().sort_index()
print(f"   äº¤æ˜“å¹´å­£ç¯„åœ: {transaction_season.index.min()} ~ {transaction_season.index.max()}")
print(f"   ç¸½å¹´å­£æ•¸: {len(transaction_season)}")

print("\n   å„å¹´å­£äº¤æ˜“é‡:")
for season, count in transaction_season.items():
    print(f"   {season}: {count:,}ç­†äº¤æ˜“")

# %% [markdown]
# ## 6. è³‡æ–™å“è³ªæª¢æŸ¥

# %%
# é—œéµæ¬„ä½è³‡æ–™å“è³ªæª¢æŸ¥
print("ðŸ” è³‡æ–™å“è³ªæª¢æŸ¥")
print("=" * 50)

# 1. é å”®ç¤¾å€é—œéµæ¬„ä½æª¢æŸ¥
print("1ï¸âƒ£ é å”®ç¤¾å€é—œéµæ¬„ä½å“è³ª:")
community_key_fields = ['ç·¨è™Ÿ', 'ç¤¾å€åç¨±', 'ç¸£å¸‚', 'è¡Œæ”¿å€', 'æˆ¶æ•¸', 'éŠ·å”®èµ·å§‹å¹´å­£']
for field in community_key_fields:
    null_count = community_df[field].isnull().sum()
    null_rate = null_count / len(community_df) * 100
    print(f"   {field}: ç¼ºå¤± {null_count} ç­† ({null_rate:.2f}%)")

# %%
# 2. äº¤æ˜“è¨˜éŒ„é—œéµæ¬„ä½æª¢æŸ¥
print("\n2ï¸âƒ£ äº¤æ˜“è¨˜éŒ„é—œéµæ¬„ä½å“è³ª:")
transaction_key_fields = ['å‚™æŸ¥ç·¨è™Ÿ', 'ç¸£å¸‚', 'è¡Œæ”¿å€', 'äº¤æ˜“æ—¥æœŸ', 'äº¤æ˜“å¹´å­£', 'äº¤æ˜“ç¸½åƒ¹', 'å»ºç‰©å–®åƒ¹']
for field in transaction_key_fields:
    null_count = transaction_df[field].isnull().sum()
    null_rate = null_count / len(transaction_df) * 100
    print(f"   {field}: ç¼ºå¤± {null_count} ç­† ({null_rate:.2f}%)")

# %%
# 3. æ•¸å€¼æ¬„ä½ç•°å¸¸å€¼æª¢æŸ¥
print("\n3ï¸âƒ£ æ•¸å€¼æ¬„ä½ç•°å¸¸å€¼æª¢æŸ¥:")

# æª¢æŸ¥æˆ¶æ•¸
print("æˆ¶æ•¸çµ±è¨ˆ:")
households_stats = community_df['æˆ¶æ•¸'].describe()
print(f"   æœ€å°å€¼: {households_stats['min']}")
print(f"   æœ€å¤§å€¼: {households_stats['max']}")
print(f"   å¹³å‡å€¼: {households_stats['mean']:.1f}")
print(f"   ä¸­ä½æ•¸: {households_stats['50%']:.1f}")

# æª¢æŸ¥äº¤æ˜“ç¸½åƒ¹
print("\näº¤æ˜“ç¸½åƒ¹çµ±è¨ˆ (è¬å…ƒ):")
price_stats = transaction_df['äº¤æ˜“ç¸½åƒ¹'].describe()
print(f"   æœ€å°å€¼: {price_stats['min']}")
print(f"   æœ€å¤§å€¼: {price_stats['max']}")
print(f"   å¹³å‡å€¼: {price_stats['mean']:.1f}")
print(f"   ä¸­ä½æ•¸: {price_stats['50%']:.1f}")

# æª¢æŸ¥å»ºç‰©å–®åƒ¹
print("\nå»ºç‰©å–®åƒ¹çµ±è¨ˆ (è¬/åª):")
unit_price_stats = transaction_df['å»ºç‰©å–®åƒ¹'].describe()
print(f"   æœ€å°å€¼: {unit_price_stats['min']}")
print(f"   æœ€å¤§å€¼: {unit_price_stats['max']}")
print(f"   å¹³å‡å€¼: {unit_price_stats['mean']:.1f}")
print(f"   ä¸­ä½æ•¸: {unit_price_stats['50%']:.1f}")

# %% [markdown]
# ## 7. è§£ç´„æƒ…å½¢åˆæ­¥åˆ†æž

# %%
# è§£ç´„æƒ…å½¢æ·±åº¦åˆ†æž
print("ðŸš¨ è§£ç´„æƒ…å½¢åˆæ­¥åˆ†æž")
print("=" * 50)

# è¨ˆç®—è§£ç´„çµ±è¨ˆ
total_transactions = len(transaction_df)
normal_transactions = transaction_df['è§£ç´„æƒ…å½¢'].isnull().sum()
cancelled_transactions = transaction_df['è§£ç´„æƒ…å½¢'].notna().sum()

print(f"ç¸½äº¤æ˜“ç­†æ•¸: {total_transactions:,}")
print(f"æ­£å¸¸äº¤æ˜“: {normal_transactions:,} ç­† ({normal_transactions/total_transactions*100:.2f}%)")
print(f"è§£ç´„äº¤æ˜“: {cancelled_transactions:,} ç­† ({cancelled_transactions/total_transactions*100:.2f}%)")

# %%
# è§£ç´„æ¨¡å¼åˆ†æž
if cancelled_transactions > 0:
    print("\nè§£ç´„è¨˜éŒ„æ¨¡å¼åˆ†æž:")
    cancelled_data = transaction_df[transaction_df['è§£ç´„æƒ…å½¢'].notna()]['è§£ç´„æƒ…å½¢']
    
    # æª¢æŸ¥è§£ç´„æ—¥æœŸæ ¼å¼æ¨¡å¼
    patterns = {}
    for cancel_str in cancelled_data.head(20):
        if 'å…¨éƒ¨è§£ç´„' in str(cancel_str):
            date_part = str(cancel_str).replace('å…¨éƒ¨è§£ç´„', '').strip()
            if date_part:
                date_len = len(date_part.split(';')[0])
                pattern = f"{date_len}ä½æ•¸å­—"
                patterns[pattern] = patterns.get(pattern, 0) + 1
        
    print("   è§£ç´„æ—¥æœŸæ ¼å¼æ¨¡å¼:")
    for pattern, count in patterns.items():
        print(f"   {pattern}: {count}ç­†")

# %% [markdown]
# ## 8. è¦–è¦ºåŒ–åˆ†æž

# %%
# å»ºç«‹è¦–è¦ºåŒ–åˆ†æž
print("ðŸ“Š è¦–è¦ºåŒ–åˆ†æž")
print("=" * 50)

# 1. ç¸£å¸‚åˆ†å¸ƒåœ“é¤…åœ–
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# é å”®ç¤¾å€ç¸£å¸‚åˆ†å¸ƒ
community_city_top10 = community_df['ç¸£å¸‚'].value_counts().head(10)
axes[0].pie(community_city_top10.values, labels=community_city_top10.index, autopct='%1.1f%%')
axes[0].set_title('é å”®ç¤¾å€ç¸£å¸‚åˆ†å¸ƒ (å‰10å)', fontsize=14, fontweight='bold')

# äº¤æ˜“è¨˜éŒ„ç¸£å¸‚åˆ†å¸ƒ
transaction_city_top10 = transaction_df['ç¸£å¸‚'].value_counts().head(10)
axes[1].pie(transaction_city_top10.values, labels=transaction_city_top10.index, autopct='%1.1f%%')
axes[1].set_title('äº¤æ˜“è¨˜éŒ„ç¸£å¸‚åˆ†å¸ƒ (å‰10å)', fontsize=14, fontweight='bold')

plt.tight_layout()
plt.show()

# %%
# 2. æ™‚é–“è¶¨å‹¢åˆ†æž
fig, axes = plt.subplots(2, 1, figsize=(15, 10))

# éŠ·å”®èµ·å§‹å¹´å­£è¶¨å‹¢
sales_trend = community_df['éŠ·å”®èµ·å§‹å¹´å­£'].value_counts().sort_index()
axes[0].bar(range(len(sales_trend)), sales_trend.values)
axes[0].set_xticks(range(len(sales_trend)))
axes[0].set_xticklabels(sales_trend.index, rotation=45)
axes[0].set_title('é å”®å»ºæ¡ˆéŠ·å”®èµ·å§‹å¹´å­£åˆ†å¸ƒ', fontsize=14, fontweight='bold')
axes[0].set_ylabel('å»ºæ¡ˆæ•¸é‡')

# äº¤æ˜“å¹´å­£è¶¨å‹¢
transaction_trend = transaction_df['äº¤æ˜“å¹´å­£'].value_counts().sort_index()
axes[1].bar(range(len(transaction_trend)), transaction_trend.values, color='orange')
axes[1].set_xticks(range(len(transaction_trend)))
axes[1].set_xticklabels(transaction_trend.index, rotation=45)
axes[1].set_title('é å”®å±‹äº¤æ˜“å¹´å­£åˆ†å¸ƒ', fontsize=14, fontweight='bold')
axes[1].set_ylabel('äº¤æ˜“ç­†æ•¸')

plt.tight_layout()
plt.show()

# %%
# 3. åƒ¹æ ¼åˆ†å¸ƒåˆ†æž
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# äº¤æ˜“ç¸½åƒ¹åˆ†å¸ƒ (ç§»é™¤æ¥µç«¯å€¼)
price_filtered = transaction_df[(transaction_df['äº¤æ˜“ç¸½åƒ¹'] >= 500) & 
                               (transaction_df['äº¤æ˜“ç¸½åƒ¹'] <= 10000)]['äº¤æ˜“ç¸½åƒ¹']
axes[0].hist(price_filtered, bins=50, alpha=0.7, color='skyblue')
axes[0].set_title('äº¤æ˜“ç¸½åƒ¹åˆ†å¸ƒ (500-10000è¬)', fontsize=14, fontweight='bold')
axes[0].set_xlabel('äº¤æ˜“ç¸½åƒ¹ (è¬å…ƒ)')
axes[0].set_ylabel('é »æ¬¡')

# å»ºç‰©å–®åƒ¹åˆ†å¸ƒ (ç§»é™¤æ¥µç«¯å€¼)
unit_price_filtered = transaction_df[(transaction_df['å»ºç‰©å–®åƒ¹'] >= 10) & 
                                    (transaction_df['å»ºç‰©å–®åƒ¹'] <= 200)]['å»ºç‰©å–®åƒ¹']
axes[1].hist(unit_price_filtered, bins=50, alpha=0.7, color='lightcoral')
axes[1].set_title('å»ºç‰©å–®åƒ¹åˆ†å¸ƒ (10-200è¬/åª)', fontsize=14, fontweight='bold')
axes[1].set_xlabel('å»ºç‰©å–®åƒ¹ (è¬/åª)')
axes[1].set_ylabel('é »æ¬¡')

plt.tight_layout()
plt.show()

# %% [markdown]
# ## 9. è³‡æ–™å“è³ªç¸½çµå ±å‘Š

# %%
# ç”Ÿæˆè³‡æ–™å“è³ªç¸½çµå ±å‘Š
print("ðŸ“‹ è³‡æ–™å“è³ªç¸½çµå ±å‘Š")
print("=" * 80)

# åŸºæœ¬çµ±è¨ˆ
print("1ï¸âƒ£ åŸºæœ¬çµ±è¨ˆè³‡è¨Š:")
print(f"   é å”®ç¤¾å€å»ºæ¡ˆæ•¸: {len(community_df):,}")
print(f"   äº¤æ˜“è¨˜éŒ„ç­†æ•¸: {len(transaction_df):,}")
print(f"   è³‡æ–™åŒ¹é…çŽ‡: {len(community_ids & transaction_ids) / max(len(community_ids), len(transaction_ids)) * 100:.2f}%")

# æ™‚é–“è¦†è“‹ç¯„åœ
print(f"\n2ï¸âƒ£ æ™‚é–“è¦†è“‹ç¯„åœ:")
print(f"   éŠ·å”®èµ·å§‹å¹´å­£: {sales_start_season.index.min()} ~ {sales_start_season.index.max()}")
print(f"   äº¤æ˜“å¹´å­£: {transaction_season.index.min()} ~ {transaction_season.index.max()}")

# åœ°ç†è¦†è“‹ç¯„åœ
print(f"\n3ï¸âƒ£ åœ°ç†è¦†è“‹ç¯„åœ:")
print(f"   æ¶µè“‹ç¸£å¸‚æ•¸: {community_df['ç¸£å¸‚'].nunique()}")
print(f"   æ¶µè“‹è¡Œæ”¿å€æ•¸: {community_df['è¡Œæ”¿å€'].nunique()}")

# è§£ç´„æƒ…æ³
print(f"\n4ï¸âƒ£ è§£ç´„æƒ…æ³:")
print(f"   è§£ç´„çŽ‡: {cancelled_transactions/total_transactions*100:.2f}%")
print(f"   è§£ç´„è¨˜éŒ„æ•¸: {cancelled_transactions:,}")

# è³‡æ–™å“è³ªè©•ä¼°
print(f"\n5ï¸âƒ£ è³‡æ–™å“è³ªè©•ä¼°:")
community_completeness = (1 - community_df[community_key_fields].isnull().sum().sum() / 
                         (len(community_df) * len(community_key_fields))) * 100
transaction_completeness = (1 - transaction_df[transaction_key_fields].isnull().sum().sum() / 
                           (len(transaction_df) * len(transaction_key_fields))) * 100

print(f"   é å”®ç¤¾å€è³‡æ–™å®Œæ•´åº¦: {community_completeness:.1f}%")
print(f"   äº¤æ˜“è¨˜éŒ„è³‡æ–™å®Œæ•´åº¦: {transaction_completeness:.1f}%")

# %%
# å„²å­˜åŸºç¤Žåˆ†æžçµæžœ
print("\nðŸ’¾ å„²å­˜åˆ†æžçµæžœ...")

# å»ºç«‹åŸºç¤Žçµ±è¨ˆæ‘˜è¦
basic_stats = {
    'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
    'community_records': len(community_df),
    'transaction_records': len(transaction_df),
    'match_rate': len(community_ids & transaction_ids) / max(len(community_ids), len(transaction_ids)) * 100,
    'cancellation_rate': cancelled_transactions/total_transactions*100,
    'community_completeness': community_completeness,
    'transaction_completeness': transaction_completeness,
    'covered_cities': community_df['ç¸£å¸‚'].nunique(),
    'covered_districts': community_df['è¡Œæ”¿å€'].nunique()
}

# è½‰æ›ç‚ºDataFrameä¸¦å„²å­˜
stats_df = pd.DataFrame([basic_stats])
stats_df.to_csv('../data/processed/01_basic_analysis_summary.csv', index=False, encoding='utf-8-sig')

print("âœ… åˆ†æžçµæžœå·²å„²å­˜è‡³: ../data/processed/01_basic_analysis_summary.csv")

# %% [markdown]
# ## 10. ä¸‹ä¸€æ­¥å·¥ä½œé‡é»ž
# 
# ### âœ… å·²å®Œæˆé …ç›®:
# 1. è³‡æ–™è¼‰å…¥èˆ‡åŸºæœ¬çµæ§‹æª¢è¦–
# 2. è³‡æ–™å“è³ªè©•ä¼°èˆ‡ç¼ºå¤±å€¼åˆ†æž  
# 3. æ™‚é–“ç¯„åœèˆ‡åœ°ç†åˆ†å¸ƒåˆ†æž
# 4. è§£ç´„æƒ…å½¢åˆæ­¥çµ±è¨ˆ
# 5. åŸºç¤Žè¦–è¦ºåŒ–åˆ†æž
# 
# ### ðŸ”„ å¾…é€²è¡Œé …ç›®:
# 1. **Notebook 2**: è§£ç´„è³‡æ–™æ·±åº¦è§£æž
#    - å¯¦ä½œè§£ç´„è³‡æ–™è§£æžå‡½æ•¸
#    - è§£ç´„æ™‚é–“è½‰æ›èˆ‡å¹´å­£è¨ˆç®—
#    - è§£ç´„æ¨¡å¼èˆ‡è¶¨å‹¢åˆ†æž
# 
# 2. **Notebook 3**: é‡è¤‡äº¤æ˜“è­˜åˆ¥èˆ‡è™•ç†
#    - å»ºç«‹ç‰©ä»¶å”¯ä¸€IDé‚è¼¯
#    - å¯¦ä½œåŽ»é‡è™•ç†æ©Ÿåˆ¶
#    - é©—è­‰æœ‰æ•ˆäº¤æ˜“åˆ¤æ–·
# 
# ### ðŸŽ¯ é—œéµç™¼ç¾:
# 1. è³‡æ–™åŒ¹é…çŽ‡ç¬¦åˆæ¸¬è©¦è³‡æ–™ç‰¹æ€§
# 2. è§£ç´„çŽ‡ {cancelled_transactions/total_transactions*100:.2f}% ç¬¦åˆå¸‚å ´é æœŸ
# 3. è³‡æ–™å®Œæ•´åº¦è‰¯å¥½ï¼Œå¯é€²è¡Œå¾ŒçºŒåˆ†æž
# 4. æ™‚é–“ç¯„åœæ¶µè“‹ PRD è¦æ ¼è¦æ±‚

print("\n" + "="*80)
print("ðŸŽ‰ Notebook 1 - åŸºç¤Žè³‡æ–™æŽ¢ç´¢å®Œæˆï¼")
print("ðŸ“ è«‹ç¹¼çºŒåŸ·è¡Œ Notebook 2 é€²è¡Œè§£ç´„è³‡æ–™æ·±åº¦è§£æž")
print("="*80)