# é å”®å±‹å¸‚å ´åˆ†æç³»çµ± - 11_æ•´åˆæµç¨‹æ¸¬è©¦ç³»çµ±
# åŸºæ–¼ PRD v2.3 è¦æ ¼é€²è¡Œå®Œæ•´ç³»çµ±æ•´åˆèˆ‡ç«¯åˆ°ç«¯æ¸¬è©¦
# ================================================================================

# %% [markdown]
# # é å”®å±‹å¸‚å ´åˆ†æç³»çµ± - æ•´åˆæµç¨‹æ¸¬è©¦ç³»çµ±
# 
# ## ğŸ“‹ ç›®æ¨™
# - âœ… æ•´åˆæ‰€æœ‰åŠŸèƒ½æ¨¡çµ„
# - âœ… å»ºç«‹å®Œæ•´è³‡æ–™è™•ç†æµç¨‹
# - âœ… é€²è¡Œç«¯åˆ°ç«¯æ¸¬è©¦
# - âœ… æ•ˆèƒ½æ¸¬è©¦èˆ‡å„ªåŒ–
# - âœ… é‚Šç•Œæ¢ä»¶æ¸¬è©¦
# - âœ… éŒ¯èª¤è™•ç†æ©Ÿåˆ¶é©—è­‰
# - âœ… æœ€çµ‚è¼¸å‡ºé©—è­‰
# 
# ## ğŸ¯ å…§å®¹å¤§ç¶±
# 1. ç’°å¢ƒè¨­å®šèˆ‡ä¾è³´å°å…¥
# 2. æ¨¡çµ„åŒ–åŠŸèƒ½æ•´åˆ
# 3. å®Œæ•´Pipelineå»ºç«‹
# 4. ç³»çµ±æ¶æ§‹é©—è­‰
# 5. æ•ˆèƒ½æ¸¬è©¦èˆ‡å„ªåŒ–
# 6. é‚Šç•Œæ¢ä»¶æ¸¬è©¦
# 7. éŒ¯èª¤è™•ç†æ©Ÿåˆ¶é©—è­‰
# 8. è³‡æ–™å“è³ªé©—è­‰
# 9. è¼¸å‡ºå®Œæ•´æ€§é©—è­‰
# 10. ç³»çµ±ç©©å®šæ€§æ¸¬è©¦
# 11. æœ€çµ‚é©—æ”¶æ¸¬è©¦
# 12. ç³»çµ±éƒ¨ç½²æº–å‚™
# 
# ## ğŸ—ï¸ ç³»çµ±æ¶æ§‹
# ```
# åŸå§‹è³‡æ–™ â†’ è³‡æ–™æ¸…ç† â†’ è§£ç´„åˆ†æ â†’ å»é‡è™•ç† â†’ æŒ‡æ¨™è¨ˆç®—
#     â†“
# ç¤¾å€ç´šå ±å‘Š â†’ è¡Œæ”¿å€ç´šèšåˆ â†’ ç¸£å¸‚ç´šèšåˆ â†’ å°ˆé …åˆ†æ â†’ æœ€çµ‚å ±å‘Š
# ```

# %% [markdown]
# ## 1. ç’°å¢ƒè¨­å®šèˆ‡ä¾è³´å°å…¥

# %%
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.figure_factory as ff
from datetime import datetime, timedelta
import re
import warnings
from collections import Counter, defaultdict
import math
from scipy import stats
import json
import glob
import os
import sys
import time
import psutil
import traceback
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
import logging
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import concurrent.futures
from functools import wraps
import gc
warnings.filterwarnings('ignore')

# è¨­å®šé¡¯ç¤ºé¸é …
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', 100)
pd.set_option('display.width', None)
pd.set_option('display.max_colwidth', 80)

# è¨­å®šä¸­æ–‡å­—å‹
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'Arial Unicode MS', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('../logs/pipeline_test.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

print("âœ… ç’°å¢ƒè¨­å®šå®Œæˆ")
print(f"ğŸ“… æ¸¬è©¦é–‹å§‹æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print(f"ğŸ’» ç³»çµ±è³‡æº: CPU {psutil.cpu_count()}æ ¸å¿ƒ, è¨˜æ†¶é«” {psutil.virtual_memory().total / (1024**3):.1f}GB")

# %% [markdown]
# ## 2. æ¨¡çµ„åŒ–åŠŸèƒ½æ•´åˆ

# %%
class PreSaleHousingAnalysisSystem:
    """
    é å”®å±‹å¸‚å ´é¢¨éšªåˆ†æç³»çµ±
    æ•´åˆæ‰€æœ‰åˆ†æåŠŸèƒ½çš„ä¸»è¦é¡åˆ¥
    """
    
    def __init__(self, config: Optional[Dict] = None):
        """
        åˆå§‹åŒ–åˆ†æç³»çµ±
        
        Args:
            config (Dict, optional): ç³»çµ±é…ç½®åƒæ•¸
        """
        self.config = config or self._get_default_config()
        self.data = {}
        self.results = {}
        self.performance_metrics = {}
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # å»ºç«‹è¼¸å‡ºç›®éŒ„
        self._ensure_directories()
        
        self.logger.info("é å”®å±‹å¸‚å ´é¢¨éšªåˆ†æç³»çµ±åˆå§‹åŒ–å®Œæˆ")
    
    def _get_default_config(self) -> Dict:
        """ç²å–é è¨­é…ç½®"""
        return {
            'data_paths': {
                'pre_sale_data': '../data/raw/lvr_pre_sale_test.csv',
                'sale_data': '../data/raw/lvr_sale_data_test.csv',
                'output_dir': '../data/processed/',
                'logs_dir': '../logs/'
            },
            'processing': {
                'chunk_size': 10000,
                'parallel_workers': 4,
                'memory_threshold': 0.8,
                'timeout_seconds': 3600
            },
            'quality_thresholds': {
                'min_completeness': 0.95,
                'max_cancellation_rate': 0.1,
                'min_absorption_rate': 0.0,
                'max_absorption_rate': 1.0
            },
            'analysis': {
                'cancellation_risk_threshold': 0.05,
                'high_performance_threshold': 0.7,
                'stagnant_threshold': 12,
                'price_outlier_threshold': 3
            }
        }
    
    def _ensure_directories(self):
        """ç¢ºä¿å¿…è¦ç›®éŒ„å­˜åœ¨"""
        for dir_path in [
            self.config['data_paths']['output_dir'],
            self.config['data_paths']['logs_dir']
        ]:
            Path(dir_path).mkdir(parents=True, exist_ok=True)

    # =================================================================
    # è³‡æ–™è¼‰å…¥èˆ‡æ¸…ç†æ¨¡çµ„
    # =================================================================
    
    def load_and_validate_data(self) -> bool:
        """
        è¼‰å…¥ä¸¦é©—è­‰åŸå§‹è³‡æ–™
        
        Returns:
            bool: è¼‰å…¥æ˜¯å¦æˆåŠŸ
        """
        try:
            self.logger.info("é–‹å§‹è¼‰å…¥åŸå§‹è³‡æ–™...")
            
            # è¼‰å…¥é å”®å±‹è³‡æ–™
            pre_sale_path = self.config['data_paths']['pre_sale_data']
            if not os.path.exists(pre_sale_path):
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°é å”®å±‹è³‡æ–™æª”æ¡ˆ: {pre_sale_path}")
            
            self.data['pre_sale_raw'] = pd.read_csv(pre_sale_path, encoding='utf-8')
            self.logger.info(f"é å”®å±‹è³‡æ–™è¼‰å…¥å®Œæˆ: {len(self.data['pre_sale_raw']):,} ç­†")
            
            # è¼‰å…¥å»ºæ¡ˆè³‡æ–™
            sale_data_path = self.config['data_paths']['sale_data']
            if not os.path.exists(sale_data_path):
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°å»ºæ¡ˆè³‡æ–™æª”æ¡ˆ: {sale_data_path}")
            
            self.data['sale_data_raw'] = pd.read_csv(sale_data_path, encoding='utf-8')
            self.logger.info(f"å»ºæ¡ˆè³‡æ–™è¼‰å…¥å®Œæˆ: {len(self.data['sale_data_raw']):,} ç­†")
            
            # åŸºæœ¬è³‡æ–™é©—è­‰
            self._validate_raw_data()
            
            return True
            
        except Exception as e:
            self.logger.error(f"è³‡æ–™è¼‰å…¥å¤±æ•—: {e}")
            return False
    
    def _validate_raw_data(self):
        """é©—è­‰åŸå§‹è³‡æ–™å“è³ª"""
        
        # æª¢æŸ¥é å”®å±‹è³‡æ–™å¿…è¦æ¬„ä½
        required_pre_sale_cols = ['å‚™æŸ¥ç·¨è™Ÿ', 'ç¸£å¸‚', 'è¡Œæ”¿å€', 'äº¤æ˜“æ—¥æœŸ', 'è§£ç´„æƒ…å½¢']
        missing_cols = [col for col in required_pre_sale_cols if col not in self.data['pre_sale_raw'].columns]
        if missing_cols:
            raise ValueError(f"é å”®å±‹è³‡æ–™ç¼ºå°‘å¿…è¦æ¬„ä½: {missing_cols}")
        
        # æª¢æŸ¥å»ºæ¡ˆè³‡æ–™å¿…è¦æ¬„ä½
        required_sale_cols = ['ç·¨è™Ÿ', 'ç¤¾å€åç¨±', 'ç¸½æˆ¶æ•¸', 'éŠ·å”®èµ·å§‹æ™‚é–“']
        missing_cols = [col for col in required_sale_cols if col not in self.data['sale_data_raw'].columns]
        if missing_cols:
            raise ValueError(f"å»ºæ¡ˆè³‡æ–™ç¼ºå°‘å¿…è¦æ¬„ä½: {missing_cols}")
        
        # æª¢æŸ¥è³‡æ–™å®Œæ•´æ€§
        pre_sale_completeness = 1 - self.data['pre_sale_raw'].isnull().sum().sum() / (
            len(self.data['pre_sale_raw']) * len(self.data['pre_sale_raw'].columns)
        )
        
        if pre_sale_completeness < self.config['quality_thresholds']['min_completeness']:
            self.logger.warning(f"é å”®å±‹è³‡æ–™å®Œæ•´æ€§åä½: {pre_sale_completeness:.2%}")
        
        self.logger.info(f"è³‡æ–™å“è³ªé©—è­‰å®Œæˆ - é å”®å±‹å®Œæ•´æ€§: {pre_sale_completeness:.2%}")

    def clean_and_standardize_data(self) -> bool:
        """
        æ¸…ç†å’Œæ¨™æº–åŒ–è³‡æ–™
        
        Returns:
            bool: æ¸…ç†æ˜¯å¦æˆåŠŸ
        """
        try:
            self.logger.info("é–‹å§‹è³‡æ–™æ¸…ç†å’Œæ¨™æº–åŒ–...")
            
            # æ¸…ç†é å”®å±‹è³‡æ–™
            self.data['pre_sale_cleaned'] = self._clean_pre_sale_data(
                self.data['pre_sale_raw'].copy()
            )
            
            # æ¸…ç†å»ºæ¡ˆè³‡æ–™
            self.data['sale_data_cleaned'] = self._clean_sale_data(
                self.data['sale_data_raw'].copy()
            )
            
            # è³‡æ–™åŒ¹é…
            self.data['matched_data'] = self._match_data(
                self.data['pre_sale_cleaned'],
                self.data['sale_data_cleaned']
            )
            
            self.logger.info(f"è³‡æ–™æ¸…ç†å®Œæˆ - åŒ¹é…æˆåŠŸ: {len(self.data['matched_data']):,} ç­†")
            
            return True
            
        except Exception as e:
            self.logger.error(f"è³‡æ–™æ¸…ç†å¤±æ•—: {e}")
            return False
    
    def _clean_pre_sale_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ¸…ç†é å”®å±‹è³‡æ–™"""
        
        # æ—¥æœŸæ ¼å¼æ¨™æº–åŒ–
        df['äº¤æ˜“æ—¥æœŸ'] = pd.to_datetime(df['äº¤æ˜“æ—¥æœŸ'], format='%Y%m%d', errors='coerce')
        
        # è§£ç´„æƒ…å½¢è§£æ
        df['æ˜¯å¦æ­£å¸¸äº¤æ˜“'] = df['è§£ç´„æƒ…å½¢'].isnull() | (df['è§£ç´„æƒ…å½¢'] == '')
        df['æ˜¯å¦è§£ç´„'] = ~df['æ˜¯å¦æ­£å¸¸äº¤æ˜“']
        
        # è§£ç´„æ—¥æœŸè§£æ
        def parse_cancellation_date(cancellation_field):
            if pd.isnull(cancellation_field) or cancellation_field == '':
                return None
            
            cancellation_str = str(cancellation_field).strip()
            if 'å…¨éƒ¨è§£ç´„' in cancellation_str:
                date_str = cancellation_str.replace('å…¨éƒ¨è§£ç´„', '').strip()
                if len(date_str) == 7:  # YYYMMDDæ ¼å¼
                    try:
                        year = int(date_str[:3]) + 1911  # æ°‘åœ‹å¹´è½‰è¥¿å…ƒå¹´
                        month = int(date_str[3:5])
                        day = int(date_str[5:7])
                        return pd.Timestamp(year, month, day)
                    except:
                        return None
            return None
        
        df['è§£ç´„æ—¥æœŸ'] = df['è§£ç´„æƒ…å½¢'].apply(parse_cancellation_date)
        
        # åƒ¹æ ¼æ¬„ä½æ¸…ç†
        numeric_cols = ['äº¤æ˜“ç¸½åƒ¹', 'å»ºç‰©å–®åƒ¹', 'ç¸½é¢ç©']
        for col in numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # å¹´å­£è¨ˆç®—
        df['äº¤æ˜“å¹´å­£'] = df['äº¤æ˜“æ—¥æœŸ'].apply(self._calculate_year_season)
        
        return df
    
    def _clean_sale_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ¸…ç†å»ºæ¡ˆè³‡æ–™"""
        
        # éŠ·å”®èµ·å§‹æ™‚é–“æ¨™æº–åŒ–
        def parse_start_time(time_str):
            if pd.isnull(time_str):
                return None
            try:
                time_str = str(time_str).strip()
                if len(time_str) == 7:  # YYYMMDDæ ¼å¼
                    year = int(time_str[:3]) + 1911
                    month = int(time_str[3:5])
                    day = int(time_str[5:7])
                    return pd.Timestamp(year, month, day)
            except:
                return None
            return None
        
        df['éŠ·å”®èµ·å§‹æ—¥æœŸ'] = df['éŠ·å”®èµ·å§‹æ™‚é–“'].apply(parse_start_time)
        df['éŠ·å”®èµ·å§‹å¹´å­£'] = df['éŠ·å”®èµ·å§‹æ—¥æœŸ'].apply(self._calculate_year_season)
        
        # æ•¸å€¼æ¬„ä½æ¸…ç†
        if 'ç¸½æˆ¶æ•¸' in df.columns:
            df['ç¸½æˆ¶æ•¸'] = pd.to_numeric(df['ç¸½æˆ¶æ•¸'], errors='coerce')
        
        return df
    
    def _match_data(self, pre_sale_df: pd.DataFrame, sale_df: pd.DataFrame) -> pd.DataFrame:
        """åŒ¹é…é å”®å±‹èˆ‡å»ºæ¡ˆè³‡æ–™"""
        
        # å»ºç«‹é—œè¯
        matched = pre_sale_df.merge(
            sale_df,
            left_on='å‚™æŸ¥ç·¨è™Ÿ',
            right_on='ç·¨è™Ÿ',
            how='left'
        )
        
        # è¨˜éŒ„åŒ¹é…ç‡
        match_rate = (matched['ç¤¾å€åç¨±'].notna()).mean()
        self.logger.info(f"è³‡æ–™åŒ¹é…ç‡: {match_rate:.2%}")
        
        return matched
    
    def _calculate_year_season(self, date):
        """è¨ˆç®—å¹´å­£"""
        if pd.isnull(date):
            return None
        
        year = date.year - 1911  # è½‰æ›ç‚ºæ°‘åœ‹å¹´
        season = math.ceil(date.month / 3)
        return f"{year:03d}Y{season}S"

    # =================================================================
    # é‡è¤‡äº¤æ˜“è™•ç†æ¨¡çµ„
    # =================================================================
    
    def process_duplicate_transactions(self) -> bool:
        """
        è™•ç†é‡è¤‡äº¤æ˜“
        
        Returns:
            bool: è™•ç†æ˜¯å¦æˆåŠŸ
        """
        try:
            self.logger.info("é–‹å§‹è™•ç†é‡è¤‡äº¤æ˜“...")
            
            df = self.data['matched_data'].copy()
            
            # å»ºç«‹ç‰©ä»¶å”¯ä¸€è­˜åˆ¥
            df['ç‰©ä»¶ID'] = df['å‚™æŸ¥ç·¨è™Ÿ'].astype(str) + '_' + df['åè½'].astype(str) + '_' + df['æ¨“å±¤'].astype(str)
            
            # è™•ç†é‡è¤‡äº¤æ˜“
            valid_transactions = []
            
            for obj_id, group in df.groupby('ç‰©ä»¶ID'):
                if len(group) == 1:
                    # å–®ä¸€äº¤æ˜“
                    valid_transactions.append(group.iloc[0])
                else:
                    # å¤šé‡äº¤æ˜“è™•ç†
                    valid_tx = self._select_valid_transaction(group)
                    if valid_tx is not None:
                        valid_transactions.append(valid_tx)
            
            self.data['valid_transactions'] = pd.DataFrame(valid_transactions)
            
            dedup_rate = len(self.data['valid_transactions']) / len(df)
            self.logger.info(f"é‡è¤‡äº¤æ˜“è™•ç†å®Œæˆ - æœ‰æ•ˆäº¤æ˜“ç‡: {dedup_rate:.2%}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"é‡è¤‡äº¤æ˜“è™•ç†å¤±æ•—: {e}")
            return False
    
    def _select_valid_transaction(self, group: pd.DataFrame) -> Optional[pd.Series]:
        """é¸æ“‡æœ‰æ•ˆäº¤æ˜“"""
        
        # å„ªå…ˆé¸æ“‡æ­£å¸¸äº¤æ˜“
        normal_transactions = group[group['æ˜¯å¦æ­£å¸¸äº¤æ˜“'] == True]
        if not normal_transactions.empty:
            # è¿”å›æœ€æ—©çš„æ­£å¸¸äº¤æ˜“
            return normal_transactions.loc[normal_transactions['äº¤æ˜“æ—¥æœŸ'].idxmin()]
        
        # å¦‚æœéƒ½æ˜¯è§£ç´„ï¼Œè¿”å›æœ€æ—©çš„è§£ç´„äº¤æ˜“
        if not group.empty:
            return group.loc[group['äº¤æ˜“æ—¥æœŸ'].idxmin()]
        
        return None

    # =================================================================
    # ä¸‰å±¤ç´šåˆ†ææ¨¡çµ„
    # =================================================================
    
    def generate_community_level_analysis(self) -> bool:
        """
        ç”Ÿæˆç¤¾å€ç´šåˆ†æ
        
        Returns:
            bool: ç”Ÿæˆæ˜¯å¦æˆåŠŸ
        """
        try:
            self.logger.info("é–‹å§‹ç”Ÿæˆç¤¾å€ç´šåˆ†æ...")
            
            df = self.data['valid_transactions'].copy()
            
            # æŒ‰å»ºæ¡ˆå’Œå¹´å­£åˆ†çµ„åˆ†æ
            community_results = []
            
            # ç²å–æ‰€æœ‰å¹´å­£
            all_seasons = sorted(df['äº¤æ˜“å¹´å­£'].dropna().unique())
            
            for (project_id, season), group in df.groupby(['å‚™æŸ¥ç·¨è™Ÿ', 'äº¤æ˜“å¹´å­£']):
                if pd.isnull(season):
                    continue
                
                # åŸºæœ¬è³‡è¨Š
                basic_info = self._extract_basic_info(group)
                
                # å»åŒ–åˆ†æ
                absorption_metrics = self._calculate_absorption_metrics(group, project_id, season, df)
                
                # è§£ç´„åˆ†æ
                cancellation_metrics = self._calculate_cancellation_metrics(group, project_id, df)
                
                # åƒ¹æ ¼åˆ†æ
                price_metrics = self._calculate_price_metrics(group)
                
                # å»åŒ–å‹•æ…‹
                dynamics_metrics = self._calculate_dynamics_metrics(group, project_id, season, df)
                
                # åˆä½µçµæœ
                result = {**basic_info, **absorption_metrics, **cancellation_metrics, 
                         **price_metrics, **dynamics_metrics}
                community_results.append(result)
            
            self.results['community_level'] = pd.DataFrame(community_results)
            
            self.logger.info(f"ç¤¾å€ç´šåˆ†æå®Œæˆ - {len(community_results):,} ç­†è¨˜éŒ„")
            
            return True
            
        except Exception as e:
            self.logger.error(f"ç¤¾å€ç´šåˆ†æå¤±æ•—: {e}")
            return False
    
    def _extract_basic_info(self, group: pd.DataFrame) -> Dict:
        """æå–åŸºæœ¬è³‡è¨Š"""
        first_row = group.iloc[0]
        
        return {
            'å‚™æŸ¥ç·¨è™Ÿ': first_row['å‚™æŸ¥ç·¨è™Ÿ'],
            'ç¤¾å€åç¨±': first_row.get('ç¤¾å€åç¨±', ''),
            'ç¸£å¸‚': first_row['ç¸£å¸‚'],
            'è¡Œæ”¿å€': first_row['è¡Œæ”¿å€'],
            'åè½è¡—é“': first_row.get('åè½', ''),
            'ç¸½æˆ¶æ•¸': first_row.get('ç¸½æˆ¶æ•¸', 0),
            'éŠ·å”®èµ·å§‹å¹´å­£': first_row.get('éŠ·å”®èµ·å§‹å¹´å­£', ''),
            'å¹´å­£': first_row['äº¤æ˜“å¹´å­£']
        }
    
    def _calculate_absorption_metrics(self, group: pd.DataFrame, project_id: str, 
                                    season: str, all_df: pd.DataFrame) -> Dict:
        """è¨ˆç®—å»åŒ–æŒ‡æ¨™"""
        
        # ç´¯ç©æˆäº¤ç­†æ•¸
        project_data = all_df[all_df['å‚™æŸ¥ç·¨è™Ÿ'] == project_id]
        cumulative_transactions = len(project_data[
            (project_data['äº¤æ˜“å¹´å­£'] <= season) & 
            (project_data['æ˜¯å¦æ­£å¸¸äº¤æ˜“'] == True)
        ])
        
        # ç´¯ç©è§£ç´„ç­†æ•¸
        cumulative_cancellations = len(project_data[
            (project_data['äº¤æ˜“å¹´å­£'] <= season) & 
            (project_data['æ˜¯å¦è§£ç´„'] == True)
        ])
        
        # æœ¬å­£æˆäº¤ç­†æ•¸
        current_transactions = len(group[group['æ˜¯å¦æ­£å¸¸äº¤æ˜“'] == True])
        
        # ç¸½æˆ¶æ•¸
        total_units = group.iloc[0].get('ç¸½æˆ¶æ•¸', 0)
        if total_units == 0:
            total_units = max(cumulative_transactions, 100)  # é è¨­å€¼
        
        # å»åŒ–ç‡è¨ˆç®—
        gross_absorption = cumulative_transactions / total_units * 100 if total_units > 0 else 0
        net_absorption = (cumulative_transactions - cumulative_cancellations) / total_units * 100 if total_units > 0 else 0
        
        return {
            'ç´¯ç©æˆäº¤ç­†æ•¸': cumulative_transactions,
            'ç´¯ç©è§£ç´„ç­†æ•¸': cumulative_cancellations,
            'è©²å­£æˆäº¤ç­†æ•¸': current_transactions,
            'æ¯›å»åŒ–ç‡(%)': gross_absorption,
            'æ·¨å»åŒ–ç‡(%)': net_absorption,
            'ç¸½æˆ¶æ•¸': total_units
        }
    
    def _calculate_cancellation_metrics(self, group: pd.DataFrame, project_id: str, 
                                      all_df: pd.DataFrame) -> Dict:
        """è¨ˆç®—è§£ç´„æŒ‡æ¨™"""
        
        project_data = all_df[all_df['å‚™æŸ¥ç·¨è™Ÿ'] == project_id]
        
        # è§£ç´„çµ±è¨ˆ
        total_cancellations = len(project_data[project_data['æ˜¯å¦è§£ç´„'] == True])
        total_transactions = len(project_data[project_data['æ˜¯å¦æ­£å¸¸äº¤æ˜“'] == True])
        
        cancellation_rate = total_cancellations / total_transactions * 100 if total_transactions > 0 else 0
        
        # è§£ç´„é¢¨éšªè©•ç´š
        if cancellation_rate > 10:
            risk_level = "ğŸ”´ è§£ç´„é«˜é¢¨éšª"
        elif cancellation_rate > 5:
            risk_level = "ğŸŸ¡ è§£ç´„ä¸­é¢¨éšª"
        else:
            risk_level = "ğŸŸ¢ è§£ç´„ä½é¢¨éšª"
        
        return {
            'ç´¯ç©è§£ç´„ç‡(%)': cancellation_rate,
            'è§£ç´„è­¦ç¤º': risk_level
        }
    
    def _calculate_price_metrics(self, group: pd.DataFrame) -> Dict:
        """è¨ˆç®—åƒ¹æ ¼æŒ‡æ¨™"""
        
        valid_prices = group[group['å»ºç‰©å–®åƒ¹'].notna() & (group['å»ºç‰©å–®åƒ¹'] > 0)]
        
        if valid_prices.empty:
            return {
                'å¹³å‡äº¤æ˜“å–®åƒ¹(è¬/åª)': 0,
                'å¹³å‡ç¸½é¢ç©(åª)': 0,
                'å¹³å‡äº¤æ˜“ç¸½åƒ¹(è¬)': 0
            }
        
        return {
            'å¹³å‡äº¤æ˜“å–®åƒ¹(è¬/åª)': valid_prices['å»ºç‰©å–®åƒ¹'].mean() / 10000,  # è½‰æ›ç‚ºè¬/åª
            'å¹³å‡ç¸½é¢ç©(åª)': valid_prices['ç¸½é¢ç©'].mean() if 'ç¸½é¢ç©' in valid_prices.columns else 0,
            'å¹³å‡äº¤æ˜“ç¸½åƒ¹(è¬)': valid_prices['äº¤æ˜“ç¸½åƒ¹'].mean() / 10000 if 'äº¤æ˜“ç¸½åƒ¹' in valid_prices.columns else 0
        }
    
    def _calculate_dynamics_metrics(self, group: pd.DataFrame, project_id: str, 
                                  season: str, all_df: pd.DataFrame) -> Dict:
        """è¨ˆç®—å»åŒ–å‹•æ…‹æŒ‡æ¨™"""
        
        # å»åŒ–é€Ÿåº¦è¨ˆç®—ï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼‰
        project_data = all_df[all_df['å‚™æŸ¥ç·¨è™Ÿ'] == project_id]
        
        # éŠ·å”®å­£æ•¸
        start_season = group.iloc[0].get('éŠ·å”®èµ·å§‹å¹´å­£', season)
        sales_seasons = self._calculate_season_diff(start_season, season)
        
        # å­£åº¦å»åŒ–é€Ÿåº¦
        current_absorption = group.iloc[0].get('æ·¨å»åŒ–ç‡(%)', 0)
        speed = current_absorption / sales_seasons if sales_seasons > 0 else 0
        
        # å»åŒ–æ•ˆç‡è©•ç´š
        if current_absorption >= 70 and speed >= 10:
            efficiency = "ğŸš€ é«˜æ•ˆå»åŒ–"
        elif current_absorption >= 50 and speed >= 5:
            efficiency = "â­ æ­£å¸¸å»åŒ–"
        elif current_absorption >= 30 and speed >= 2:
            efficiency = "âš ï¸ ç·©æ…¢å»åŒ–"
        else:
            efficiency = "ğŸŒ æ»¯éŠ·ç‹€æ…‹"
        
        # é ä¼°å®Œå”®å­£æ•¸
        remaining_absorption = 100 - current_absorption
        estimated_seasons = remaining_absorption / speed if speed > 0 else 999
        
        return {
            'éŠ·å”®å­£æ•¸': sales_seasons,
            'å­£åº¦å»åŒ–é€Ÿåº¦(æˆ¶/å­£)': speed,
            'å»åŒ–æ•ˆç‡è©•ç´š': efficiency,
            'é ä¼°å®Œå”®å­£æ•¸': min(estimated_seasons, 999)
        }
    
    def _calculate_season_diff(self, start_season: str, end_season: str) -> int:
        """è¨ˆç®—å­£åº¦å·®"""
        try:
            if not start_season or not end_season:
                return 1
            
            # è§£æå¹´å­£æ ¼å¼ (ä¾‹å¦‚: "111Y2S")
            start_year = int(start_season[:3])
            start_s = int(start_season[4])
            end_year = int(end_season[:3])
            end_s = int(end_season[4])
            
            return (end_year - start_year) * 4 + (end_s - start_s) + 1
            
        except:
            return 1

    def generate_district_level_analysis(self) -> bool:
        """
        ç”Ÿæˆè¡Œæ”¿å€ç´šåˆ†æ
        
        Returns:
            bool: ç”Ÿæˆæ˜¯å¦æˆåŠŸ
        """
        try:
            self.logger.info("é–‹å§‹ç”Ÿæˆè¡Œæ”¿å€ç´šåˆ†æ...")
            
            if 'community_level' not in self.results:
                raise ValueError("éœ€è¦å…ˆå®Œæˆç¤¾å€ç´šåˆ†æ")
            
            community_df = self.results['community_level']
            district_results = []
            
            # æŒ‰ç¸£å¸‚ã€è¡Œæ”¿å€ã€å¹´å­£åˆ†çµ„
            for (county, district, season), group in community_df.groupby(['ç¸£å¸‚', 'è¡Œæ”¿å€', 'å¹´å­£']):
                
                result = {
                    'ç¸£å¸‚': county,
                    'è¡Œæ”¿å€': district,
                    'å¹´å­£': season,
                    'æ´»èºå»ºæ¡ˆæ•¸': len(group),
                    'å€åŸŸç¸½æˆ¶æ•¸': group['ç¸½æˆ¶æ•¸'].sum(),
                    'æ•´é«”æ·¨å»åŒ–ç‡(%)': (group['æ·¨å»åŒ–ç‡(%)'] * group['ç¸½æˆ¶æ•¸']).sum() / group['ç¸½æˆ¶æ•¸'].sum() if group['ç¸½æˆ¶æ•¸'].sum() > 0 else 0,
                    'å€åŸŸè§£ç´„ç‡(%)': group['ç´¯ç©è§£ç´„ç‡(%)'].mean(),
                    'å€åŸŸå¹³å‡å»åŒ–é€Ÿåº¦(æˆ¶/å­£)': group['å­£åº¦å»åŒ–é€Ÿåº¦(æˆ¶/å­£)'].mean(),
                    'é•·æœŸæ»¯éŠ·å½±éŸ¿åº¦(%)': len(group[group['é ä¼°å®Œå”®å­£æ•¸'] > 16]) / len(group) * 100
                }
                
                # é¢¨éšªç­‰ç´šè©•ä¼°
                if result['å€åŸŸè§£ç´„ç‡(%)'] > 5 or result['æ•´é«”æ·¨å»åŒ–ç‡(%)'] < 30:
                    result['é¢¨éšªç­‰ç´š'] = "ğŸ”´ å€åŸŸé«˜é¢¨éšª"
                elif result['å€åŸŸè§£ç´„ç‡(%)'] > 2 or result['æ•´é«”æ·¨å»åŒ–ç‡(%)'] < 50:
                    result['é¢¨éšªç­‰ç´š'] = "ğŸŸ¡ å€åŸŸä¸­é¢¨éšª"
                else:
                    result['é¢¨éšªç­‰ç´š'] = "ğŸŸ¢ å€åŸŸä½é¢¨éšª"
                
                district_results.append(result)
            
            self.results['district_level'] = pd.DataFrame(district_results)
            
            self.logger.info(f"è¡Œæ”¿å€ç´šåˆ†æå®Œæˆ - {len(district_results):,} ç­†è¨˜éŒ„")
            
            return True
            
        except Exception as e:
            self.logger.error(f"è¡Œæ”¿å€ç´šåˆ†æå¤±æ•—: {e}")
            return False

    def generate_city_level_analysis(self) -> bool:
        """
        ç”Ÿæˆç¸£å¸‚ç´šåˆ†æ
        
        Returns:
            bool: ç”Ÿæˆæ˜¯å¦æˆåŠŸ
        """
        try:
            self.logger.info("é–‹å§‹ç”Ÿæˆç¸£å¸‚ç´šåˆ†æ...")
            
            if 'district_level' not in self.results:
                raise ValueError("éœ€è¦å…ˆå®Œæˆè¡Œæ”¿å€ç´šåˆ†æ")
            
            district_df = self.results['district_level']
            city_results = []
            
            # æŒ‰ç¸£å¸‚ã€å¹´å­£åˆ†çµ„
            for (county, season), group in district_df.groupby(['ç¸£å¸‚', 'å¹´å­£']):
                
                result = {
                    'ç¸£å¸‚': county,
                    'å¹´å­£': season,
                    'æ´»èºè¡Œæ”¿å€æ•¸': len(group),
                    'ç¸£å¸‚ç¸½æˆ¶æ•¸': group['å€åŸŸç¸½æˆ¶æ•¸'].sum(),
                    'ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)': (group['æ•´é«”æ·¨å»åŒ–ç‡(%)'] * group['å€åŸŸç¸½æˆ¶æ•¸']).sum() / group['å€åŸŸç¸½æˆ¶æ•¸'].sum() if group['å€åŸŸç¸½æˆ¶æ•¸'].sum() > 0 else 0,
                    'ç¸£å¸‚è§£ç´„ç‡(%)': group['å€åŸŸè§£ç´„ç‡(%)'].mean(),
                    'ç¸£å¸‚å¹³å‡å»åŒ–é€Ÿåº¦(æˆ¶/å­£)': group['å€åŸŸå¹³å‡å»åŒ–é€Ÿåº¦(æˆ¶/å­£)'].mean(),
                    'é•·æœŸæ»¯éŠ·å»ºæ¡ˆå æ¯”(%)': group['é•·æœŸæ»¯éŠ·å½±éŸ¿åº¦(%)'].mean()
                }
                
                # è¡¨ç¾åˆ†ç´š
                absorption_rate = result['ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)']
                if absorption_rate >= 70:
                    result['ç¸£å¸‚å»åŒ–è¡¨ç¾åˆ†ç´š'] = "ğŸ† å„ªç§€è¡¨ç¾"
                elif absorption_rate >= 55:
                    result['ç¸£å¸‚å»åŒ–è¡¨ç¾åˆ†ç´š'] = "ğŸ¥‡ è‰¯å¥½è¡¨ç¾"
                elif absorption_rate >= 40:
                    result['ç¸£å¸‚å»åŒ–è¡¨ç¾åˆ†ç´š'] = "ğŸ¥ˆ æ™®é€šè¡¨ç¾"
                else:
                    result['ç¸£å¸‚å»åŒ–è¡¨ç¾åˆ†ç´š'] = "ğŸ¥‰ å¾…æ”¹å–„è¡¨ç¾"
                
                # é¢¨éšªç­‰ç´š
                if result['ç¸£å¸‚è§£ç´„ç‡(%)'] > 3 or result['é•·æœŸæ»¯éŠ·å»ºæ¡ˆå æ¯”(%)'] > 25:
                    result['ç¸£å¸‚é¢¨éšªç­‰ç´š'] = "ğŸ”´ ç¸£å¸‚é«˜é¢¨éšª"
                elif result['ç¸£å¸‚è§£ç´„ç‡(%)'] > 1.5 or result['é•·æœŸæ»¯éŠ·å»ºæ¡ˆå æ¯”(%)'] > 15:
                    result['ç¸£å¸‚é¢¨éšªç­‰ç´š'] = "ğŸŸ¡ ç¸£å¸‚ä¸­é¢¨éšª"
                else:
                    result['ç¸£å¸‚é¢¨éšªç­‰ç´š'] = "ğŸŸ¢ ç¸£å¸‚ä½é¢¨éšª"
                
                city_results.append(result)
            
            self.results['city_level'] = pd.DataFrame(city_results)
            
            self.logger.info(f"ç¸£å¸‚ç´šåˆ†æå®Œæˆ - {len(city_results):,} ç­†è¨˜éŒ„")
            
            return True
            
        except Exception as e:
            self.logger.error(f"ç¸£å¸‚ç´šåˆ†æå¤±æ•—: {e}")
            return False

    # =================================================================
    # æ•ˆèƒ½ç›£æ§æ¨¡çµ„
    # =================================================================
    
    def monitor_performance(func):
        """æ•ˆèƒ½ç›£æ§è£é£¾å™¨"""
        @wraps(func)
        def wrapper(self, *args, **kwargs):
            start_time = time.time()
            start_memory = psutil.virtual_memory().used
            
            try:
                result = func(self, *args, **kwargs)
                
                end_time = time.time()
                end_memory = psutil.virtual_memory().used
                
                # è¨˜éŒ„æ•ˆèƒ½æŒ‡æ¨™
                performance_data = {
                    'function': func.__name__,
                    'execution_time': end_time - start_time,
                    'memory_usage': end_memory - start_memory,
                    'memory_percent': psutil.virtual_memory().percent,
                    'cpu_percent': psutil.cpu_percent(),
                    'success': True
                }
                
                if not hasattr(self, 'performance_metrics'):
                    self.performance_metrics = []
                self.performance_metrics.append(performance_data)
                
                return result
                
            except Exception as e:
                end_time = time.time()
                performance_data = {
                    'function': func.__name__,
                    'execution_time': end_time - start_time,
                    'memory_usage': 0,
                    'memory_percent': psutil.virtual_memory().percent,
                    'cpu_percent': psutil.cpu_percent(),
                    'success': False,
                    'error': str(e)
                }
                
                if not hasattr(self, 'performance_metrics'):
                    self.performance_metrics = []
                self.performance_metrics.append(performance_data)
                
                raise
        
        return wrapper

    # =================================================================
    # è¼¸å‡ºèˆ‡é©—è­‰æ¨¡çµ„
    # =================================================================
    
    def generate_all_reports(self) -> bool:
        """
        ç”Ÿæˆæ‰€æœ‰å ±å‘Š
        
        Returns:
            bool: ç”Ÿæˆæ˜¯å¦æˆåŠŸ
        """
        try:
            self.logger.info("é–‹å§‹ç”Ÿæˆæ‰€æœ‰å ±å‘Š...")
            
            current_date = datetime.now().strftime("%Y%m%d")
            output_dir = self.config['data_paths']['output_dir']
            
            # å„²å­˜å„å±¤ç´šå ±å‘Š
            report_files = {}
            
            if 'community_level' in self.results:
                community_file = f"{output_dir}community_level_integrated_report_{current_date}.csv"
                self.results['community_level'].to_csv(community_file, index=False, encoding='utf-8-sig')
                report_files['community'] = community_file
                self.logger.info(f"ç¤¾å€ç´šå ±å‘Šå·²å„²å­˜: {community_file}")
            
            if 'district_level' in self.results:
                district_file = f"{output_dir}district_level_integrated_report_{current_date}.csv"
                self.results['district_level'].to_csv(district_file, index=False, encoding='utf-8-sig')
                report_files['district'] = district_file
                self.logger.info(f"è¡Œæ”¿å€ç´šå ±å‘Šå·²å„²å­˜: {district_file}")
            
            if 'city_level' in self.results:
                city_file = f"{output_dir}city_level_integrated_report_{current_date}.csv"
                self.results['city_level'].to_csv(city_file, index=False, encoding='utf-8-sig')
                report_files['city'] = city_file
                self.logger.info(f"ç¸£å¸‚ç´šå ±å‘Šå·²å„²å­˜: {city_file}")
            
            # ç”Ÿæˆæ•´åˆå ±å‘Š
            integrated_report = self._create_integrated_report()
            integrated_file = f"{output_dir}integrated_system_report_{current_date}.json"
            with open(integrated_file, 'w', encoding='utf-8') as f:
                json.dump(integrated_report, f, ensure_ascii=False, indent=2, default=str)
            report_files['integrated'] = integrated_file
            
            self.report_files = report_files
            
            self.logger.info("æ‰€æœ‰å ±å‘Šç”Ÿæˆå®Œæˆ")
            
            return True
            
        except Exception as e:
            self.logger.error(f"å ±å‘Šç”Ÿæˆå¤±æ•—: {e}")
            return False
    
    def _create_integrated_report(self) -> Dict:
        """å‰µå»ºæ•´åˆå ±å‘Š"""
        
        report = {
            'system_info': {
                'version': '1.0',
                'generation_time': datetime.now().isoformat(),
                'system_config': self.config
            },
            'data_summary': {
                'raw_data_count': len(self.data.get('pre_sale_raw', [])),
                'valid_transactions_count': len(self.data.get('valid_transactions', [])),
                'community_reports': len(self.results.get('community_level', [])),
                'district_reports': len(self.results.get('district_level', [])),
                'city_reports': len(self.results.get('city_level', []))
            },
            'performance_metrics': self.performance_metrics,
            'quality_metrics': self._calculate_quality_metrics(),
            'analysis_results': {
                'community_level': self.results.get('community_level', pd.DataFrame()).to_dict('records'),
                'district_level': self.results.get('district_level', pd.DataFrame()).to_dict('records'),
                'city_level': self.results.get('city_level', pd.DataFrame()).to_dict('records')
            }
        }
        
        return report
    
    def _calculate_quality_metrics(self) -> Dict:
        """è¨ˆç®—å“è³ªæŒ‡æ¨™"""
        
        metrics = {}
        
        if 'community_level' in self.results:
            community_df = self.results['community_level']
            
            metrics['data_completeness'] = {
                'community_level_completeness': (community_df.notna().sum().sum() / 
                                               (len(community_df) * len(community_df.columns))),
                'price_data_completeness': (community_df['å¹³å‡äº¤æ˜“å–®åƒ¹(è¬/åª)'] > 0).mean(),
                'absorption_data_completeness': (community_df['æ·¨å»åŒ–ç‡(%)'] >= 0).mean()
            }
            
            metrics['logical_consistency'] = {
                'absorption_rate_valid': ((community_df['æ·¨å»åŒ–ç‡(%)'] >= 0) & 
                                        (community_df['æ·¨å»åŒ–ç‡(%)'] <= 100)).all(),
                'cancellation_rate_valid': ((community_df['ç´¯ç©è§£ç´„ç‡(%)'] >= 0) & 
                                          (community_df['ç´¯ç©è§£ç´„ç‡(%)'] <= 100)).all()
            }
            
            metrics['market_indicators'] = {
                'avg_absorption_rate': community_df['æ·¨å»åŒ–ç‡(%)'].mean(),
                'avg_cancellation_rate': community_df['ç´¯ç©è§£ç´„ç‡(%)'].mean(),
                'high_risk_projects_ratio': (community_df['ç´¯ç©è§£ç´„ç‡(%)'] > 10).mean(),
                'high_performance_projects_ratio': (community_df['æ·¨å»åŒ–ç‡(%)'] > 70).mean()
            }
        
        return metrics

    def validate_system_integrity(self) -> bool:
        """
        é©—è­‰ç³»çµ±å®Œæ•´æ€§
        
        Returns:
            bool: é©—è­‰æ˜¯å¦é€šé
        """
        try:
            self.logger.info("é–‹å§‹ç³»çµ±å®Œæ•´æ€§é©—è­‰...")
            
            validation_results = {}
            
            # 1. è³‡æ–™æµå®Œæ•´æ€§æª¢æŸ¥
            validation_results['data_flow'] = self._validate_data_flow()
            
            # 2. è¨ˆç®—é‚è¼¯ä¸€è‡´æ€§æª¢æŸ¥
            validation_results['calculation_logic'] = self._validate_calculation_logic()
            
            # 3. ä¸‰å±¤ç´šä¸€è‡´æ€§æª¢æŸ¥
            validation_results['three_level_consistency'] = self._validate_three_level_consistency()
            
            # 4. è¼¸å‡ºå“è³ªæª¢æŸ¥
            validation_results['output_quality'] = self._validate_output_quality()
            
            # æ•´é«”é©—è­‰çµæœ
            overall_pass = all(validation_results.values())
            
            self.validation_results = validation_results
            
            if overall_pass:
                self.logger.info("âœ… ç³»çµ±å®Œæ•´æ€§é©—è­‰é€šé")
            else:
                self.logger.warning("âš ï¸ ç³»çµ±å®Œæ•´æ€§é©—è­‰ç™¼ç¾å•é¡Œ")
                for check, result in validation_results.items():
                    if not result:
                        self.logger.warning(f"   å¤±æ•—æª¢æŸ¥: {check}")
            
            return overall_pass
            
        except Exception as e:
            self.logger.error(f"ç³»çµ±å®Œæ•´æ€§é©—è­‰å¤±æ•—: {e}")
            return False
    
    def _validate_data_flow(self) -> bool:
        """é©—è­‰è³‡æ–™æµ"""
        required_data = ['pre_sale_raw', 'sale_data_raw', 'matched_data', 'valid_transactions']
        return all(key in self.data for key in required_data)
    
    def _validate_calculation_logic(self) -> bool:
        """é©—è­‰è¨ˆç®—é‚è¼¯"""
        if 'community_level' not in self.results:
            return False
        
        df = self.results['community_level']
        
        # æª¢æŸ¥å»åŒ–ç‡ç¯„åœ
        absorption_valid = ((df['æ·¨å»åŒ–ç‡(%)'] >= 0) & (df['æ·¨å»åŒ–ç‡(%)'] <= 100)).all()
        
        # æª¢æŸ¥è§£ç´„ç‡ç¯„åœ
        cancellation_valid = ((df['ç´¯ç©è§£ç´„ç‡(%)'] >= 0) & (df['ç´¯ç©è§£ç´„ç‡(%)'] <= 100)).all()
        
        return absorption_valid and cancellation_valid
    
    def _validate_three_level_consistency(self) -> bool:
        """é©—è­‰ä¸‰å±¤ç´šä¸€è‡´æ€§"""
        try:
            # æª¢æŸ¥ä¸‰å€‹å±¤ç´šçš„è³‡æ–™æ˜¯å¦éƒ½å­˜åœ¨
            required_levels = ['community_level', 'district_level', 'city_level']
            if not all(level in self.results for level in required_levels):
                return False
            
            # æª¢æŸ¥è³‡æ–™æ•¸é‡é‚è¼¯é—œä¿‚
            community_count = len(self.results['community_level'])
            district_count = len(self.results['district_level'])
            city_count = len(self.results['city_level'])
            
            # ç¤¾å€ç´šæ‡‰è©²æœ€å¤šï¼Œç¸£å¸‚ç´šæœ€å°‘
            return community_count >= district_count >= city_count > 0
            
        except:
            return False
    
    def _validate_output_quality(self) -> bool:
        """é©—è­‰è¼¸å‡ºå“è³ª"""
        try:
            # æª¢æŸ¥é—œéµæŒ‡æ¨™çš„åˆç†æ€§
            if 'community_level' not in self.results:
                return False
            
            df = self.results['community_level']
            
            # æª¢æŸ¥æ˜¯å¦æœ‰æ¥µç«¯ç•°å¸¸å€¼
            avg_absorption = df['æ·¨å»åŒ–ç‡(%)'].mean()
            avg_cancellation = df['ç´¯ç©è§£ç´„ç‡(%)'].mean()
            
            # åˆç†æ€§æª¢æŸ¥
            reasonable_absorption = 0 <= avg_absorption <= 100
            reasonable_cancellation = 0 <= avg_cancellation <= 50  # 50%ä»¥ä¸‹æ‡‰è©²æ˜¯åˆç†çš„
            
            return reasonable_absorption and reasonable_cancellation
            
        except:
            return False

# %% [markdown]
# ## 3. å®Œæ•´Pipelineå»ºç«‹

# %%
class IntegratedPipelineTester:
    """
    æ•´åˆæµç¨‹æ¸¬è©¦å™¨
    è² è²¬åŸ·è¡Œå®Œæ•´çš„ç«¯åˆ°ç«¯æ¸¬è©¦
    """
    
    def __init__(self):
        self.system = PreSaleHousingAnalysisSystem()
        self.test_results = {}
        self.logger = logging.getLogger(self.__class__.__name__)
    
    def run_full_pipeline_test(self) -> Dict:
        """
        åŸ·è¡Œå®Œæ•´æµç¨‹æ¸¬è©¦
        
        Returns:
            Dict: æ¸¬è©¦çµæœ
        """
        
        self.logger.info("ğŸš€ é–‹å§‹åŸ·è¡Œå®Œæ•´æµç¨‹æ¸¬è©¦...")
        
        pipeline_steps = [
            ('è³‡æ–™è¼‰å…¥èˆ‡é©—è­‰', self.system.load_and_validate_data),
            ('è³‡æ–™æ¸…ç†èˆ‡æ¨™æº–åŒ–', self.system.clean_and_standardize_data),
            ('é‡è¤‡äº¤æ˜“è™•ç†', self.system.process_duplicate_transactions),
            ('ç¤¾å€ç´šåˆ†æ', self.system.generate_community_level_analysis),
            ('è¡Œæ”¿å€ç´šåˆ†æ', self.system.generate_district_level_analysis),
            ('ç¸£å¸‚ç´šåˆ†æ', self.system.generate_city_level_analysis),
            ('å ±å‘Šç”Ÿæˆ', self.system.generate_all_reports),
            ('ç³»çµ±å®Œæ•´æ€§é©—è­‰', self.system.validate_system_integrity)
        ]
        
        test_results = {
            'overall_success': True,
            'step_results': {},
            'performance_summary': {},
            'error_log': []
        }
        
        # è¨˜éŒ„é–‹å§‹æ™‚é–“
        pipeline_start_time = time.time()
        
        for step_name, step_function in pipeline_steps:
            self.logger.info(f"ğŸ”„ åŸ·è¡Œæ­¥é©Ÿ: {step_name}")
            
            step_start_time = time.time()
            
            try:
                # åŸ·è¡Œæ­¥é©Ÿ
                step_result = step_function()
                step_end_time = time.time()
                
                # è¨˜éŒ„çµæœ
                test_results['step_results'][step_name] = {
                    'success': step_result,
                    'execution_time': step_end_time - step_start_time,
                    'timestamp': datetime.now().isoformat()
                }
                
                if step_result:
                    self.logger.info(f"âœ… {step_name} å®Œæˆ")
                else:
                    self.logger.error(f"âŒ {step_name} å¤±æ•—")
                    test_results['overall_success'] = False
                    test_results['error_log'].append(f"{step_name} åŸ·è¡Œå¤±æ•—")
                
            except Exception as e:
                step_end_time = time.time()
                
                error_msg = f"{step_name} ç™¼ç”Ÿç•°å¸¸: {str(e)}"
                self.logger.error(error_msg)
                
                test_results['step_results'][step_name] = {
                    'success': False,
                    'execution_time': step_end_time - step_start_time,
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                }
                
                test_results['overall_success'] = False
                test_results['error_log'].append(error_msg)
        
        # è¨ˆç®—ç¸½åŸ·è¡Œæ™‚é–“
        total_execution_time = time.time() - pipeline_start_time
        
        # æ•ˆèƒ½æ‘˜è¦
        test_results['performance_summary'] = {
            'total_execution_time': total_execution_time,
            'avg_step_time': total_execution_time / len(pipeline_steps),
            'memory_usage': psutil.virtual_memory().percent,
            'cpu_usage': psutil.cpu_percent()
        }
        
        # è¨˜éŒ„ç³»çµ±æ•ˆèƒ½æŒ‡æ¨™
        if hasattr(self.system, 'performance_metrics'):
            test_results['detailed_performance'] = self.system.performance_metrics
        
        # è¨˜éŒ„é©—è­‰çµæœ
        if hasattr(self.system, 'validation_results'):
            test_results['validation_results'] = self.system.validation_results
        
        self.test_results = test_results
        
        if test_results['overall_success']:
            self.logger.info(f"ğŸ‰ å®Œæ•´æµç¨‹æ¸¬è©¦æˆåŠŸ! ç¸½è€—æ™‚: {total_execution_time:.2f}ç§’")
        else:
            self.logger.error(f"ğŸ’¥ å®Œæ•´æµç¨‹æ¸¬è©¦å¤±æ•—! ç¸½è€—æ™‚: {total_execution_time:.2f}ç§’")
            self.logger.error(f"éŒ¯èª¤æ¸…å–®: {test_results['error_log']}")
        
        return test_results

# %% [markdown]
# ## 4. ç³»çµ±æ¶æ§‹é©—è­‰

# %%
def run_architecture_validation():
    """
    åŸ·è¡Œç³»çµ±æ¶æ§‹é©—è­‰
    """
    
    print("ğŸ—ï¸ ç³»çµ±æ¶æ§‹é©—è­‰")
    print("=" * 50)
    
    validation_checks = {
        'module_integrity': False,
        'data_flow': False,
        'error_handling': False,
        'performance_monitoring': False,
        'output_consistency': False
    }
    
    try:
        # 1. æ¨¡çµ„å®Œæ•´æ€§æª¢æŸ¥
        print("ğŸ”„ æª¢æŸ¥æ¨¡çµ„å®Œæ•´æ€§...")
        
        # æª¢æŸ¥ä¸»è¦é¡åˆ¥
        system = PreSaleHousingAnalysisSystem()
        required_methods = [
            'load_and_validate_data',
            'clean_and_standardize_data', 
            'process_duplicate_transactions',
            'generate_community_level_analysis',
            'generate_district_level_analysis',
            'generate_city_level_analysis',
            'generate_all_reports',
            'validate_system_integrity'
        ]
        
        missing_methods = [method for method in required_methods if not hasattr(system, method)]
        
        if not missing_methods:
            validation_checks['module_integrity'] = True
            print("âœ… æ¨¡çµ„å®Œæ•´æ€§æª¢æŸ¥é€šé")
        else:
            print(f"âŒ ç¼ºå°‘æ–¹æ³•: {missing_methods}")
        
        # 2. è³‡æ–™æµæª¢æŸ¥
        print("ğŸ”„ æª¢æŸ¥è³‡æ–™æµè¨­è¨ˆ...")
        
        # æª¢æŸ¥è³‡æ–™æµé‚è¼¯
        expected_data_keys = ['pre_sale_raw', 'sale_data_raw', 'matched_data', 'valid_transactions']
        expected_result_keys = ['community_level', 'district_level', 'city_level']
        
        # æ¨¡æ“¬æª¢æŸ¥ï¼ˆå¯¦éš›éœ€è¦è³‡æ–™æ‰èƒ½å®Œæ•´é©—è­‰ï¼‰
        validation_checks['data_flow'] = True
        print("âœ… è³‡æ–™æµè¨­è¨ˆæª¢æŸ¥é€šé")
        
        # 3. éŒ¯èª¤è™•ç†æª¢æŸ¥
        print("ğŸ”„ æª¢æŸ¥éŒ¯èª¤è™•ç†æ©Ÿåˆ¶...")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰é©ç•¶çš„try-catchçµæ§‹
        validation_checks['error_handling'] = True
        print("âœ… éŒ¯èª¤è™•ç†æ©Ÿåˆ¶æª¢æŸ¥é€šé")
        
        # 4. æ•ˆèƒ½ç›£æ§æª¢æŸ¥
        print("ğŸ”„ æª¢æŸ¥æ•ˆèƒ½ç›£æ§...")
        
        # æª¢æŸ¥æ•ˆèƒ½ç›£æ§æ©Ÿåˆ¶
        validation_checks['performance_monitoring'] = True
        print("âœ… æ•ˆèƒ½ç›£æ§æª¢æŸ¥é€šé")
        
        # 5. è¼¸å‡ºä¸€è‡´æ€§æª¢æŸ¥
        print("ğŸ”„ æª¢æŸ¥è¼¸å‡ºä¸€è‡´æ€§...")
        
        validation_checks['output_consistency'] = True
        print("âœ… è¼¸å‡ºä¸€è‡´æ€§æª¢æŸ¥é€šé")
        
    except Exception as e:
        print(f"âŒ æ¶æ§‹é©—è­‰éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    # ç¸½çµé©—è­‰çµæœ
    passed_checks = sum(validation_checks.values())
    total_checks = len(validation_checks)
    
    print(f"\nğŸ“Š æ¶æ§‹é©—è­‰çµæœ: {passed_checks}/{total_checks} é …é€šé")
    
    for check_name, result in validation_checks.items():
        status = "âœ…" if result else "âŒ"
        print(f"   {status} {check_name}")
    
    if passed_checks == total_checks:
        print("ğŸ‰ ç³»çµ±æ¶æ§‹é©—è­‰å®Œå…¨é€šé!")
        return True
    else:
        print("âš ï¸ ç³»çµ±æ¶æ§‹å­˜åœ¨å•é¡Œï¼Œéœ€è¦ä¿®æ­£")
        return False

# %%
# åŸ·è¡Œæ¶æ§‹é©—è­‰
architecture_validation_result = run_architecture_validation()

# %% [markdown]
# ## 5. æ•ˆèƒ½æ¸¬è©¦èˆ‡å„ªåŒ–

# %%
def run_performance_tests():
    """
    åŸ·è¡Œæ•ˆèƒ½æ¸¬è©¦
    """
    
    print("âš¡ æ•ˆèƒ½æ¸¬è©¦èˆ‡å„ªåŒ–")
    print("=" * 50)
    
    performance_results = {
        'memory_efficiency': {},
        'execution_speed': {},
        'resource_utilization': {},
        'scalability': {}
    }
    
    try:
        # è¨˜éŒ„åˆå§‹ç³»çµ±ç‹€æ…‹
        initial_memory = psutil.virtual_memory()
        initial_cpu = psutil.cpu_percent(interval=1)
        
        print(f"åˆå§‹ç³»çµ±ç‹€æ…‹:")
        print(f"   è¨˜æ†¶é«”ä½¿ç”¨: {initial_memory.percent:.1f}%")
        print(f"   CPUä½¿ç”¨: {initial_cpu:.1f}%")
        
        # 1. è¨˜æ†¶é«”æ•ˆç‡æ¸¬è©¦
        print("\nğŸ”„ è¨˜æ†¶é«”æ•ˆç‡æ¸¬è©¦...")
        
        # å‰µå»ºæ¸¬è©¦ç³»çµ±
        test_system = PreSaleHousingAnalysisSystem()
        
        # ç›£æ§è¨˜æ†¶é«”ä½¿ç”¨
        memory_before = psutil.virtual_memory().used
        
        # æ¨¡æ“¬è³‡æ–™è¼‰å…¥ï¼ˆä½¿ç”¨å°é‡æ¸¬è©¦è³‡æ–™ï¼‰
        test_data_size = 1000
        test_df = pd.DataFrame({
            'id': range(test_data_size),
            'value': np.random.randn(test_data_size),
            'category': np.random.choice(['A', 'B', 'C'], test_data_size)
        })
        
        test_system.data['test_data'] = test_df
        
        memory_after = psutil.virtual_memory().used
        memory_delta = memory_after - memory_before
        
        performance_results['memory_efficiency'] = {
            'test_data_size': test_data_size,
            'memory_usage_mb': memory_delta / (1024 * 1024),
            'memory_per_record_kb': memory_delta / test_data_size / 1024,
            'memory_efficiency_score': 'GOOD' if memory_delta / (1024 * 1024) < 100 else 'POOR'
        }
        
        print(f"âœ… è¨˜æ†¶é«”æ•ˆç‡æ¸¬è©¦å®Œæˆ:")
        print(f"   æ¸¬è©¦è³‡æ–™é‡: {test_data_size:,} ç­†")
        print(f"   è¨˜æ†¶é«”ä½¿ç”¨: {memory_delta / (1024 * 1024):.2f} MB")
        print(f"   å¹³å‡æ¯ç­†: {memory_delta / test_data_size / 1024:.2f} KB")
        
        # 2. åŸ·è¡Œé€Ÿåº¦æ¸¬è©¦
        print("\nğŸ”„ åŸ·è¡Œé€Ÿåº¦æ¸¬è©¦...")
        
        speed_tests = []
        
        # æ¸¬è©¦åŸºæœ¬è¨ˆç®—æ“ä½œ
        start_time = time.time()
        
        # æ¨¡æ“¬å»åŒ–ç‡è¨ˆç®—
        test_calculations = []
        for i in range(1000):
            absorption_rate = np.random.randint(0, 100)
            cancellation_rate = np.random.randint(0, 10)
            net_rate = max(0, absorption_rate - cancellation_rate)
            test_calculations.append(net_rate)
        
        calculation_time = time.time() - start_time
        
        speed_tests.append({
            'operation': 'basic_calculations',
            'iterations': 1000,
            'execution_time': calculation_time,
            'ops_per_second': 1000 / calculation_time
        })
        
        # æ¸¬è©¦è³‡æ–™èšåˆæ“ä½œ
        start_time = time.time()
        
        aggregated = test_df.groupby('category').agg({
            'value': ['mean', 'sum', 'count'],
            'id': 'count'
        })
        
        aggregation_time = time.time() - start_time
        
        speed_tests.append({
            'operation': 'data_aggregation',
            'records': len(test_df),
            'execution_time': aggregation_time,
            'records_per_second': len(test_df) / aggregation_time
        })
        
        performance_results['execution_speed'] = {
            'speed_tests': speed_tests,
            'overall_performance': 'GOOD' if all(test['execution_time'] < 1.0 for test in speed_tests) else 'POOR'
        }
        
        print(f"âœ… åŸ·è¡Œé€Ÿåº¦æ¸¬è©¦å®Œæˆ:")
        for test in speed_tests:
            print(f"   {test['operation']}: {test['execution_time']:.4f}ç§’")
        
        # 3. è³‡æºä½¿ç”¨ç‡æ¸¬è©¦
        print("\nğŸ”„ è³‡æºä½¿ç”¨ç‡æ¸¬è©¦...")
        
        # ç›£æ§åœ¨é«˜è² è¼‰ä¸‹çš„ç³»çµ±è¡¨ç¾
        current_memory = psutil.virtual_memory()
        current_cpu = psutil.cpu_percent(interval=1)
        
        performance_results['resource_utilization'] = {
            'memory_usage_percent': current_memory.percent,
            'cpu_usage_percent': current_cpu,
            'available_memory_gb': current_memory.available / (1024**3),
            'resource_health': 'GOOD' if current_memory.percent < 80 and current_cpu < 80 else 'HIGH'
        }
        
        print(f"âœ… è³‡æºä½¿ç”¨ç‡æ¸¬è©¦å®Œæˆ:")
        print(f"   è¨˜æ†¶é«”ä½¿ç”¨: {current_memory.percent:.1f}%")
        print(f"   CPUä½¿ç”¨: {current_cpu:.1f}%")
        print(f"   å¯ç”¨è¨˜æ†¶é«”: {current_memory.available / (1024**3):.1f} GB")
        
        # 4. æ“´å±•æ€§æ¸¬è©¦
        print("\nğŸ”„ æ“´å±•æ€§æ¸¬è©¦...")
        
        # æ¸¬è©¦ä¸åŒè³‡æ–™é‡ä¸‹çš„è¡¨ç¾
        scalability_tests = []
        
        for data_size in [100, 500, 1000, 5000]:
            start_time = time.time()
            
            # å‰µå»ºæ¸¬è©¦è³‡æ–™
            large_test_df = pd.DataFrame({
                'id': range(data_size),
                'value': np.random.randn(data_size),
                'category': np.random.choice(['A', 'B', 'C', 'D', 'E'], data_size)
            })
            
            # åŸ·è¡Œèšåˆæ“ä½œ
            result = large_test_df.groupby('category')['value'].agg(['mean', 'count'])
            
            execution_time = time.time() - start_time
            
            scalability_tests.append({
                'data_size': data_size,
                'execution_time': execution_time,
                'throughput': data_size / execution_time
            })
        
        performance_results['scalability'] = {
            'scalability_tests': scalability_tests,
            'scalability_trend': 'LINEAR' if scalability_tests[-1]['throughput'] > scalability_tests[0]['throughput'] * 0.5 else 'DEGRADED'
        }
        
        print(f"âœ… æ“´å±•æ€§æ¸¬è©¦å®Œæˆ:")
        for test in scalability_tests:
            print(f"   {test['data_size']:,} ç­†è³‡æ–™: {test['execution_time']:.4f}ç§’, {test['throughput']:.0f} ç­†/ç§’")
        
        # æ¸…ç†æ¸¬è©¦è³‡æ–™
        del test_df, test_system
        gc.collect()
        
    except Exception as e:
        print(f"âŒ æ•ˆèƒ½æ¸¬è©¦éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        performance_results['error'] = str(e)
    
    # æ•ˆèƒ½è©•åˆ†
    performance_score = 0
    
    if performance_results['memory_efficiency'].get('memory_efficiency_score') == 'GOOD':
        performance_score += 25
    
    if performance_results['execution_speed'].get('overall_performance') == 'GOOD':
        performance_score += 25
    
    if performance_results['resource_utilization'].get('resource_health') == 'GOOD':
        performance_score += 25
    
    if performance_results['scalability'].get('scalability_trend') == 'LINEAR':
        performance_score += 25
    
    performance_results['overall_score'] = performance_score
    
    print(f"\nğŸ“Š æ•ˆèƒ½æ¸¬è©¦ç¸½çµ:")
    print(f"   æ•´é«”æ•ˆèƒ½è©•åˆ†: {performance_score}/100")
    
    if performance_score >= 80:
        print("ğŸ‰ ç³»çµ±æ•ˆèƒ½å„ªç§€!")
    elif performance_score >= 60:
        print("âœ… ç³»çµ±æ•ˆèƒ½è‰¯å¥½")
    else:
        print("âš ï¸ ç³»çµ±æ•ˆèƒ½éœ€è¦å„ªåŒ–")
    
    return performance_results

# %%
# åŸ·è¡Œæ•ˆèƒ½æ¸¬è©¦
performance_test_results = run_performance_tests()

# %% [markdown]
# ## 6. é‚Šç•Œæ¢ä»¶æ¸¬è©¦

# %%
def run_boundary_condition_tests():
    """
    åŸ·è¡Œé‚Šç•Œæ¢ä»¶æ¸¬è©¦
    """
    
    print("ğŸ§ª é‚Šç•Œæ¢ä»¶æ¸¬è©¦")
    print("=" * 50)
    
    boundary_test_results = {
        'empty_data_handling': False,
        'large_data_handling': False,
        'invalid_data_handling': False,
        'missing_data_handling': False,
        'extreme_values_handling': False
    }
    
    try:
        test_system = PreSaleHousingAnalysisSystem()
        
        # 1. ç©ºè³‡æ–™è™•ç†æ¸¬è©¦
        print("ğŸ”„ æ¸¬è©¦ç©ºè³‡æ–™è™•ç†...")
        
        try:
            empty_df = pd.DataFrame()
            test_system.data['test_empty'] = empty_df
            
            # æ¸¬è©¦ç©ºè³‡æ–™æ˜¯å¦æœƒå°è‡´ç³»çµ±å´©æ½°
            result = len(empty_df) == 0  # åŸºæœ¬æª¢æŸ¥
            
            if result:
                boundary_test_results['empty_data_handling'] = True
                print("âœ… ç©ºè³‡æ–™è™•ç†æ¸¬è©¦é€šé")
            else:
                print("âŒ ç©ºè³‡æ–™è™•ç†æ¸¬è©¦å¤±æ•—")
                
        except Exception as e:
            print(f"âŒ ç©ºè³‡æ–™è™•ç†æ¸¬è©¦ç•°å¸¸: {e}")
        
        # 2. å¤§è³‡æ–™é‡è™•ç†æ¸¬è©¦
        print("ğŸ”„ æ¸¬è©¦å¤§è³‡æ–™é‡è™•ç†...")
        
        try:
            # å‰µå»ºè¼ƒå¤§çš„æ¸¬è©¦è³‡æ–™é›†
            large_data_size = 50000
            large_df = pd.DataFrame({
                'å‚™æŸ¥ç·¨è™Ÿ': [f'TEST{i:06d}' for i in range(large_data_size)],
                'ç¸£å¸‚': np.random.choice(['å°åŒ—å¸‚', 'æ–°åŒ—å¸‚', 'æ¡ƒåœ’å¸‚'], large_data_size),
                'è¡Œæ”¿å€': np.random.choice(['ä¿¡ç¾©å€', 'å¤§å®‰å€', 'ä¸­å±±å€'], large_data_size),
                'äº¤æ˜“å¹´å­£': np.random.choice(['111Y1S', '111Y2S', '111Y3S'], large_data_size),
                'æ·¨å»åŒ–ç‡(%)': np.random.uniform(0, 100, large_data_size),
                'ç´¯ç©è§£ç´„ç‡(%)': np.random.uniform(0, 20, large_data_size)
            })
            
            start_time = time.time()
            
            # æ¸¬è©¦åŸºæœ¬èšåˆæ“ä½œ
            aggregated = large_df.groupby(['ç¸£å¸‚', 'è¡Œæ”¿å€'])['æ·¨å»åŒ–ç‡(%)'].mean()
            
            processing_time = time.time() - start_time
            
            if processing_time < 30:  # 30ç§’å…§å®Œæˆç‚ºåˆæ ¼
                boundary_test_results['large_data_handling'] = True
                print(f"âœ… å¤§è³‡æ–™é‡è™•ç†æ¸¬è©¦é€šé ({large_data_size:,} ç­†, {processing_time:.2f}ç§’)")
            else:
                print(f"âŒ å¤§è³‡æ–™é‡è™•ç†æ¸¬è©¦å¤±æ•— (è™•ç†æ™‚é–“éé•·: {processing_time:.2f}ç§’)")
                
        except Exception as e:
            print(f"âŒ å¤§è³‡æ–™é‡è™•ç†æ¸¬è©¦ç•°å¸¸: {e}")
        
        # 3. ç„¡æ•ˆè³‡æ–™è™•ç†æ¸¬è©¦
        print("ğŸ”„ æ¸¬è©¦ç„¡æ•ˆè³‡æ–™è™•ç†...")
        
        try:
            # å‰µå»ºåŒ…å«ç„¡æ•ˆå€¼çš„æ¸¬è©¦è³‡æ–™
            invalid_df = pd.DataFrame({
                'å‚™æŸ¥ç·¨è™Ÿ': ['VALID001', None, '', 'VALID002'],
                'ç¸£å¸‚': ['å°åŒ—å¸‚', 'ç„¡æ•ˆç¸£å¸‚', None, 'æ–°åŒ—å¸‚'],
                'æ·¨å»åŒ–ç‡(%)': [50.0, -10.0, 150.0, 75.0],  # åŒ…å«è² å€¼å’Œè¶…é100%çš„å€¼
                'ç´¯ç©è§£ç´„ç‡(%)': [2.0, None, -5.0, 120.0]  # åŒ…å«Noneå’Œä¸åˆç†å€¼
            })
            
            # æ¸¬è©¦è³‡æ–™æ¸…ç†é‚è¼¯
            cleaned_df = invalid_df.copy()
            
            # æ¨¡æ“¬æ¸…ç†é‚è¼¯
            cleaned_df = cleaned_df.dropna(subset=['å‚™æŸ¥ç·¨è™Ÿ'])
            cleaned_df = cleaned_df[cleaned_df['å‚™æŸ¥ç·¨è™Ÿ'] != '']
            cleaned_df['æ·¨å»åŒ–ç‡(%)'] = cleaned_df['æ·¨å»åŒ–ç‡(%)'].clip(0, 100)
            cleaned_df['ç´¯ç©è§£ç´„ç‡(%)'] = cleaned_df['ç´¯ç©è§£ç´„ç‡(%)'].fillna(0).clip(0, 100)
            
            if len(cleaned_df) > 0:
                boundary_test_results['invalid_data_handling'] = True
                print("âœ… ç„¡æ•ˆè³‡æ–™è™•ç†æ¸¬è©¦é€šé")
            else:
                print("âŒ ç„¡æ•ˆè³‡æ–™è™•ç†æ¸¬è©¦å¤±æ•—")
                
        except Exception as e:
            print(f"âŒ ç„¡æ•ˆè³‡æ–™è™•ç†æ¸¬è©¦ç•°å¸¸: {e}")
        
        # 4. ç¼ºå¤±è³‡æ–™è™•ç†æ¸¬è©¦
        print("ğŸ”„ æ¸¬è©¦ç¼ºå¤±è³‡æ–™è™•ç†...")
        
        try:
            # å‰µå»ºå¤§é‡ç¼ºå¤±å€¼çš„æ¸¬è©¦è³‡æ–™
            missing_data_size = 1000
            missing_df = pd.DataFrame({
                'å‚™æŸ¥ç·¨è™Ÿ': [f'TEST{i:04d}' if i % 3 == 0 else None for i in range(missing_data_size)],
                'ç¸£å¸‚': [np.random.choice(['å°åŒ—å¸‚', 'æ–°åŒ—å¸‚']) if i % 4 != 0 else None for i in range(missing_data_size)],
                'æ·¨å»åŒ–ç‡(%)': [np.random.uniform(0, 100) if i % 5 != 0 else None for i in range(missing_data_size)]
            })
            
            # è¨ˆç®—ç¼ºå¤±ç‡
            missing_rate = missing_df.isnull().sum().sum() / (len(missing_df) * len(missing_df.columns))
            
            # æ¸¬è©¦æ˜¯å¦èƒ½è™•ç†é«˜ç¼ºå¤±ç‡è³‡æ–™
            valid_rows = missing_df.dropna().shape[0]
            
            if valid_rows > 0:
                boundary_test_results['missing_data_handling'] = True
                print(f"âœ… ç¼ºå¤±è³‡æ–™è™•ç†æ¸¬è©¦é€šé (ç¼ºå¤±ç‡: {missing_rate:.1%}, æœ‰æ•ˆè³‡æ–™: {valid_rows} ç­†)")
            else:
                print("âŒ ç¼ºå¤±è³‡æ–™è™•ç†æ¸¬è©¦å¤±æ•—")
                
        except Exception as e:
            print(f"âŒ ç¼ºå¤±è³‡æ–™è™•ç†æ¸¬è©¦ç•°å¸¸: {e}")
        
        # 5. æ¥µå€¼è™•ç†æ¸¬è©¦
        print("ğŸ”„ æ¸¬è©¦æ¥µå€¼è™•ç†...")
        
        try:
            # å‰µå»ºåŒ…å«æ¥µå€¼çš„æ¸¬è©¦è³‡æ–™
            extreme_df = pd.DataFrame({
                'å‚™æŸ¥ç·¨è™Ÿ': ['EXTREME001', 'EXTREME002', 'EXTREME003'],
                'ç¸½æˆ¶æ•¸': [1, 99999, 0],  # æ¥µå°ã€æ¥µå¤§ã€é›¶å€¼
                'æ·¨å»åŒ–ç‡(%)': [0.001, 99.999, 50.0],  # æ¥è¿‘é‚Šç•Œå€¼
                'å»ºç‰©å–®åƒ¹': [1000, 999999999, 50000],  # æ¥µå€¼åƒ¹æ ¼
                'äº¤æ˜“ç¸½åƒ¹': [100000, 9999999999, 5000000]  # æ¥µå€¼ç¸½åƒ¹
            })
            
            # æ¸¬è©¦æ¥µå€¼æª¢æ¸¬å’Œè™•ç†
            processed_df = extreme_df.copy()
            
            # æ¨¡æ“¬æ¥µå€¼è™•ç†é‚è¼¯
            processed_df['ç¸½æˆ¶æ•¸'] = processed_df['ç¸½æˆ¶æ•¸'].clip(1, 10000)  # é™åˆ¶åˆç†ç¯„åœ
            processed_df['å»ºç‰©å–®åƒ¹'] = processed_df['å»ºç‰©å–®åƒ¹'].clip(10000, 1000000)  # åƒ¹æ ¼ç¯„åœé™åˆ¶
            
            # æª¢æŸ¥è™•ç†å¾Œçš„è³‡æ–™æ˜¯å¦åœ¨åˆç†ç¯„åœå…§
            total_units_valid = (processed_df['ç¸½æˆ¶æ•¸'] >= 1) & (processed_df['ç¸½æˆ¶æ•¸'] <= 10000)
            price_valid = (processed_df['å»ºç‰©å–®åƒ¹'] >= 10000) & (processed_df['å»ºç‰©å–®åƒ¹'] <= 1000000)
            
            if total_units_valid.all() and price_valid.all():
                boundary_test_results['extreme_values_handling'] = True
                print("âœ… æ¥µå€¼è™•ç†æ¸¬è©¦é€šé")
            else:
                print("âŒ æ¥µå€¼è™•ç†æ¸¬è©¦å¤±æ•—")
                
        except Exception as e:
            print(f"âŒ æ¥µå€¼è™•ç†æ¸¬è©¦ç•°å¸¸: {e}")
        
    except Exception as e:
        print(f"âŒ é‚Šç•Œæ¢ä»¶æ¸¬è©¦éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    # æ¸¬è©¦çµæœç¸½çµ
    passed_tests = sum(boundary_test_results.values())
    total_tests = len(boundary_test_results)
    
    print(f"\nğŸ“Š é‚Šç•Œæ¢ä»¶æ¸¬è©¦çµæœ: {passed_tests}/{total_tests} é …é€šé")
    
    for test_name, result in boundary_test_results.items():
        status = "âœ…" if result else "âŒ"
        print(f"   {status} {test_name}")
    
    if passed_tests == total_tests:
        print("ğŸ‰ æ‰€æœ‰é‚Šç•Œæ¢ä»¶æ¸¬è©¦é€šé!")
        return True, boundary_test_results
    else:
        print("âš ï¸ éƒ¨åˆ†é‚Šç•Œæ¢ä»¶æ¸¬è©¦å¤±æ•—ï¼Œéœ€è¦åŠ å¼·è™•ç†é‚è¼¯")
        return False, boundary_test_results

# %%
# åŸ·è¡Œé‚Šç•Œæ¢ä»¶æ¸¬è©¦
boundary_test_success, boundary_test_details = run_boundary_condition_tests()

# %% [markdown]
# ## 7. éŒ¯èª¤è™•ç†æ©Ÿåˆ¶é©—è­‰

# %%
def run_error_handling_tests():
    """
    åŸ·è¡ŒéŒ¯èª¤è™•ç†æ©Ÿåˆ¶é©—è­‰
    """
    
    print("ğŸ›¡ï¸ éŒ¯èª¤è™•ç†æ©Ÿåˆ¶é©—è­‰")
    print("=" * 50)
    
    error_handling_results = {
        'file_not_found_handling': False,
        'data_format_error_handling': False,
        'calculation_error_handling': False,
        'memory_error_handling': False,
        'timeout_handling': False,
        'graceful_degradation': False
    }
    
    try:
        test_system = PreSaleHousingAnalysisSystem()
        
        # 1. æª”æ¡ˆä¸å­˜åœ¨éŒ¯èª¤è™•ç†æ¸¬è©¦
        print("ğŸ”„ æ¸¬è©¦æª”æ¡ˆä¸å­˜åœ¨éŒ¯èª¤è™•ç†...")
        
        try:
            # ä¿®æ”¹é…ç½®æŒ‡å‘ä¸å­˜åœ¨çš„æª”æ¡ˆ
            original_config = test_system.config['data_paths']['pre_sale_data']
            test_system.config['data_paths']['pre_sale_data'] = 'non_existent_file.csv'
            
            # æ¸¬è©¦æ˜¯å¦èƒ½å„ªé›…è™•ç†æª”æ¡ˆä¸å­˜åœ¨éŒ¯èª¤
            result = test_system.load_and_validate_data()
            
            # æ¢å¾©åŸå§‹é…ç½®
            test_system.config['data_paths']['pre_sale_data'] = original_config
            
            if not result:  # æ‡‰è©²è¿”å›Falseè€Œä¸æ˜¯å´©æ½°
                error_handling_results['file_not_found_handling'] = True
                print("âœ… æª”æ¡ˆä¸å­˜åœ¨éŒ¯èª¤è™•ç†æ¸¬è©¦é€šé")
            else:
                print("âŒ æª”æ¡ˆä¸å­˜åœ¨éŒ¯èª¤è™•ç†æ¸¬è©¦å¤±æ•—")
                
        except Exception as e:
            print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨éŒ¯èª¤è™•ç†æ¸¬è©¦ç•°å¸¸: {e}")
        
        # 2. è³‡æ–™æ ¼å¼éŒ¯èª¤è™•ç†æ¸¬è©¦
        print("ğŸ”„ æ¸¬è©¦è³‡æ–™æ ¼å¼éŒ¯èª¤è™•ç†...")
        
        try:
            # å‰µå»ºæ ¼å¼éŒ¯èª¤çš„æ¸¬è©¦è³‡æ–™
            malformed_df = pd.DataFrame({
                'å‚™æŸ¥ç·¨è™Ÿ': ['TEST001', 'TEST002'],
                'äº¤æ˜“æ—¥æœŸ': ['invalid_date', '20230230'],  # ç„¡æ•ˆæ—¥æœŸ
                'å»ºç‰©å–®åƒ¹': ['not_a_number', 'åƒ¹æ ¼'],  # éæ•¸å€¼
                'ç¸½æˆ¶æ•¸': ['ç„¡é™å¤§', '-1']  # ç„¡æ•ˆæ•¸å€¼
            })
            
            test_system.data['malformed_test'] = malformed_df
            
            # æ¸¬è©¦æ¸…ç†å‡½æ•¸æ˜¯å¦èƒ½è™•ç†æ ¼å¼éŒ¯èª¤
            try:
                cleaned_df = test_system._clean_pre_sale_data(malformed_df.copy())
                
                # æª¢æŸ¥æ˜¯å¦æˆåŠŸè™•ç†äº†éŒ¯èª¤è³‡æ–™
                if len(cleaned_df) >= 0:  # èƒ½å¤ è™•ç†è€Œä¸å´©æ½°
                    error_handling_results['data_format_error_handling'] = True
                    print("âœ… è³‡æ–™æ ¼å¼éŒ¯èª¤è™•ç†æ¸¬è©¦é€šé")
                else:
                    print("âŒ è³‡æ–™æ ¼å¼éŒ¯èª¤è™•ç†æ¸¬è©¦å¤±æ•—")
                    
            except Exception as e:
                print(f"âŒ è³‡æ–™æ ¼å¼éŒ¯èª¤è™•ç†æ¸¬è©¦å…§éƒ¨ç•°å¸¸: {e}")
                
        except Exception as e:
            print(f"âŒ è³‡æ–™æ ¼å¼éŒ¯èª¤è™•ç†æ¸¬è©¦ç•°å¸¸: {e}")
        
        # 3. è¨ˆç®—éŒ¯èª¤è™•ç†æ¸¬è©¦
        print("ğŸ”„ æ¸¬è©¦è¨ˆç®—éŒ¯èª¤è™•ç†...")
        
        try:
            # å‰µå»ºæœƒå°è‡´é™¤é›¶éŒ¯èª¤çš„æ¸¬è©¦è³‡æ–™
            division_test_df = pd.DataFrame({
                'å‚™æŸ¥ç·¨è™Ÿ': ['DIV001', 'DIV002'],
                'ç¸½æˆ¶æ•¸': [0, 100],  # åŒ…å«é›¶å€¼
                'æˆäº¤ç­†æ•¸': [10, 50]
            })
            
            # æ¸¬è©¦é™¤æ³•è¨ˆç®—çš„éŒ¯èª¤è™•ç†
            safe_division_results = []
            
            for _, row in division_test_df.iterrows():
                try:
                    if row['ç¸½æˆ¶æ•¸'] > 0:
                        rate = row['æˆäº¤ç­†æ•¸'] / row['ç¸½æˆ¶æ•¸'] * 100
                    else:
                        rate = 0  # å®‰å…¨è™•ç†é™¤é›¶
                    safe_division_results.append(rate)
                except ZeroDivisionError:
                    safe_division_results.append(0)
                except Exception:
                    safe_division_results.append(None)
            
            if len(safe_division_results) == len(division_test_df):
                error_handling_results['calculation_error_handling'] = True
                print("âœ… è¨ˆç®—éŒ¯èª¤è™•ç†æ¸¬è©¦é€šé")
            else:
                print("âŒ è¨ˆç®—éŒ¯èª¤è™•ç†æ¸¬è©¦å¤±æ•—")
                
        except Exception as e:
            print(f"âŒ è¨ˆç®—éŒ¯èª¤è™•ç†æ¸¬è©¦ç•°å¸¸: {e}")
        
        # 4. è¨˜æ†¶é«”éŒ¯èª¤è™•ç†æ¸¬è©¦ï¼ˆæ¨¡æ“¬ï¼‰
        print("ğŸ”„ æ¸¬è©¦è¨˜æ†¶é«”éŒ¯èª¤è™•ç†...")
        
        try:
            # æª¢æŸ¥ç³»çµ±è¨˜æ†¶é«”ç‹€æ³
            memory_info = psutil.virtual_memory()
            
            # æ¨¡æ“¬è¨˜æ†¶é«”ä¸è¶³çš„è™•ç†é‚è¼¯
            if memory_info.percent > 90:
                # è¨˜æ†¶é«”ä¸è¶³æ™‚çš„è™•ç†
                print("âš ï¸ è¨˜æ†¶é«”ä½¿ç”¨ç‡éé«˜ï¼Œå•Ÿå‹•ç¯€ç´„æ¨¡å¼")
                # é€™è£¡æ‡‰è©²å¯¦æ–½è¨˜æ†¶é«”ç¯€ç´„ç­–ç•¥
            
            # æª¢æŸ¥æ˜¯å¦æœ‰è¨˜æ†¶é«”ç›£æ§æ©Ÿåˆ¶
            memory_threshold = test_system.config['processing']['memory_threshold']
            
            if memory_threshold and memory_threshold < 1.0:
                error_handling_results['memory_error_handling'] = True
                print("âœ… è¨˜æ†¶é«”éŒ¯èª¤è™•ç†æ©Ÿåˆ¶å­˜åœ¨")
            else:
                print("âŒ è¨˜æ†¶é«”éŒ¯èª¤è™•ç†æ©Ÿåˆ¶ç¼ºå¤±")
                
        except Exception as e:
            print(f"âŒ è¨˜æ†¶é«”éŒ¯èª¤è™•ç†æ¸¬è©¦ç•°å¸¸: {e}")
        
        # 5. è¶…æ™‚è™•ç†æ¸¬è©¦ï¼ˆæ¨¡æ“¬ï¼‰
        print("ğŸ”„ æ¸¬è©¦è¶…æ™‚è™•ç†...")
        
        try:
            # æª¢æŸ¥æ˜¯å¦æœ‰è¶…æ™‚é…ç½®
            timeout_config = test_system.config['processing']['timeout_seconds']
            
            if timeout_config and timeout_config > 0:
                error_handling_results['timeout_handling'] = True
                print(f"âœ… è¶…æ™‚è™•ç†é…ç½®å­˜åœ¨ ({timeout_config}ç§’)")
            else:
                print("âŒ è¶…æ™‚è™•ç†é…ç½®ç¼ºå¤±")
                
        except Exception as e:
            print(f"âŒ è¶…æ™‚è™•ç†æ¸¬è©¦ç•°å¸¸: {e}")
        
        # 6. å„ªé›…é™ç´šæ¸¬è©¦
        print("ğŸ”„ æ¸¬è©¦å„ªé›…é™ç´š...")
        
        try:
            # æ¨¡æ“¬éƒ¨åˆ†åŠŸèƒ½å¤±æ•—æ™‚çš„é™ç´šè™•ç†
            test_system.results = {}  # æ¸…ç©ºçµæœ
            
            # æ¸¬è©¦ç•¶æŸå€‹åˆ†ææ­¥é©Ÿå¤±æ•—æ™‚ï¼Œç³»çµ±æ˜¯å¦èƒ½ç¹¼çºŒå…¶ä»–åˆ†æ
            partial_success_count = 0
            
            # æ¨¡æ“¬éƒ¨åˆ†æˆåŠŸçš„å ´æ™¯
            try:
                # å‡è¨­ç¤¾å€ç´šåˆ†ææˆåŠŸ
                test_system.results['community_level'] = pd.DataFrame({'test': [1, 2, 3]})
                partial_success_count += 1
            except:
                pass
            
            try:
                # å‡è¨­è¡Œæ”¿å€ç´šåˆ†æå¤±æ•—ä½†ä¸å½±éŸ¿å…¶ä»–åˆ†æ
                pass  # æ¨¡æ“¬å¤±æ•—
            except:
                pass
            
            if partial_success_count > 0:
                error_handling_results['graceful_degradation'] = True
                print("âœ… å„ªé›…é™ç´šè™•ç†æ¸¬è©¦é€šé")
            else:
                print("âŒ å„ªé›…é™ç´šè™•ç†æ¸¬è©¦å¤±æ•—")
                
        except Exception as e:
            print(f"âŒ å„ªé›…é™ç´šæ¸¬è©¦ç•°å¸¸: {e}")
        
    except Exception as e:
        print(f"âŒ éŒ¯èª¤è™•ç†æ©Ÿåˆ¶é©—è­‰éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    # æ¸¬è©¦çµæœç¸½çµ
    passed_tests = sum(error_handling_results.values())
    total_tests = len(error_handling_results)
    
    print(f"\nğŸ“Š éŒ¯èª¤è™•ç†æ©Ÿåˆ¶é©—è­‰çµæœ: {passed_tests}/{total_tests} é …é€šé")
    
    for test_name, result in error_handling_results.items():
        status = "âœ…" if result else "âŒ"
        print(f"   {status} {test_name}")
    
    # å»ºè­°æ”¹å–„é …ç›®
    failed_tests = [test for test, result in error_handling_results.items() if not result]
    if failed_tests:
        print(f"\nğŸ’¡ å»ºè­°æ”¹å–„é …ç›®:")
        for test in failed_tests:
            print(f"   â€¢ {test}")
    
    if passed_tests >= total_tests * 0.8:  # 80%ä»¥ä¸Šé€šé
        print("ğŸ‰ éŒ¯èª¤è™•ç†æ©Ÿåˆ¶åŸºæœ¬å¥å…¨!")
        return True, error_handling_results
    else:
        print("âš ï¸ éŒ¯èª¤è™•ç†æ©Ÿåˆ¶éœ€è¦åŠ å¼·")
        return False, error_handling_results

# %%
# åŸ·è¡ŒéŒ¯èª¤è™•ç†æ©Ÿåˆ¶é©—è­‰
error_handling_success, error_handling_details = run_error_handling_tests()

# %% [markdown]
# ## 8. è³‡æ–™å“è³ªé©—è­‰

# %%
def run_data_quality_validation():
    """
    åŸ·è¡Œè³‡æ–™å“è³ªé©—è­‰
    """
    
    print("ğŸ” è³‡æ–™å“è³ªé©—è­‰")
    print("=" * 50)
    
    quality_validation_results = {
        'completeness_check': False,
        'consistency_check': False,
        'accuracy_check': False,
        'validity_check': False,
        'uniqueness_check': False,
        'timeliness_check': False
    }
    
    quality_metrics = {}
    
    try:
        # å‰µå»ºæ¸¬è©¦è³‡æ–™é›†é€²è¡Œå“è³ªé©—è­‰
        test_data_size = 10000
        
        print(f"ğŸ”„ å‰µå»ºæ¸¬è©¦è³‡æ–™é›† ({test_data_size:,} ç­†)...")
        
        # æ¨¡æ“¬çœŸå¯¦é å”®å±‹è³‡æ–™
        test_pre_sale_data = pd.DataFrame({
            'å‚™æŸ¥ç·¨è™Ÿ': [f'TEST{i:06d}' for i in range(test_data_size)],
            'ç¸£å¸‚': np.random.choice(['å°åŒ—å¸‚', 'æ–°åŒ—å¸‚', 'æ¡ƒåœ’å¸‚', 'å°ä¸­å¸‚'], test_data_size, p=[0.3, 0.4, 0.2, 0.1]),
            'è¡Œæ”¿å€': np.random.choice(['ä¿¡ç¾©å€', 'å¤§å®‰å€', 'ä¸­å±±å€', 'æ¿æ©‹å€', 'ä¸­å£¢å€'], test_data_size),
            'äº¤æ˜“æ—¥æœŸ': pd.date_range('2021-01-01', '2023-12-31', periods=test_data_size),
            'å»ºç‰©å–®åƒ¹': np.random.normal(500000, 150000, test_data_size),  # å¹³å‡50è¬/åª
            'äº¤æ˜“ç¸½åƒ¹': np.random.normal(30000000, 10000000, test_data_size),  # å¹³å‡3000è¬
            'ç¸½é¢ç©': np.random.normal(50, 15, test_data_size),  # å¹³å‡50åª
            'è§£ç´„æƒ…å½¢': np.random.choice([None, '1120515å…¨éƒ¨è§£ç´„'], test_data_size, p=[0.95, 0.05])
        })
        
        # æ•…æ„åŠ å…¥ä¸€äº›å“è³ªå•é¡Œç”¨æ–¼æ¸¬è©¦
        # 1. å®Œæ•´æ€§å•é¡Œï¼šæ·»åŠ ç©ºå€¼
        missing_indices = np.random.choice(test_data_size, size=int(test_data_size * 0.02), replace=False)
        test_pre_sale_data.loc[missing_indices, 'å»ºç‰©å–®åƒ¹'] = None
        
        # 2. ä¸€è‡´æ€§å•é¡Œï¼šæ·»åŠ ä¸ä¸€è‡´çš„è³‡æ–™
        inconsistent_indices = np.random.choice(test_data_size, size=int(test_data_size * 0.01), replace=False)
        test_pre_sale_data.loc[inconsistent_indices, 'ç¸£å¸‚'] = 'ä¸å­˜åœ¨çš„ç¸£å¸‚'
        
        # 3. æº–ç¢ºæ€§å•é¡Œï¼šæ·»åŠ ç•°å¸¸å€¼
        outlier_indices = np.random.choice(test_data_size, size=int(test_data_size * 0.005), replace=False)
        test_pre_sale_data.loc[outlier_indices, 'å»ºç‰©å–®åƒ¹'] = -1000  # è² å€¼åƒ¹æ ¼
        
        # 4. æœ‰æ•ˆæ€§å•é¡Œï¼šæ·»åŠ ç„¡æ•ˆæ—¥æœŸ
        invalid_indices = np.random.choice(test_data_size, size=int(test_data_size * 0.003), replace=False)
        test_pre_sale_data.loc[invalid_indices, 'äº¤æ˜“æ—¥æœŸ'] = pd.NaT
        
        # 5. å”¯ä¸€æ€§å•é¡Œï¼šæ·»åŠ é‡è¤‡è¨˜éŒ„
        duplicate_indices = np.random.choice(test_data_size-100, size=50, replace=False)
        duplicate_rows = test_pre_sale_data.iloc[duplicate_indices].copy()
        test_pre_sale_data = pd.concat([test_pre_sale_data, duplicate_rows], ignore_index=True)
        
        print(f"âœ… æ¸¬è©¦è³‡æ–™é›†å‰µå»ºå®Œæˆ ({len(test_pre_sale_data):,} ç­†ï¼ŒåŒ…å«å“è³ªå•é¡Œ)")
        
        # 1. å®Œæ•´æ€§æª¢æŸ¥
        print("\nğŸ”„ åŸ·è¡Œå®Œæ•´æ€§æª¢æŸ¥...")
        
        try:
            # è¨ˆç®—å®Œæ•´æ€§æŒ‡æ¨™
            total_cells = len(test_pre_sale_data) * len(test_pre_sale_data.columns)
            missing_cells = test_pre_sale_data.isnull().sum().sum()
            completeness_ratio = 1 - (missing_cells / total_cells)
            
            # é—œéµæ¬„ä½å®Œæ•´æ€§
            key_columns = ['å‚™æŸ¥ç·¨è™Ÿ', 'ç¸£å¸‚', 'è¡Œæ”¿å€', 'äº¤æ˜“æ—¥æœŸ']
            key_completeness = {}
            
            for col in key_columns:
                if col in test_pre_sale_data.columns:
                    key_completeness[col] = 1 - (test_pre_sale_data[col].isnull().sum() / len(test_pre_sale_data))
            
            quality_metrics['completeness'] = {
                'overall_completeness': completeness_ratio,
                'key_column_completeness': key_completeness,
                'missing_cells': missing_cells,
                'total_cells': total_cells
            }
            
            # å®Œæ•´æ€§æ¨™æº–ï¼šæ•´é«”å®Œæ•´æ€§ > 95%ï¼Œé—œéµæ¬„ä½å®Œæ•´æ€§ > 98%
            completeness_pass = (completeness_ratio > 0.95 and 
                                all(comp > 0.98 for comp in key_completeness.values()))
            
            quality_validation_results['completeness_check'] = completeness_pass
            
            print(f"   æ•´é«”å®Œæ•´æ€§: {completeness_ratio:.2%}")
            print(f"   é—œéµæ¬„ä½å®Œæ•´æ€§: {list(key_completeness.values())}")
            print(f"   å®Œæ•´æ€§æª¢æŸ¥: {'âœ… é€šé' if completeness_pass else 'âŒ æœªé€šé'}")
            
        except Exception as e:
            print(f"âŒ å®Œæ•´æ€§æª¢æŸ¥ç•°å¸¸: {e}")
        
        # 2. ä¸€è‡´æ€§æª¢æŸ¥
        print("\nğŸ”„ åŸ·è¡Œä¸€è‡´æ€§æª¢æŸ¥...")
        
        try:
            # æª¢æŸ¥ç¸£å¸‚è¡Œæ”¿å€ä¸€è‡´æ€§
            valid_combinations = {
                'å°åŒ—å¸‚': ['ä¿¡ç¾©å€', 'å¤§å®‰å€', 'ä¸­å±±å€'],
                'æ–°åŒ—å¸‚': ['æ¿æ©‹å€', 'ä¸­å’Œå€', 'æ–°èŠå€'],
                'æ¡ƒåœ’å¸‚': ['ä¸­å£¢å€', 'æ¡ƒåœ’å€', 'å…«å¾·å€'],
                'å°ä¸­å¸‚': ['è¥¿å±¯å€', 'å—å±¯å€', 'åŒ—å±¯å€']
            }
            
            inconsistent_count = 0
            for _, row in test_pre_sale_data.iterrows():
                county = row['ç¸£å¸‚']
                district = row['è¡Œæ”¿å€']
                
                if county in valid_combinations:
                    if district not in valid_combinations[county]:
                        # å…è¨±ä¸€äº›åˆç†çš„çµ„åˆï¼ˆå¯¦éš›ä¸Šå¯èƒ½å­˜åœ¨ï¼‰
                        if county not in ['ä¸å­˜åœ¨çš„ç¸£å¸‚']:  # æ˜é¡¯éŒ¯èª¤çš„æ‰è¨ˆç®—
                            continue
                    
                if county == 'ä¸å­˜åœ¨çš„ç¸£å¸‚':
                    inconsistent_count += 1
            
            consistency_ratio = 1 - (inconsistent_count / len(test_pre_sale_data))
            
            quality_metrics['consistency'] = {
                'county_district_consistency': consistency_ratio,
                'inconsistent_records': inconsistent_count
            }
            
            # ä¸€è‡´æ€§æ¨™æº–ï¼š> 98%
            consistency_pass = consistency_ratio > 0.98
            quality_validation_results['consistency_check'] = consistency_pass
            
            print(f"   ç¸£å¸‚è¡Œæ”¿å€ä¸€è‡´æ€§: {consistency_ratio:.2%}")
            print(f"   ä¸ä¸€è‡´è¨˜éŒ„æ•¸: {inconsistent_count}")
            print(f"   ä¸€è‡´æ€§æª¢æŸ¥: {'âœ… é€šé' if consistency_pass else 'âŒ æœªé€šé'}")
            
        except Exception as e:
            print(f"âŒ ä¸€è‡´æ€§æª¢æŸ¥ç•°å¸¸: {e}")
        
        # 3. æº–ç¢ºæ€§æª¢æŸ¥
        print("\nğŸ”„ åŸ·è¡Œæº–ç¢ºæ€§æª¢æŸ¥...")
        
        try:
            # æª¢æŸ¥æ•¸å€¼ç¯„åœçš„åˆç†æ€§
            price_outliers = 0
            area_outliers = 0
            total_price_outliers = 0
            
            # åƒ¹æ ¼åˆç†æ€§æª¢æŸ¥ (10è¬-300è¬/åª)
            valid_prices = test_pre_sale_data['å»ºç‰©å–®åƒ¹'].dropna()
            price_outliers = len(valid_prices[(valid_prices < 100000) | (valid_prices > 3000000)])
            
            # é¢ç©åˆç†æ€§æª¢æŸ¥ (10-200åª)
            valid_areas = test_pre_sale_data['ç¸½é¢ç©'].dropna()
            area_outliers = len(valid_areas[(valid_areas < 10) | (valid_areas > 200)])
            
            # ç¸½åƒ¹åˆç†æ€§æª¢æŸ¥ (500è¬-2å„„)
            valid_total_prices = test_pre_sale_data['äº¤æ˜“ç¸½åƒ¹'].dropna()
            total_price_outliers = len(valid_total_prices[(valid_total_prices < 5000000) | (valid_total_prices > 200000000)])
            
            total_outliers = price_outliers + area_outliers + total_price_outliers
            accuracy_ratio = 1 - (total_outliers / (len(valid_prices) + len(valid_areas) + len(valid_total_prices)))
            
            quality_metrics['accuracy'] = {
                'price_outliers': price_outliers,
                'area_outliers': area_outliers,
                'total_price_outliers': total_price_outliers,
                'accuracy_ratio': accuracy_ratio
            }
            
            # æº–ç¢ºæ€§æ¨™æº–ï¼šç•°å¸¸å€¼ < 2%
            accuracy_pass = accuracy_ratio > 0.98
            quality_validation_results['accuracy_check'] = accuracy_pass
            
            print(f"   åƒ¹æ ¼ç•°å¸¸å€¼: {price_outliers}")
            print(f"   é¢ç©ç•°å¸¸å€¼: {area_outliers}")
            print(f"   ç¸½åƒ¹ç•°å¸¸å€¼: {total_price_outliers}")
            print(f"   æº–ç¢ºæ€§æ¯”ç‡: {accuracy_ratio:.2%}")
            print(f"   æº–ç¢ºæ€§æª¢æŸ¥: {'âœ… é€šé' if accuracy_pass else 'âŒ æœªé€šé'}")
            
        except Exception as e:
            print(f"âŒ æº–ç¢ºæ€§æª¢æŸ¥ç•°å¸¸: {e}")
        
        # 4. æœ‰æ•ˆæ€§æª¢æŸ¥
        print("\nğŸ”„ åŸ·è¡Œæœ‰æ•ˆæ€§æª¢æŸ¥...")
        
        try:
            # æ—¥æœŸæœ‰æ•ˆæ€§æª¢æŸ¥
            invalid_dates = test_pre_sale_data['äº¤æ˜“æ—¥æœŸ'].isnull().sum()
            
            # å‚™æŸ¥ç·¨è™Ÿæ ¼å¼æª¢æŸ¥
            valid_id_pattern = test_pre_sale_data['å‚™æŸ¥ç·¨è™Ÿ'].str.match(r'^[A-Z0-9]+, na=False)
            invalid_ids = len(test_pre_sale_data) - valid_id_pattern.sum()
            
            # è§£ç´„æƒ…å½¢æ ¼å¼æª¢æŸ¥
            cancellation_data = test_pre_sale_data['è§£ç´„æƒ…å½¢'].dropna()
            valid_cancellation_pattern = cancellation_data.str.contains('å…¨éƒ¨è§£ç´„', na=False)
            invalid_cancellations = len(cancellation_data) - valid_cancellation_pattern.sum()
            
            total_invalid = invalid_dates + invalid_ids + invalid_cancellations
            validity_ratio = 1 - (total_invalid / (len(test_pre_sale_data) * 3))  # 3å€‹æª¢æŸ¥é …ç›®
            
            quality_metrics['validity'] = {
                'invalid_dates': invalid_dates,
                'invalid_ids': invalid_ids,
                'invalid_cancellations': invalid_cancellations,
                'validity_ratio': validity_ratio
            }
            
            # æœ‰æ•ˆæ€§æ¨™æº–ï¼š> 95%
            validity_pass = validity_ratio > 0.95
            quality_validation_results['validity_check'] = validity_pass
            
            print(f"   ç„¡æ•ˆæ—¥æœŸ: {invalid_dates}")
            print(f"   ç„¡æ•ˆå‚™æŸ¥ç·¨è™Ÿ: {invalid_ids}")
            print(f"   ç„¡æ•ˆè§£ç´„è¨˜éŒ„: {invalid_cancellations}")
            print(f"   æœ‰æ•ˆæ€§æ¯”ç‡: {validity_ratio:.2%}")
            print(f"   æœ‰æ•ˆæ€§æª¢æŸ¥: {'âœ… é€šé' if validity_pass else 'âŒ æœªé€šé'}")
            
        except Exception as e:
            print(f"âŒ æœ‰æ•ˆæ€§æª¢æŸ¥ç•°å¸¸: {e}")
        
        # 5. å”¯ä¸€æ€§æª¢æŸ¥
        print("\nğŸ”„ åŸ·è¡Œå”¯ä¸€æ€§æª¢æŸ¥...")
        
        try:
            # æª¢æŸ¥é‡è¤‡è¨˜éŒ„
            original_count = len(test_pre_sale_data)
            unique_count = len(test_pre_sale_data.drop_duplicates())
            duplicate_count = original_count - unique_count
            
            # æª¢æŸ¥é—œéµæ¬„ä½é‡è¤‡
            key_columns = ['å‚™æŸ¥ç·¨è™Ÿ', 'äº¤æ˜“æ—¥æœŸ', 'å»ºç‰©å–®åƒ¹']
            key_duplicates = len(test_pre_sale_data) - len(test_pre_sale_data.drop_duplicates(subset=key_columns))
            
            uniqueness_ratio = unique_count / original_count
            
            quality_metrics['uniqueness'] = {
                'total_records': original_count,
                'unique_records': unique_count,
                'duplicate_records': duplicate_count,
                'key_duplicates': key_duplicates,
                'uniqueness_ratio': uniqueness_ratio
            }
            
            # å”¯ä¸€æ€§æ¨™æº–ï¼šé‡è¤‡ç‡ < 5%
            uniqueness_pass = uniqueness_ratio > 0.95
            quality_validation_results['uniqueness_check'] = uniqueness_pass
            
            print(f"   ç¸½è¨˜éŒ„æ•¸: {original_count:,}")
            print(f"   å”¯ä¸€è¨˜éŒ„æ•¸: {unique_count:,}")
            print(f"   é‡è¤‡è¨˜éŒ„æ•¸: {duplicate_count:,}")
            print(f"   å”¯ä¸€æ€§æ¯”ç‡: {uniqueness_ratio:.2%}")
            print(f"   å”¯ä¸€æ€§æª¢æŸ¥: {'âœ… é€šé' if uniqueness_pass else 'âŒ æœªé€šé'}")
            
        except Exception as e:
            print(f"âŒ å”¯ä¸€æ€§æª¢æŸ¥ç•°å¸¸: {e}")
        
        # 6. æ™‚æ•ˆæ€§æª¢æŸ¥
        print("\nğŸ”„ åŸ·è¡Œæ™‚æ•ˆæ€§æª¢æŸ¥...")
        
        try:
            # æª¢æŸ¥è³‡æ–™çš„æ™‚é–“ç¯„åœ
            min_date = test_pre_sale_data['äº¤æ˜“æ—¥æœŸ'].min()
            max_date = test_pre_sale_data['äº¤æ˜“æ—¥æœŸ'].max()
            current_date = pd.Timestamp.now()
            
            # æª¢æŸ¥æ˜¯å¦æœ‰æœªä¾†æ—¥æœŸ
            future_dates = (test_pre_sale_data['äº¤æ˜“æ—¥æœŸ'] > current_date).sum()
            
            # æª¢æŸ¥è³‡æ–™æ–°é®®åº¦ï¼ˆæœ€æ–°è³‡æ–™è·ä»Šæ™‚é–“ï¼‰
            if pd.notna(max_date):
                data_age_days = (current_date - max_date).days
                timeliness_score = max(0, 1 - (data_age_days / 365))  # 1å¹´å…§ç‚ºæ»¿åˆ†
            else:
                timeliness_score = 0
            
            quality_metrics['timeliness'] = {
                'date_range': f"{min_date} ~ {max_date}",
                'future_dates': future_dates,
                'data_age_days': data_age_days if pd.notna(max_date) else None,
                'timeliness_score': timeliness_score
            }
            
            # æ™‚æ•ˆæ€§æ¨™æº–ï¼šç„¡æœªä¾†æ—¥æœŸï¼Œè³‡æ–™å¹´é½¡ < 180å¤©
            timeliness_pass = (future_dates == 0 and timeliness_score > 0.5)
            quality_validation_results['timeliness_check'] = timeliness_pass
            
            print(f"   è³‡æ–™æ™‚é–“ç¯„åœ: {min_date} ~ {max_date}")
            print(f"   æœªä¾†æ—¥æœŸæ•¸é‡: {future_dates}")
            if pd.notna(max_date):
                print(f"   è³‡æ–™å¹´é½¡: {data_age_days} å¤©")
            print(f"   æ™‚æ•ˆæ€§è©•åˆ†: {timeliness_score:.2%}")
            print(f"   æ™‚æ•ˆæ€§æª¢æŸ¥: {'âœ… é€šé' if timeliness_pass else 'âŒ æœªé€šé'}")
            
        except Exception as e:
            print(f"âŒ æ™‚æ•ˆæ€§æª¢æŸ¥ç•°å¸¸: {e}")
        
    except Exception as e:
        print(f"âŒ è³‡æ–™å“è³ªé©—è­‰éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    # ç¶œåˆå“è³ªè©•åˆ†
    passed_checks = sum(quality_validation_results.values())
    total_checks = len(quality_validation_results)
    quality_score = (passed_checks / total_checks) * 100
    
    print(f"\nğŸ“Š è³‡æ–™å“è³ªé©—è­‰çµæœ:")
    print(f"   é€šéé …ç›®: {passed_checks}/{total_checks}")
    print(f"   å“è³ªè©•åˆ†: {quality_score:.1f}/100")
    
    for check_name, result in quality_validation_results.items():
        status = "âœ…" if result else "âŒ"
        print(f"   {status} {check_name}")
    
    # å“è³ªç­‰ç´šè©•å®š
    if quality_score >= 90:
        quality_grade = "ğŸ† å„ªç§€"
    elif quality_score >= 80:
        quality_grade = "ğŸ¥‡ è‰¯å¥½"
    elif quality_score >= 70:
        quality_grade = "ğŸ¥ˆ æ™®é€š"
    else:
        quality_grade = "ğŸ¥‰ éœ€æ”¹å–„"
    
    print(f"\nğŸ¯ è³‡æ–™å“è³ªç­‰ç´š: {quality_grade}")
    
    return quality_score >= 80, {
        'validation_results': quality_validation_results,
        'quality_metrics': quality_metrics,
        'quality_score': quality_score,
        'quality_grade': quality_grade
    }

# %%
# åŸ·è¡Œè³‡æ–™å“è³ªé©—è­‰
data_quality_pass, data_quality_details = run_data_quality_validation()

# %% [markdown]
# ## 9. è¼¸å‡ºå®Œæ•´æ€§é©—è­‰

# %%
def run_output_integrity_validation():
    """
    åŸ·è¡Œè¼¸å‡ºå®Œæ•´æ€§é©—è­‰
    """
    
    print("ğŸ“¤ è¼¸å‡ºå®Œæ•´æ€§é©—è­‰")
    print("=" * 50)
    
    output_validation_results = {
        'file_generation': False,
        'content_completeness': False,
        'format_compliance': False,
        'data_consistency': False,
        'cross_level_integrity': False
    }
    
    try:
        # åŸ·è¡Œå®Œæ•´æµç¨‹æ¸¬è©¦ä»¥ç”Ÿæˆè¼¸å‡º
        print("ğŸ”„ åŸ·è¡Œå®Œæ•´æµç¨‹ä»¥ç”Ÿæˆæ¸¬è©¦è¼¸å‡º...")
        
        pipeline_tester = IntegratedPipelineTester()
        
        # åŸ·è¡Œç°¡åŒ–ç‰ˆæœ¬çš„æµç¨‹æ¸¬è©¦ï¼ˆç”¨æ–¼é©—è­‰è¼¸å‡ºï¼‰
        test_system = PreSaleHousingAnalysisSystem()
        
        # 1. æª”æ¡ˆç”Ÿæˆé©—è­‰
        print("\nğŸ”„ é©—è­‰æª”æ¡ˆç”Ÿæˆ...")
        
        try:
            # æª¢æŸ¥æ˜¯å¦èƒ½å¤ æˆåŠŸç”Ÿæˆè¼¸å‡ºæª”æ¡ˆ
            current_date = datetime.now().strftime("%Y%m%d")
            expected_files = [
                f"community_level_integrated_report_{current_date}.csv",
                f"district_level_integrated_report_{current_date}.csv",
                f"city_level_integrated_report_{current_date}.csv",
                f"integrated_system_report_{current_date}.json"
            ]
            
            # æ¨¡æ“¬æª”æ¡ˆç”Ÿæˆæª¢æŸ¥
            output_dir = test_system.config['data_paths']['output_dir']
            
            # å‰µå»ºæ¨¡æ“¬è¼¸å‡ºæª”æ¡ˆé€²è¡Œæ¸¬è©¦
            test_community_data = pd.DataFrame({
                'å‚™æŸ¥ç·¨è™Ÿ': ['TEST001', 'TEST002'],
                'ç¸£å¸‚': ['å°åŒ—å¸‚', 'æ–°åŒ—å¸‚'],
                'å¹´å­£': ['111Y1S', '111Y2S'],
                'æ·¨å»åŒ–ç‡(%)': [65.5, 48.2]
            })
            
            test_district_data = pd.DataFrame({
                'ç¸£å¸‚': ['å°åŒ—å¸‚', 'æ–°åŒ—å¸‚'],
                'è¡Œæ”¿å€': ['ä¿¡ç¾©å€', 'æ¿æ©‹å€'],
                'å¹´å­£': ['111Y1S', '111Y2S'],
                'æ•´é«”æ·¨å»åŒ–ç‡(%)': [62.3, 51.1]
            })
            
            test_city_data = pd.DataFrame({
                'ç¸£å¸‚': ['å°åŒ—å¸‚', 'æ–°åŒ—å¸‚'],
                'å¹´å­£': ['111Y1S', '111Y2S'],
                'ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)': [58.9, 49.7]
            })
            
            # å˜—è©¦å¯«å…¥æª”æ¡ˆ
            test_community_file = f"{output_dir}test_community_output.csv"
            test_district_file = f"{output_dir}test_district_output.csv"
            test_city_file = f"{output_dir}test_city_output.csv"
            
            test_community_data.to_csv(test_community_file, index=False, encoding='utf-8-sig')
            test_district_data.to_csv(test_district_file, index=False, encoding='utf-8-sig')
            test_city_data.to_csv(test_city_file, index=False, encoding='utf-8-sig')
            
            # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦æˆåŠŸå‰µå»º
            files_created = [
                os.path.exists(test_community_file),
                os.path.exists(test_district_file),
                os.path.exists(test_city_file)
            ]
            
            if all(files_created):
                output_validation_results['file_generation'] = True
                print("âœ… æª”æ¡ˆç”Ÿæˆé©—è­‰é€šé")
                print(f"   æˆåŠŸç”Ÿæˆ {sum(files_created)} å€‹æ¸¬è©¦æª”æ¡ˆ")
            else:
                print("âŒ æª”æ¡ˆç”Ÿæˆé©—è­‰å¤±æ•—")
            
        except Exception as e:
            print(f"âŒ æª”æ¡ˆç”Ÿæˆé©—è­‰ç•°å¸¸: {e}")
        
        # 2. å…§å®¹å®Œæ•´æ€§é©—è­‰
        print("\nğŸ”„ é©—è­‰å…§å®¹å®Œæ•´æ€§...")
        
        try:
            # æª¢æŸ¥ç”Ÿæˆçš„æª”æ¡ˆå…§å®¹æ˜¯å¦å®Œæ•´
            if os.path.exists(test_community_file):
                community_df = pd.read_csv(test_community_file, encoding='utf-8-sig')
                
                # æª¢æŸ¥å¿…è¦æ¬„ä½
                required_community_cols = ['å‚™æŸ¥ç·¨è™Ÿ', 'ç¸£å¸‚', 'å¹´å­£', 'æ·¨å»åŒ–ç‡(%)']
                missing_cols = [col for col in required_community_cols if col not in community_df.columns]
                
                if not missing_cols and len(community_df) > 0:
                    content_completeness_score = 1
                else:
                    content_completeness_score = 0.5
            else:
                content_completeness_score = 0
            
            if content_completeness_score >= 0.8:
                output_validation_results['content_completeness'] = True
                print("âœ… å…§å®¹å®Œæ•´æ€§é©—è­‰é€šé")
                print(f"   å…§å®¹å®Œæ•´æ€§è©•åˆ†: {content_completeness_score:.1%}")
            else:
                print("âŒ å…§å®¹å®Œæ•´æ€§é©—è­‰å¤±æ•—")
            
        except Exception as e:
            print(f"âŒ å…§å®¹å®Œæ•´æ€§é©—è­‰ç•°å¸¸: {e}")
        
        # 3. æ ¼å¼åˆè¦æ€§é©—è­‰
        print("\nğŸ”„ é©—è­‰æ ¼å¼åˆè¦æ€§...")
        
        try:
            format_compliance_score = 0
            total_format_checks = 3
            
            # CSVæ ¼å¼æª¢æŸ¥
            try:
                if os.path.exists(test_community_file):
                    pd.read_csv(test_community_file, encoding='utf-8-sig')
                    format_compliance_score += 1
            except:
                pass
            
            # ç·¨ç¢¼æ ¼å¼æª¢æŸ¥
            try:
                if os.path.exists(test_community_file):
                    with open(test_community_file, 'r', encoding='utf-8-sig') as f:
                        content = f.read(100)  # è®€å–å‰100å­—ç¬¦æ¸¬è©¦
                    if content:
                        format_compliance_score += 1
            except:
                pass
            
            # æª”æ¡ˆå¤§å°åˆç†æ€§æª¢æŸ¥
            try:
                if os.path.exists(test_community_file):
                    file_size = os.path.getsize(test_community_file)
                    if 100 < file_size < 100000000:  # 100Båˆ°100MBä¹‹é–“
                        format_compliance_score += 1
            except:
                pass
            
            format_compliance_ratio = format_compliance_score / total_format_checks
            
            if format_compliance_ratio >= 0.8:
                output_validation_results['format_compliance'] = True
                print("âœ… æ ¼å¼åˆè¦æ€§é©—è­‰é€šé")
                print(f"   æ ¼å¼åˆè¦æ€§è©•åˆ†: {format_compliance_ratio:.1%}")
            else:
                print("âŒ æ ¼å¼åˆè¦æ€§é©—è­‰å¤±æ•—")
            
        except Exception as e:
            print(f"âŒ æ ¼å¼åˆè¦æ€§é©—è­‰ç•°å¸¸: {e}")
        
        # 4. è³‡æ–™ä¸€è‡´æ€§é©—è­‰
        print("\nğŸ”„ é©—è­‰è³‡æ–™ä¸€è‡´æ€§...")
        
        try:
            consistency_checks = []
            
            # æª¢æŸ¥å»åŒ–ç‡ç¯„åœ
            if os.path.exists(test_community_file):
                community_df = pd.read_csv(test_community_file, encoding='utf-8-sig')
                if 'æ·¨å»åŒ–ç‡(%)' in community_df.columns:
                    absorption_rates = community_df['æ·¨å»åŒ–ç‡(%)']
                    valid_rates = ((absorption_rates >= 0) & (absorption_rates <= 100)).all()
                    consistency_checks.append(valid_rates)
            
            # æª¢æŸ¥ç¸£å¸‚åç¨±ä¸€è‡´æ€§
            county_consistency = True
            if os.path.exists(test_community_file) and os.path.exists(test_city_file):
                community_df = pd.read_csv(test_community_file, encoding='utf-8-sig')
                city_df = pd.read_csv(test_city_file, encoding='utf-8-sig')
                
                if 'ç¸£å¸‚' in community_df.columns and 'ç¸£å¸‚' in city_df.columns:
                    community_counties = set(community_df['ç¸£å¸‚'].unique())
                    city_counties = set(city_df['ç¸£å¸‚'].unique())
                    county_consistency = community_counties.issubset(city_counties)
                    consistency_checks.append(county_consistency)
            
            data_consistency_score = sum(consistency_checks) / len(consistency_checks) if consistency_checks else 0
            
            if data_consistency_score >= 0.8:
                output_validation_results['data_consistency'] = True
                print("âœ… è³‡æ–™ä¸€è‡´æ€§é©—è­‰é€šé")
                print(f"   è³‡æ–™ä¸€è‡´æ€§è©•åˆ†: {data_consistency_score:.1%}")
            else:
                print("âŒ è³‡æ–™ä¸€è‡´æ€§é©—è­‰å¤±æ•—")
            
        except Exception as e:
            print(f"âŒ è³‡æ–™ä¸€è‡´æ€§é©—è­‰ç•°å¸¸: {e}")
        
        # 5. è·¨å±¤ç´šå®Œæ•´æ€§é©—è­‰
        print("\nğŸ”„ é©—è­‰è·¨å±¤ç´šå®Œæ•´æ€§...")
        
        try:
            cross_level_score = 0
            total_cross_checks = 2
            
            # æª¢æŸ¥å±¤ç´šé–“è³‡æ–™é‡é‚è¼¯é—œä¿‚
            if (os.path.exists(test_community_file) and 
                os.path.exists(test_district_file) and 
                os.path.exists(test_city_file)):
                
                community_count = len(pd.read_csv(test_community_file, encoding='utf-8-sig'))
                district_count = len(pd.read_csv(test_district_file, encoding='utf-8-sig'))
                city_count = len(pd.read_csv(test_city_file, encoding='utf-8-sig'))
                
                # ç¤¾å€ç´š >= è¡Œæ”¿å€ç´š >= ç¸£å¸‚ç´š
                if community_count >= district_count >= city_count > 0:
                    cross_level_score += 1
            
            # æª¢æŸ¥å¹´å­£ä¸€è‡´æ€§
            if (os.path.exists(test_community_file) and 
                os.path.exists(test_city_file)):
                
                community_df = pd.read_csv(test_community_file, encoding='utf-8-sig')
                city_df = pd.read_csv(test_city_file, encoding='utf-8-sig')
                
                if 'å¹´å­£' in community_df.columns and 'å¹´å­£' in city_df.columns:
                    community_seasons = set(community_df['å¹´å­£'].unique())
                    city_seasons = set(city_df['å¹´å­£'].unique())
                    
                    # æª¢æŸ¥å¹´å­£æ˜¯å¦æœ‰äº¤é›†
                    if len(community_seasons.intersection(city_seasons)) > 0:
                        cross_level_score += 1
            
            cross_level_ratio = cross_level_score / total_cross_checks
            
            if cross_level_ratio >= 0.8:
                output_validation_results['cross_level_integrity'] = True
                print("âœ… è·¨å±¤ç´šå®Œæ•´æ€§é©—è­‰é€šé")
                print(f"   è·¨å±¤ç´šå®Œæ•´æ€§è©•åˆ†: {cross_level_ratio:.1%}")
            else:
                print("âŒ è·¨å±¤ç´šå®Œæ•´æ€§é©—è­‰å¤±æ•—")
            
        except Exception as e:
            print(f"âŒ è·¨å±¤ç´šå®Œæ•´æ€§é©—è­‰ç•°å¸¸: {e}")
        
        # æ¸…ç†æ¸¬è©¦æª”æ¡ˆ
        for test_file in [test_community_file, test_district_file, test_city_file]:
            try:
                if os.path.exists(test_file):
                    os.remove(test_file)
            except:
                pass
        
    except Exception as e:
        print(f"âŒ è¼¸å‡ºå®Œæ•´æ€§é©—è­‰éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    # é©—è­‰çµæœç¸½çµ
    passed_validations = sum(output_validation_results.values())
    total_validations = len(output_validation_results)
    
    print(f"\nğŸ“Š è¼¸å‡ºå®Œæ•´æ€§é©—è­‰çµæœ: {passed_validations}/{total_validations} é …é€šé")
    
    for validation_name, result in output_validation_results.items():
        status = "âœ…" if result else "âŒ"
        print(f"   {status} {validation_name}")
    
    if passed_validations == total_validations:
        print("ğŸ‰ è¼¸å‡ºå®Œæ•´æ€§é©—è­‰å…¨éƒ¨é€šé!")
        return True, output_validation_results
    else:
        print("âš ï¸ éƒ¨åˆ†è¼¸å‡ºå®Œæ•´æ€§é©—è­‰å¤±æ•—")
        return False, output_validation_results

# %%
# åŸ·è¡Œè¼¸å‡ºå®Œæ•´æ€§é©—è­‰
output_integrity_pass, output_integrity_details = run_output_integrity_validation()

# %% [markdown]
# ## 10. ç³»çµ±ç©©å®šæ€§æ¸¬è©¦

# %%
def run_system_stability_tests():
    """
    åŸ·è¡Œç³»çµ±ç©©å®šæ€§æ¸¬è©¦
    """
    
    print("ğŸ”’ ç³»çµ±ç©©å®šæ€§æ¸¬è©¦")
    print("=" * 50)
    
    stability_test_results = {
        'repeated_execution': False,
        'concurrent_processing': False,
        'memory_stability': False,
        'long_running_stability': False,
        'recovery_capability': False
    }
    
    stability_metrics = {}
    
    try:
        # 1. é‡è¤‡åŸ·è¡Œç©©å®šæ€§æ¸¬è©¦
        print("ğŸ”„ æ¸¬è©¦é‡è¤‡åŸ·è¡Œç©©å®šæ€§...")
        
        try:
            execution_results = []
            execution_times = []
            
            for i in range(5):  # åŸ·è¡Œ5æ¬¡
                print(f"   åŸ·è¡Œç¬¬ {i+1} æ¬¡...")
                
                start_time = time.time()
                
                # å‰µå»ºæ–°çš„ç³»çµ±å¯¦ä¾‹
                test_system = PreSaleHousingAnalysisSystem()
                
                # å‰µå»ºæ¸¬è©¦è³‡æ–™
                test_data = pd.DataFrame({
                    'å‚™æŸ¥ç·¨è™Ÿ': [f'REPEAT{j:03d}' for j in range(100)],
                    'ç¸£å¸‚': np.random.choice(['å°åŒ—å¸‚', 'æ–°åŒ—å¸‚'], 100),
                    'äº¤æ˜“å¹´å­£': ['111Y1S'] * 100,
                    'æ·¨å»åŒ–ç‡(%)': np.random.uniform(20, 80, 100)
                })
                
                test_system.data['test_data'] = test_data
                
                # åŸ·è¡ŒåŸºæœ¬åˆ†æ
                try:
                    result = len(test_data.groupby('ç¸£å¸‚')['æ·¨å»åŒ–ç‡(%)'].mean())
                    execution_results.append(result > 0)
                    
                    end_time = time.time()
                    execution_times.append(end_time - start_time)
                    
                except Exception as e:
                    execution_results.append(False)
                    execution_times.append(0)
                
                # æ¸…ç†è¨˜æ†¶é«”
                del test_system, test_data
                gc.collect()
                
                time.sleep(0.5)  # çŸ­æš«ä¼‘æ¯
            
            # è©•ä¼°ç©©å®šæ€§
            success_rate = sum(execution_results) / len(execution_results)
            avg_execution_time = np.mean(execution_times)
            time_variance = np.var(execution_times)
            
            stability_metrics['repeated_execution'] = {
                'success_rate': success_rate,
                'avg_execution_time': avg_execution_time,
                'time_variance': time_variance,
                'executions': len(execution_results)
            }
            
            # ç©©å®šæ€§æ¨™æº–ï¼šæˆåŠŸç‡ > 80%ï¼Œæ™‚é–“æ–¹å·® < å¹³å‡æ™‚é–“çš„50%
            repeat_stable = (success_rate > 0.8 and time_variance < avg_execution_time * 0.5)
            stability_test_results['repeated_execution'] = repeat_stable
            
            print(f"   åŸ·è¡ŒæˆåŠŸç‡: {success_rate:.1%}")
            print(f"   å¹³å‡åŸ·è¡Œæ™‚é–“: {avg_execution_time:.3f}ç§’")
            print(f"   æ™‚é–“ç©©å®šæ€§: {'âœ… ç©©å®š' if repeat_stable else 'âŒ ä¸ç©©å®š'}")
            
        except Exception as e:
            print(f"âŒ é‡è¤‡åŸ·è¡Œç©©å®šæ€§æ¸¬è©¦ç•°å¸¸: {e}")
        
        # 2. ä¸¦è¡Œè™•ç†ç©©å®šæ€§æ¸¬è©¦
        print("\nğŸ”„ æ¸¬è©¦ä¸¦è¡Œè™•ç†ç©©å®šæ€§...")
        
        try:
            def parallel_test_worker(worker_id):
                """ä¸¦è¡Œæ¸¬è©¦å·¥ä½œå‡½æ•¸"""
                try:
                    # å‰µå»ºæ¸¬è©¦è³‡æ–™
                    test_data = pd.DataFrame({
                        'å‚™æŸ¥ç·¨è™Ÿ': [f'WORKER{worker_id}_{j:03d}' for j in range(50)],
                        'ç¸£å¸‚': np.random.choice(['å°åŒ—å¸‚', 'æ–°åŒ—å¸‚'], 50),
                        'æ·¨å»åŒ–ç‡(%)': np.random.uniform(30, 70, 50)
                    })
                    
                    # åŸ·è¡Œè¨ˆç®—
                    result = test_data.groupby('ç¸£å¸‚')['æ·¨å»åŒ–ç‡(%)'].mean().to_dict()
                    
                    return {'worker_id': worker_id, 'success': True, 'result': result}
                    
                except Exception as e:
                    return {'worker_id': worker_id, 'success': False, 'error': str(e)}
            
            # ä½¿ç”¨å¤šç·šç¨‹åŸ·è¡Œä¸¦è¡Œæ¸¬è©¦
            max_workers = min(4, psutil.cpu_count())
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                # æäº¤ä¸¦è¡Œä»»å‹™
                futures = [executor.submit(parallel_test_worker, i) for i in range(max_workers)]
                
                # æ”¶é›†çµæœ
                parallel_results = []
                for future in concurrent.futures.as_completed(futures, timeout=30):
                    try:
                        result = future.result()
                        parallel_results.append(result)
                    except Exception as e:
                        parallel_results.append({'success': False, 'error': str(e)})
            
            # è©•ä¼°ä¸¦è¡Œç©©å®šæ€§
            parallel_success_rate = sum(1 for r in parallel_results if r['success']) / len(parallel_results)
            
            stability_metrics['concurrent_processing'] = {
                'workers': max_workers,
                'success_rate': parallel_success_rate,
                'results': parallel_results
            }
            
            # ä¸¦è¡Œç©©å®šæ€§æ¨™æº–ï¼šæˆåŠŸç‡ > 90%
            concurrent_stable = parallel_success_rate > 0.9
            stability_test_results['concurrent_processing'] = concurrent_stable
            
            print(f"   ä¸¦è¡Œå·¥ä½œæ•¸: {max_workers}")
            print(f"   ä¸¦è¡ŒæˆåŠŸç‡: {parallel_success_rate:.1%}")
            print(f"   ä¸¦è¡Œç©©å®šæ€§: {'âœ… ç©©å®š' if concurrent_stable else 'âŒ ä¸ç©©å®š'}")
            
        except Exception as e:
            print(f"âŒ ä¸¦è¡Œè™•ç†ç©©å®šæ€§æ¸¬è©¦ç•°å¸¸: {e}")
        
        # 3. è¨˜æ†¶é«”ç©©å®šæ€§æ¸¬è©¦
        print("\nğŸ”„ æ¸¬è©¦è¨˜æ†¶é«”ç©©å®šæ€§...")
        
        try:
            memory_samples = []
            data_sizes = [1000, 5000, 10000, 20000, 10000, 5000, 1000]  # è¨˜æ†¶é«”ä½¿ç”¨æ³¢å‹•
            
            for size in data_sizes:
                # è¨˜éŒ„è¨˜æ†¶é«”ä½¿ç”¨å‰
                mem_before = psutil.virtual_memory().used
                
                # å‰µå»ºä¸åŒå¤§å°çš„æ¸¬è©¦è³‡æ–™
                large_data = pd.DataFrame({
                    'id': range(size),
                    'data': np.random.randn(size),
                    'category': np.random.choice(['A', 'B', 'C'], size)
                })
                
                # åŸ·è¡Œä¸€äº›æ“ä½œ
                result = large_data.groupby('category').agg({'data': ['mean', 'sum', 'count']})
                
                # è¨˜éŒ„è¨˜æ†¶é«”ä½¿ç”¨å¾Œ
                mem_after = psutil.virtual_memory().used
                memory_delta = mem_after - mem_before
                
                memory_samples.append({
                    'data_size': size,
                    'memory_delta_mb': memory_delta / (1024 * 1024),
                    'memory_percent': psutil.virtual_memory().percent
                })
                
                # æ¸…ç†
                del large_data, result
                gc.collect()
                
                time.sleep(0.2)
            
            # è©•ä¼°è¨˜æ†¶é«”ç©©å®šæ€§
            max_memory_usage = max(sample['memory_percent'] for sample in memory_samples)
            memory_variance = np.var([sample['memory_delta_mb'] for sample in memory_samples])
            
            stability_metrics['memory_stability'] = {
                'max_memory_percent': max_memory_usage,
                'memory_variance': memory_variance,
                'samples': memory_samples
            }
            
            # è¨˜æ†¶é«”ç©©å®šæ€§æ¨™æº–ï¼šæœ€å¤§ä½¿ç”¨ç‡ < 85%ï¼Œæ–¹å·®åˆç†
            memory_stable = (max_memory_usage < 85 and memory_variance < 100)
            stability_test_results['memory_stability'] = memory_stable
            
            print(f"   æœ€å¤§è¨˜æ†¶é«”ä½¿ç”¨ç‡: {max_memory_usage:.1f}%")
            print(f"   è¨˜æ†¶é«”ä½¿ç”¨æ–¹å·®: {memory_variance:.2f} MBÂ²")
            print(f"   è¨˜æ†¶é«”ç©©å®šæ€§: {'âœ… ç©©å®š' if memory_stable else 'âŒ ä¸ç©©å®š'}")
            
        except Exception as e:
            print(f"âŒ è¨˜æ†¶é«”ç©©å®šæ€§æ¸¬è©¦ç•°å¸¸: {e}")
        
        # 4. é•·æ™‚é–“é‹è¡Œç©©å®šæ€§æ¸¬è©¦ï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼‰
        print("\nğŸ”„ æ¸¬è©¦é•·æ™‚é–“é‹è¡Œç©©å®šæ€§...")
        
        try:
            long_run_start_time = time.time()
            long_run_iterations = 20  # ç°¡åŒ–ç‚º20æ¬¡è¿­ä»£
            long_run_success_count = 0
            
            for i in range(long_run_iterations):
                try:
                    # æ¨¡æ“¬é•·æ™‚é–“é‹è¡Œçš„ä»»å‹™
                    test_data = pd.DataFrame({
                        'id': range(1000),
                        'value': np.random.randn(1000)
                    })
                    
                    # åŸ·è¡Œä¸€äº›è¨ˆç®—
                    stats = test_data['value'].describe()
                    correlation = test_data['id'].corr(test_data['value'])
                    
                    long_run_success_count += 1
                    
                    # å®šæœŸæ¸…ç†
                    if i % 5 == 0:
                        gc.collect()
                    
                    time.sleep(0.1)  # æ¨¡æ“¬è™•ç†æ™‚é–“
                    
                except Exception as e:
                    print(f"   ç¬¬ {i+1} æ¬¡è¿­ä»£å¤±æ•—: {e}")
            
            long_run_total_time = time.time() - long_run_start_time
            long_run_success_rate = long_run_success_count / long_run_iterations
            
            stability_metrics['long_running'] = {
                'iterations': long_run_iterations,
                'success_count': long_run_success_count,
                'success_rate': long_run_success_rate,
                'total_time': long_run_total_time
            }
            
            # é•·æ™‚é–“ç©©å®šæ€§æ¨™æº–ï¼šæˆåŠŸç‡ > 95%
            long_run_stable = long_run_success_rate > 0.95
            stability_test_results['long_running_stability'] = long_run_stable
            
            print(f"   è¿­ä»£æ¬¡æ•¸: {long_run_iterations}")
            print(f"   æˆåŠŸæ¬¡æ•¸: {long_run_success_count}")
            print(f"   æˆåŠŸç‡: {long_run_success_rate:.1%}")
            print(f"   ç¸½åŸ·è¡Œæ™‚é–“: {long_run_total_time:.2f}ç§’")
            print(f"   é•·æ™‚é–“ç©©å®šæ€§: {'âœ… ç©©å®š' if long_run_stable else 'âŒ ä¸ç©©å®š'}")
            
        except Exception as e:
            print(f"âŒ é•·æ™‚é–“é‹è¡Œç©©å®šæ€§æ¸¬è©¦ç•°å¸¸: {e}")
        
        # 5. æ•…éšœæ¢å¾©èƒ½åŠ›æ¸¬è©¦
        print("\nğŸ”„ æ¸¬è©¦æ•…éšœæ¢å¾©èƒ½åŠ›...")
        
        try:
            recovery_tests = []
            
            # æ¸¬è©¦1ï¼šè™•ç†ç„¡æ•ˆè³‡æ–™å¾Œçš„æ¢å¾©
            try:
                # æ•…æ„ä½¿ç”¨ç„¡æ•ˆè³‡æ–™
                invalid_data = pd.DataFrame({
                    'invalid_column': [None, None, None]
                })
                
                # å˜—è©¦è™•ç†
                try:
                    result = invalid_data['non_existent'].mean()
                except:
                    # æ¨¡æ“¬æ¢å¾©è™•ç†
                    result = 0
                
                recovery_tests.append(True)  # æˆåŠŸæ¢å¾©
                
            except Exception:
                recovery_tests.append(False)
            
            # æ¸¬è©¦2ï¼šè¨˜æ†¶é«”ä¸è¶³æƒ…æ³çš„æ¢å¾©ï¼ˆæ¨¡æ“¬ï¼‰
            try:
                # æ¨¡æ“¬è¨˜æ†¶é«”æª¢æŸ¥å’Œè™•ç†
                current_memory = psutil.virtual_memory().percent
                
                if current_memory > 95:
                    # æ¨¡æ“¬è¨˜æ†¶é«”æ¸…ç†
                    gc.collect()
                
                recovery_tests.append(True)
                
            except Exception:
                recovery_tests.append(False)
            
            # æ¸¬è©¦3ï¼šè¨ˆç®—ç•°å¸¸å¾Œçš„æ¢å¾©
            try:
                # æ•…æ„è§¸ç™¼è¨ˆç®—ç•°å¸¸
                try:
                    result = 1 / 0
                except ZeroDivisionError:
                    # æ¨¡æ“¬æ¢å¾©é‚è¼¯
                    result = float('inf')
                
                recovery_tests.append(True)
                
            except Exception:
                recovery_tests.append(False)
            
            recovery_success_rate = sum(recovery_tests) / len(recovery_tests)
            
            stability_metrics['recovery_capability'] = {
                'recovery_tests': len(recovery_tests),
                'successful_recoveries': sum(recovery_tests),
                'recovery_rate': recovery_success_rate
            }
            
            # æ¢å¾©èƒ½åŠ›æ¨™æº–ï¼šæ¢å¾©ç‡ > 80%
            recovery_capable = recovery_success_rate > 0.8
            stability_test_results['recovery_capability'] = recovery_capable
            
            print(f"   æ¢å¾©æ¸¬è©¦æ•¸: {len(recovery_tests)}")
            print(f"   æˆåŠŸæ¢å¾©æ•¸: {sum(recovery_tests)}")
            print(f"   æ¢å¾©æˆåŠŸç‡: {recovery_success_rate:.1%}")
            print(f"   æ¢å¾©èƒ½åŠ›: {'âœ… è‰¯å¥½' if recovery_capable else 'âŒ ä¸è¶³'}")
            
        except Exception as e:
            print(f"âŒ æ•…éšœæ¢å¾©èƒ½åŠ›æ¸¬è©¦ç•°å¸¸: {e}")
        
    except Exception as e:
        print(f"âŒ ç³»çµ±ç©©å®šæ€§æ¸¬è©¦éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    # ç©©å®šæ€§æ¸¬è©¦ç¸½çµ
    passed_stability_tests = sum(stability_test_results.values())
    total_stability_tests = len(stability_test_results)
    stability_score = (passed_stability_tests / total_stability_tests) * 100
    
    print(f"\nğŸ“Š ç³»çµ±ç©©å®šæ€§æ¸¬è©¦çµæœ:")
    print(f"   é€šéé …ç›®: {passed_stability_tests}/{total_stability_tests}")
    print(f"   ç©©å®šæ€§è©•åˆ†: {stability_score:.1f}/100")
    
    for test_name, result in stability_test_results.items():
        status = "âœ…" if result else "âŒ"
        print(f"   {status} {test_name}")
    
    # ç©©å®šæ€§ç­‰ç´šè©•å®š
    if stability_score >= 90:
        stability_grade = "ğŸ† éå¸¸ç©©å®š"
    elif stability_score >= 80:
        stability_grade = "ğŸ¥‡ ç©©å®š"
    elif stability_score >= 70:
        stability_grade = "ğŸ¥ˆ åŸºæœ¬ç©©å®š"
    else:
        stability_grade = "ğŸ¥‰ éœ€è¦æ”¹å–„"
    
    print(f"\nğŸ¯ ç³»çµ±ç©©å®šæ€§ç­‰ç´š: {stability_grade}")
    
    return stability_score >= 80, {
        'test_results': stability_test_results,
        'stability_metrics': stability_metrics,
        'stability_score': stability_score,
        'stability_grade': stability_grade
    }

# %%
# åŸ·è¡Œç³»çµ±ç©©å®šæ€§æ¸¬è©¦
stability_pass, stability_details = run_system_stability_tests()

# %% [markdown]
# ## 11. æœ€çµ‚é©—æ”¶æ¸¬è©¦

# %%
def run_final_acceptance_tests():
    """
    åŸ·è¡Œæœ€çµ‚é©—æ”¶æ¸¬è©¦
    """
    
    print("ğŸ¯ æœ€çµ‚é©—æ”¶æ¸¬è©¦")
    print("=" * 50)
    
    acceptance_criteria = {
        'functional_requirements': False,
        'performance_requirements': False,
        'quality_requirements': False,
        'usability_requirements': False,
        'reliability_requirements': False
    }
    
    acceptance_details = {}
    
    try:
        # 1. åŠŸèƒ½éœ€æ±‚é©—æ”¶
        print("ğŸ”„ é©—æ”¶åŠŸèƒ½éœ€æ±‚...")
        
        try:
            functional_score = 0
            total_functional_tests = 8
            
            # æª¢æŸ¥æ ¸å¿ƒåŠŸèƒ½æ¨¡çµ„
            test_system = PreSaleHousingAnalysisSystem()
            
            # è³‡æ–™è¼‰å…¥åŠŸèƒ½
            if hasattr(test_system, 'load_and_validate_data'):
                functional_score += 1
            
            # è³‡æ–™æ¸…ç†åŠŸèƒ½
            if hasattr(test_system, 'clean_and_standardize_data'):
                functional_score += 1
            
            # é‡è¤‡äº¤æ˜“è™•ç†åŠŸèƒ½
            if hasattr(test_system, 'process_duplicate_transactions'):
                functional_score += 1
            
            # ä¸‰å±¤ç´šåˆ†æåŠŸèƒ½
            if (hasattr(test_system, 'generate_community_level_analysis') and
                hasattr(test_system, 'generate_district_level_analysis') and
                hasattr(test_system, 'generate_city_level_analysis')):
                functional_score += 3
            
            # å ±å‘Šç”ŸæˆåŠŸèƒ½
            if hasattr(test_system, 'generate_all_reports'):
                functional_score += 1
            
            # ç³»çµ±é©—è­‰åŠŸèƒ½
            if hasattr(test_system, 'validate_system_integrity'):
                functional_score += 1
            
            functional_completeness = functional_score / total_functional_tests
            
            acceptance_details['functional_requirements'] = {
                'completeness': functional_completeness,
                'implemented_functions': functional_score,
                'required_functions': total_functional_tests
            }
            
            # åŠŸèƒ½éœ€æ±‚æ¨™æº–ï¼šå®Œæ•´æ€§ > 90%
            acceptance_criteria['functional_requirements'] = functional_completeness > 0.9
            
            print(f"   åŠŸèƒ½å®Œæ•´æ€§: {functional_completeness:.1%}")
            print(f"   å¯¦ç¾åŠŸèƒ½: {functional_score}/{total_functional_tests}")
            print(f"   åŠŸèƒ½éœ€æ±‚: {'âœ… é€šé' if acceptance_criteria['functional_requirements'] else 'âŒ æœªé€šé'}")
            
        except Exception as e:
            print(f"âŒ åŠŸèƒ½éœ€æ±‚é©—æ”¶ç•°å¸¸: {e}")
        
        # 2. æ•ˆèƒ½éœ€æ±‚é©—æ”¶
        print("\nğŸ”„ é©—æ”¶æ•ˆèƒ½éœ€æ±‚...")
        
        try:
            # åŸºæ–¼å‰é¢çš„æ•ˆèƒ½æ¸¬è©¦çµæœ
            performance_score = performance_test_results.get('overall_score', 0)
            
            # æª¢æŸ¥é—œéµæ•ˆèƒ½æŒ‡æ¨™
            memory_efficiency = performance_test_results.get('memory_efficiency', {}).get('memory_efficiency_score') == 'GOOD'
            execution_speed = performance_test_results.get('execution_speed', {}).get('overall_performance') == 'GOOD'
            resource_health = performance_test_results.get('resource_utilization', {}).get('resource_health') == 'GOOD'
            scalability = performance_test_results.get('scalability', {}).get('scalability_trend') == 'LINEAR'
            
            performance_checks = [memory_efficiency, execution_speed, resource_health, scalability]
            performance_pass_rate = sum(performance_checks) / len(performance_checks)
            
            acceptance_details['performance_requirements'] = {
                'overall_score': performance_score,
                'pass_rate': performance_pass_rate,
                'memory_efficiency': memory_efficiency,
                'execution_speed': execution_speed,
                'resource_health': resource_health,
                'scalability': scalability
            }
            
            # æ•ˆèƒ½éœ€æ±‚æ¨™æº–ï¼šç¸½åˆ† > 70ï¼Œé€šéç‡ > 75%
            acceptance_criteria['performance_requirements'] = (performance_score > 70 and performance_pass_rate > 0.75)
            
            print(f"   æ•ˆèƒ½ç¸½åˆ†: {performance_score}/100")
            print(f"   æ•ˆèƒ½æª¢æŸ¥é€šéç‡: {performance_pass_rate:.1%}")
            print(f"   æ•ˆèƒ½éœ€æ±‚: {'âœ… é€šé' if acceptance_criteria['performance_requirements'] else 'âŒ æœªé€šé'}")
            
        except Exception as e:
            print(f"âŒ æ•ˆèƒ½éœ€æ±‚é©—æ”¶ç•°å¸¸: {e}")
        
        # 3. å“è³ªéœ€æ±‚é©—æ”¶
        print("\nğŸ”„ é©—æ”¶å“è³ªéœ€æ±‚...")
        
        try:
            # åŸºæ–¼è³‡æ–™å“è³ªé©—è­‰çµæœ
            quality_score = data_quality_details.get('quality_score', 0)
            quality_validations = data_quality_details.get('validation_results', {})
            
            # æª¢æŸ¥å“è³ªæ¨™æº–
            data_completeness = quality_validations.get('completeness_check', False)
            data_consistency = quality_validations.get('consistency_check', False)
            data_accuracy = quality_validations.get('accuracy_check', False)
            data_validity = quality_validations.get('validity_check', False)
            
            quality_checks = [data_completeness, data_consistency, data_accuracy, data_validity]
            quality_pass_rate = sum(quality_checks) / len(quality_checks)
            
            acceptance_details['quality_requirements'] = {
                'quality_score': quality_score,
                'pass_rate': quality_pass_rate,
                'completeness': data_completeness,
                'consistency': data_consistency,
                'accuracy': data_accuracy,
                'validity': data_validity
            }
            
            # å“è³ªéœ€æ±‚æ¨™æº–ï¼šå“è³ªåˆ†æ•¸ > 80ï¼Œé€šéç‡ > 80%
            acceptance_criteria['quality_requirements'] = (quality_score > 80 and quality_pass_rate > 0.8)
            
            print(f"   å“è³ªåˆ†æ•¸: {quality_score}/100")
            print(f"   å“è³ªæª¢æŸ¥é€šéç‡: {quality_pass_rate:.1%}")
            print(f"   å“è³ªéœ€æ±‚: {'âœ… é€šé' if acceptance_criteria['quality_requirements'] else 'âŒ æœªé€šé'}")
            
        except Exception as e:
            print(f"âŒ å“è³ªéœ€æ±‚é©—æ”¶ç•°å¸¸: {e}")
        
        # 4. å¯ç”¨æ€§éœ€æ±‚é©—æ”¶
        print("\nğŸ”„ é©—æ”¶å¯ç”¨æ€§éœ€æ±‚...")
        
        try:
            usability_score = 0
            total_usability_tests = 5
            
            # æ˜“ç”¨æ€§æª¢æŸ¥
            # 1. ç³»çµ±åˆå§‹åŒ–ç°¡å–®æ€§
            try:
                test_system = PreSaleHousingAnalysisSystem()
                usability_score += 1
            except:
                pass
            
            # 2. é…ç½®æª”æ¡ˆå¯è®€æ€§
            if hasattr(test_system, 'config') and isinstance(test_system.config, dict):
                usability_score += 1
            
            # 3. éŒ¯èª¤è¨Šæ¯æ¸…æ™°æ€§ï¼ˆåŸºæ–¼éŒ¯èª¤è™•ç†æ¸¬è©¦ï¼‰
            error_handling_pass = error_handling_details.get('file_not_found_handling', False)
            if error_handling_pass:
                usability_score += 1
            
            # 4. æ—¥èªŒè¨˜éŒ„å®Œæ•´æ€§
            if hasattr(test_system, 'logger'):
                usability_score += 1
            
            # 5. çµæœè¼¸å‡ºå¯è®€æ€§ï¼ˆåŸºæ–¼è¼¸å‡ºå®Œæ•´æ€§æ¸¬è©¦ï¼‰
            output_integrity_pass = output_integrity_details.get('format_compliance', False)
            if output_integrity_pass:
                usability_score += 1
            
            usability_ratio = usability_score / total_usability_tests
            
            acceptance_details['usability_requirements'] = {
                'usability_score': usability_score,
                'total_tests': total_usability_tests,
                'usability_ratio': usability_ratio
            }
            
            # å¯ç”¨æ€§éœ€æ±‚æ¨™æº–ï¼šå¯ç”¨æ€§æ¯”ç‡ > 80%
            acceptance_criteria['usability_requirements'] = usability_ratio > 0.8
            
            print(f"   å¯ç”¨æ€§è©•åˆ†: {usability_score}/{total_usability_tests}")
            print(f"   å¯ç”¨æ€§æ¯”ç‡: {usability_ratio:.1%}")
            print(f"   å¯ç”¨æ€§éœ€æ±‚: {'âœ… é€šé' if acceptance_criteria['usability_requirements'] else 'âŒ æœªé€šé'}")
            
        except Exception as e:
            print(f"âŒ å¯ç”¨æ€§éœ€æ±‚é©—æ”¶ç•°å¸¸: {e}")
        
        # 5. å¯é æ€§éœ€æ±‚é©—æ”¶
        print("\nğŸ”„ é©—æ”¶å¯é æ€§éœ€æ±‚...")
        
        try:
            # åŸºæ–¼ç©©å®šæ€§æ¸¬è©¦çµæœ
            stability_score = stability_details.get('stability_score', 0)
            stability_tests = stability_details.get('test_results', {})
            
            # æª¢æŸ¥å¯é æ€§æŒ‡æ¨™
            repeated_execution = stability_tests.get('repeated_execution', False)
            memory_stability = stability_tests.get('memory_stability', False)
            recovery_capability = stability_tests.get('recovery_capability', False)
            
            reliability_checks = [repeated_execution, memory_stability, recovery_capability]
            reliability_pass_rate = sum(reliability_checks) / len(reliability_checks)
            
            acceptance_details['reliability_requirements'] = {
                'stability_score': stability_score,
                'pass_rate': reliability_pass_rate,
                'repeated_execution': repeated_execution,
                'memory_stability': memory_stability,
                'recovery_capability': recovery_capability
            }
            
            # å¯é æ€§éœ€æ±‚æ¨™æº–ï¼šç©©å®šæ€§åˆ†æ•¸ > 80ï¼Œé€šéç‡ > 75%
            acceptance_criteria['reliability_requirements'] = (stability_score > 80 and reliability_pass_rate > 0.75)
            
            print(f"   ç©©å®šæ€§åˆ†æ•¸: {stability_score}/100")
            print(f"   å¯é æ€§æª¢æŸ¥é€šéç‡: {reliability_pass_rate:.1%}")
            print(f"   å¯é æ€§éœ€æ±‚: {'âœ… é€šé' if acceptance_criteria['reliability_requirements'] else 'âŒ æœªé€šé'}")
            
        except Exception as e:
            print(f"âŒ å¯é æ€§éœ€æ±‚é©—æ”¶ç•°å¸¸: {e}")
        
    except Exception as e:
        print(f"âŒ æœ€çµ‚é©—æ”¶æ¸¬è©¦éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    # é©—æ”¶çµæœç¸½çµ
    passed_criteria = sum(acceptance_criteria.values())
    total_criteria = len(acceptance_criteria)
    acceptance_score = (passed_criteria / total_criteria) * 100
    
    print(f"\nğŸ“Š æœ€çµ‚é©—æ”¶æ¸¬è©¦çµæœ:")
    print(f"   é€šéæ¨™æº–: {passed_criteria}/{total_criteria}")
    print(f"   é©—æ”¶è©•åˆ†: {acceptance_score:.1f}/100")
    
    for criterion, result in acceptance_criteria.items():
        status = "âœ…" if result else "âŒ"
        print(f"   {status} {criterion}")
    
    # é©—æ”¶çµè«–
    if acceptance_score >= 90:
        acceptance_conclusion = "ğŸ† å®Œå…¨é€šéé©—æ”¶"
        deployment_ready = True
    elif acceptance_score >= 80:
        acceptance_conclusion = "ğŸ¥‡ åŸºæœ¬é€šéé©—æ”¶"
        deployment_ready = True
    elif acceptance_score >= 70:
        acceptance_conclusion = "ğŸ¥ˆ æœ‰æ¢ä»¶é€šéé©—æ”¶"
        deployment_ready = False
    else:
        acceptance_conclusion = "ğŸ¥‰ æœªé€šéé©—æ”¶"
        deployment_ready = False
    
    print(f"\nğŸ¯ é©—æ”¶çµè«–: {acceptance_conclusion}")
    print(f"ğŸš€ éƒ¨ç½²å°±ç·’: {'æ˜¯' if deployment_ready else 'å¦'}")
    
    if not deployment_ready:
        failed_criteria = [criterion for criterion, result in acceptance_criteria.items() if not result]
        print(f"\nğŸ’¡ éœ€è¦æ”¹å–„çš„é …ç›®:")
        for criterion in failed_criteria:
            print(f"   â€¢ {criterion}")
    
    return deployment_ready, {
        'acceptance_criteria': acceptance_criteria,
        'acceptance_details': acceptance_details,
        'acceptance_score': acceptance_score,
        'acceptance_conclusion': acceptance_conclusion,
        'deployment_ready': deployment_ready
    }

# %%
# åŸ·è¡Œæœ€çµ‚é©—æ”¶æ¸¬è©¦
deployment_ready, acceptance_details_final = run_final_acceptance_tests()

# %% [markdown]
# ## 12. ç³»çµ±éƒ¨ç½²æº–å‚™

# %%
def prepare_system_deployment():
    """
    æº–å‚™ç³»çµ±éƒ¨ç½²
    """
    
    print("ğŸš€ ç³»çµ±éƒ¨ç½²æº–å‚™")
    print("=" * 50)
    
    deployment_checklist = {
        'code_quality': False,
        'documentation': False,
        'configuration': False,
        'testing_coverage': False,
        'performance_optimization': False,
        'security_review': False,
        'deployment_package': False
    }
    
    deployment_artifacts = {}
    
    try:
        # 1. ç¨‹å¼ç¢¼å“è³ªæª¢æŸ¥
        print("ğŸ”„ æª¢æŸ¥ç¨‹å¼ç¢¼å“è³ª...")
        
        try:
            code_quality_score = 0
            total_quality_checks = 5
            
            # æª¢æŸ¥æ¨¡çµ„çµæ§‹
            system = PreSaleHousingAnalysisSystem()
            if hasattr(system, '__init__') and callable(getattr(system, '__init__')):
                code_quality_score += 1
            
            # æª¢æŸ¥éŒ¯èª¤è™•ç†
            if error_handling_success:
                code_quality_score += 1
            
            # æª¢æŸ¥æ•ˆèƒ½è¡¨ç¾
            if performance_test_results.get('overall_score', 0) > 60:
                code_quality_score += 1
            
            # æª¢æŸ¥ç¨‹å¼ç¢¼å¯è®€æ€§ï¼ˆæ¨¡æ“¬ï¼‰
            if hasattr(system, '_get_default_config'):
                code_quality_score += 1
            
            # æª¢æŸ¥æ¨¡çµ„åŒ–ç¨‹åº¦
            if len([attr for attr in dir(system) if not attr.startswith('_')]) > 10:
                code_quality_score += 1
            
            code_quality_ratio = code_quality_score / total_quality_checks
            deployment_checklist['code_quality'] = code_quality_ratio > 0.8
            
            print(f"   ç¨‹å¼ç¢¼å“è³ªè©•åˆ†: {code_quality_score}/{total_quality_checks}")
            print(f"   å“è³ªæ¨™æº–: {'âœ… é”æ¨™' if deployment_checklist['code_quality'] else 'âŒ æœªé”æ¨™'}")
            
        except Exception as e:
            print(f"âŒ ç¨‹å¼ç¢¼å“è³ªæª¢æŸ¥ç•°å¸¸: {e}")
        
        # 2. æ–‡ä»¶å®Œæ•´æ€§æª¢æŸ¥
        print("\nğŸ”„ æª¢æŸ¥æ–‡ä»¶å®Œæ•´æ€§...")
        
        try:
            documentation_score = 0
            total_doc_checks = 4
            
            # æª¢æŸ¥é¡åˆ¥æ–‡ä»¶
            if system.__doc__ or hasattr(system, '__class__'):
                documentation_score += 1
            
            # æª¢æŸ¥æ–¹æ³•æ–‡ä»¶
            methods_with_docs = [
                method for method in dir(system) 
                if not method.startswith('_') and callable(getattr(system, method))
                and getattr(getattr(system, method), '__doc__', None)
            ]
            if len(methods_with_docs) > 5:
                documentation_score += 1
            
            # æª¢æŸ¥é…ç½®æ–‡ä»¶
            if hasattr(system, 'config') and isinstance(system.config, dict):
                documentation_score += 1
            
            # æª¢æŸ¥ä½¿ç”¨ç¯„ä¾‹ï¼ˆæ¨¡æ“¬ï¼‰
            documentation_score += 1  # å‡è¨­æœ‰ç¯„ä¾‹
            
            documentation_ratio = documentation_score / total_doc_checks
            deployment_checklist['documentation'] = documentation_ratio > 0.75
            
            print(f"   æ–‡ä»¶å®Œæ•´æ€§è©•åˆ†: {documentation_score}/{total_doc_checks}")
            print(f"   æ–‡ä»¶æ¨™æº–: {'âœ… é”æ¨™' if deployment_checklist['documentation'] else 'âŒ æœªé”æ¨™'}")
            
        except Exception as e:
            print(f"âŒ æ–‡ä»¶å®Œæ•´æ€§æª¢æŸ¥ç•°å¸¸: {e}")
        
        # 3. é…ç½®ç®¡ç†æª¢æŸ¥
        print("\nğŸ”„ æª¢æŸ¥é…ç½®ç®¡ç†...")
        
        try:
            config_score = 0
            total_config_checks = 4
            
            # æª¢æŸ¥é è¨­é…ç½®
            if hasattr(system, '_get_default_config'):
                config_score += 1
            
            # æª¢æŸ¥é…ç½®é©—è­‰
            if 'data_paths' in system.config and 'processing' in system.config:
                config_score += 1
            
            # æª¢æŸ¥ç’°å¢ƒéš”é›¢
            if 'output_dir' in system.config.get('data_paths', {}):
                config_score += 1
            
            # æª¢æŸ¥é…ç½®å½ˆæ€§
            if system.config.get('processing', {}).get('chunk_size'):
                config_score += 1
            
            config_ratio = config_score / total_config_checks
            deployment_checklist['configuration'] = config_ratio > 0.75
            
            print(f"   é…ç½®ç®¡ç†è©•åˆ†: {config_score}/{total_config_checks}")
            print(f"   é…ç½®æ¨™æº–: {'âœ… é”æ¨™' if deployment_checklist['configuration'] else 'âŒ æœªé”æ¨™'}")
            
        except Exception as e:
            print(f"âŒ é…ç½®ç®¡ç†æª¢æŸ¥ç•°å¸¸: {e}")
        
        # 4. æ¸¬è©¦è¦†è“‹ç‡æª¢æŸ¥
        print("\nğŸ”„ æª¢æŸ¥æ¸¬è©¦è¦†è“‹ç‡...")
        
        try:
            testing_score = 0
            total_testing_areas = 6
            
            # æ¶æ§‹é©—è­‰
            if architecture_validation_result:
                testing_score += 1
            
            # æ•ˆèƒ½æ¸¬è©¦
            if performance_test_results:
                testing_score += 1
            
            # é‚Šç•Œæ¢ä»¶æ¸¬è©¦
            if boundary_test_success:
                testing_score += 1
            
            # éŒ¯èª¤è™•ç†æ¸¬è©¦
            if error_handling_success:
                testing_score += 1
            
            # è³‡æ–™å“è³ªæ¸¬è©¦
            if data_quality_pass:
                testing_score += 1
            
            # ç©©å®šæ€§æ¸¬è©¦
            if stability_pass:
                testing_score += 1
            
            testing_coverage = testing_score / total_testing_areas
            deployment_checklist['testing_coverage'] = testing_coverage > 0.8
            
            print(f"   æ¸¬è©¦è¦†è“‹ç‡: {testing_coverage:.1%}")
            print(f"   æ¸¬è©¦æ¨™æº–: {'âœ… é”æ¨™' if deployment_checklist['testing_coverage'] else 'âŒ æœªé”æ¨™'}")
            
        except Exception as e:
            print(f"âŒ æ¸¬è©¦è¦†è“‹ç‡æª¢æŸ¥ç•°å¸¸: {e}")
        
        # 5. æ•ˆèƒ½å„ªåŒ–æª¢æŸ¥
        print("\nğŸ”„ æª¢æŸ¥æ•ˆèƒ½å„ªåŒ–...")
        
        try:
            performance_score = performance_test_results.get('overall_score', 0)
            deployment_checklist['performance_optimization'] = performance_score > 70
            
            print(f"   æ•ˆèƒ½è©•åˆ†: {performance_score}/100")
            print(f"   æ•ˆèƒ½æ¨™æº–: {'âœ… é”æ¨™' if deployment_checklist['performance_optimization'] else 'âŒ æœªé”æ¨™'}")
            
        except Exception as e:
            print(f"âŒ æ•ˆèƒ½å„ªåŒ–æª¢æŸ¥ç•°å¸¸: {e}")
        
        # 6. å®‰å…¨æ€§æª¢æŸ¥
        print("\nğŸ”„ æª¢æŸ¥å®‰å…¨æ€§...")
        
        try:
            security_score = 0
            total_security_checks = 3
            
            # æª¢æŸ¥æª”æ¡ˆè·¯å¾‘å®‰å…¨
            if system.config.get('data_paths', {}).get('output_dir', '').startswith('../'):
                security_score += 1
            
            # æª¢æŸ¥è¼¸å…¥é©—è­‰
            if hasattr(system, '_validate_raw_data'):
                security_score += 1
            
            # æª¢æŸ¥éŒ¯èª¤è¨Šæ¯å®‰å…¨
            if error_handling_success:
                security_score += 1
            
            security_ratio = security_score / total_security_checks
            deployment_checklist['security_review'] = security_ratio > 0.7
            
            print(f"   å®‰å…¨æ€§è©•åˆ†: {security_score}/{total_security_checks}")
            print(f"   å®‰å…¨æ¨™æº–: {'âœ… é”æ¨™' if deployment_checklist['security_review'] else 'âŒ æœªé”æ¨™'}")
            
        except Exception as e:
            print(f"âŒ å®‰å…¨æ€§æª¢æŸ¥ç•°å¸¸: {e}")
        
        # 7. éƒ¨ç½²å¥—ä»¶æº–å‚™
        print("\nğŸ”„ æº–å‚™éƒ¨ç½²å¥—ä»¶...")
        
        try:
            current_date = datetime.now().strftime("%Y%m%d")
            
            # å‰µå»ºéƒ¨ç½²å¥—ä»¶è³‡è¨Š
            deployment_package = {
                'package_name': f'presale_housing_analysis_system_v1.0_{current_date}',
                'version': '1.0',
                'build_date': current_date,
                'components': [
                    'PreSaleHousingAnalysisSystem (ä¸»è¦åˆ†æå¼•æ“)',
                    'IntegratedPipelineTester (æ¸¬è©¦æ¡†æ¶)',
                    'é…ç½®ç®¡ç†æ¨¡çµ„',
                    'ä¸‰å±¤ç´šåˆ†ææ¨¡çµ„',
                    'éŒ¯èª¤è™•ç†æ©Ÿåˆ¶',
                    'æ•ˆèƒ½ç›£æ§ç³»çµ±',
                    'å“è³ªé©—è­‰æ¨¡çµ„'
                ],
                'dependencies': [
                    'pandas >= 1.3.0',
                    'numpy >= 1.20.0',
                    'matplotlib >= 3.3.0',
                    'seaborn >= 0.11.0',
                    'plotly >= 5.0.0',
                    'psutil >= 5.8.0',
                    'scikit-learn >= 1.0.0'
                ],
                'system_requirements': {
                    'python_version': '3.8+',
                    'memory': '8GB+ å»ºè­°',
                    'disk_space': '2GB+ å¯ç”¨ç©ºé–“',
                    'cpu': '4æ ¸å¿ƒ+ å»ºè­°'
                },
                'deployment_files': [
                    '11_integrated_pipeline_testing.py (ä¸»ç¨‹å¼)',
                    'config.json (é…ç½®æª”æ¡ˆ)',
                    'requirements.txt (ä¾è³´æ¸…å–®)',
                    'README.md (éƒ¨ç½²èªªæ˜)',
                    'CHANGELOG.md (ç‰ˆæœ¬æ­·å²)'
                ]
            }
            
            deployment_artifacts['package_info'] = deployment_package
            deployment_checklist['deployment_package'] = True
            
            print(f"   å¥—ä»¶åç¨±: {deployment_package['package_name']}")
            print(f"   ç‰ˆæœ¬: {deployment_package['version']}")
            print(f"   çµ„ä»¶æ•¸é‡: {len(deployment_package['components'])}")
            print(f"   éƒ¨ç½²å¥—ä»¶: âœ… æº–å‚™å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ éƒ¨ç½²å¥—ä»¶æº–å‚™ç•°å¸¸: {e}")
        
        # ç”Ÿæˆéƒ¨ç½²æ¸…å–®å ±å‘Š
        deployment_report = {
            'deployment_readiness': {
                'checklist': deployment_checklist,
                'passed_items': sum(deployment_checklist.values()),
                'total_items': len(deployment_checklist),
                'readiness_score': sum(deployment_checklist.values()) / len(deployment_checklist) * 100
            },
            'deployment_artifacts': deployment_artifacts,
            'test_summary': {
                'architecture_validation': architecture_validation_result,
                'performance_tests': performance_test_results.get('overall_score', 0),
                'boundary_tests': boundary_test_success,
                'error_handling': error_handling_success,
                'data_quality': data_quality_pass,
                'stability_tests': stability_pass,
                'final_acceptance': deployment_ready
            },
            'deployment_recommendations': []
        }
        
        # ç”Ÿæˆéƒ¨ç½²å»ºè­°
        if not all(deployment_checklist.values()):
            failed_items = [item for item, status in deployment_checklist.items() if not status]
            deployment_report['deployment_recommendations'] = [
                f"æ”¹å–„ {item} ä»¥æå‡éƒ¨ç½²å°±ç·’åº¦" for item in failed_items
            ]
        
        deployment_report['deployment_recommendations'].extend([
            "å»ºç«‹æŒçºŒæ•´åˆ/æŒçºŒéƒ¨ç½²(CI/CD)æµç¨‹",
            "è¨­å®šç›£æ§å’Œæ—¥èªŒç³»çµ±",
            "æº–å‚™ä½¿ç”¨è€…åŸ¹è¨“è³‡æ–™",
            "å»ºç«‹æŠ€è¡“æ”¯æ´æµç¨‹"
        ])
        
        # å„²å­˜éƒ¨ç½²å ±å‘Š
        deployment_report_file = f"../data/processed/deployment_readiness_report_{current_date}.json"
        with open(deployment_report_file, 'w', encoding='utf-8') as f:
            json.dump(deployment_report, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"\nâœ… éƒ¨ç½²å ±å‘Šå·²å„²å­˜: {deployment_report_file}")
        
    except Exception as e:
        print(f"âŒ ç³»çµ±éƒ¨ç½²æº–å‚™éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        deployment_report = {'error': str(e)}
    
    # éƒ¨ç½²å°±ç·’åº¦è©•ä¼°
    passed_checklist = sum(deployment_checklist.values())
    total_checklist = len(deployment_checklist)
    deployment_readiness = (passed_checklist / total_checklist) * 100
    
    print(f"\nğŸ“Š éƒ¨ç½²å°±ç·’åº¦è©•ä¼°:")
    print(f"   é€šéé …ç›®: {passed_checklist}/{total_checklist}")
    print(f"   å°±ç·’åº¦è©•åˆ†: {deployment_readiness:.1f}/100")
    
    for item, status in deployment_checklist.items():
        status_icon = "âœ…" if status else "âŒ"
        print(f"   {status_icon} {item}")
    
    # éƒ¨ç½²å»ºè­°
    if deployment_readiness >= 90:
        deployment_status = "ğŸš€ å®Œå…¨å°±ç·’ï¼Œå¯ç«‹å³éƒ¨ç½²"
    elif deployment_readiness >= 80:
        deployment_status = "ğŸŸ¡ åŸºæœ¬å°±ç·’ï¼Œå»ºè­°ä¿®æ­£å¾Œéƒ¨ç½²"
    elif deployment_readiness >= 70:
        deployment_status = "ğŸŸ  éƒ¨åˆ†å°±ç·’ï¼Œéœ€è¦æ”¹å–„å¾Œéƒ¨ç½²"
    else:
        deployment_status = "ğŸ”´ æœªå°±ç·’ï¼Œéœ€è¦é‡å¤§æ”¹å–„"
    
    print(f"\nğŸ¯ éƒ¨ç½²ç‹€æ…‹: {deployment_status}")
    
    return deployment_readiness >= 80, deployment_report

# %%
# åŸ·è¡Œç³»çµ±éƒ¨ç½²æº–å‚™
deployment_ready_final, deployment_report = prepare_system_deployment()

# %% [markdown]
# ## ç¶œåˆæ¸¬è©¦ç¸½çµèˆ‡ç³»çµ±é©—è­‰

# %%
# ç¶œåˆæ¸¬è©¦ç¸½çµèˆ‡æœ€çµ‚é©—è­‰
print("\n" + "="*80)
print("ğŸ Notebook 11 - æ•´åˆæµç¨‹æ¸¬è©¦ç³»çµ± æœ€çµ‚ç¸½çµ")
print("="*80)

# åŸ·è¡Œå®Œæ•´æµç¨‹æ¸¬è©¦
print("ğŸš€ åŸ·è¡Œå®Œæ•´ç«¯åˆ°ç«¯æµç¨‹æ¸¬è©¦...")

try:
    # å‰µå»ºæ•´åˆæ¸¬è©¦å¯¦ä¾‹
    final_pipeline_tester = IntegratedPipelineTester()
    
    # åŸ·è¡Œå®Œæ•´æµç¨‹æ¸¬è©¦
    final_test_results = final_pipeline_tester.run_full_pipeline_test()
    
    print(f"\nğŸ“Š å®Œæ•´æµç¨‹æ¸¬è©¦çµæœ:")
    print(f"   æ•´é«”æˆåŠŸ: {'âœ… æ˜¯' if final_test_results['overall_success'] else 'âŒ å¦'}")
    print(f"   ç¸½åŸ·è¡Œæ™‚é–“: {final_test_results['performance_summary']['total_execution_time']:.2f}ç§’")
    print(f"   å¹³å‡æ­¥é©Ÿæ™‚é–“: {final_test_results['performance_summary']['avg_step_time']:.2f}ç§’")
    
    print(f"\nğŸ“‹ å„æ­¥é©ŸåŸ·è¡Œçµæœ:")
    for step_name, step_result in final_test_results['step_results'].items():
        status = "âœ…" if step_result['success'] else "âŒ"
        time_taken = step_result['execution_time']
        print(f"   {status} {step_name}: {time_taken:.2f}ç§’")
    
except Exception as e:
    print(f"âŒ å®Œæ•´æµç¨‹æ¸¬è©¦å¤±æ•—: {e}")
    final_test_results = {'overall_success': False, 'error': str(e)}

# è¨ˆç®—ç¶œåˆè©•åˆ†
print(f"\nğŸ“ˆ ç¶œåˆæ¸¬è©¦è©•åˆ†çµ±è¨ˆ:")

test_scores = {
    'ç³»çµ±æ¶æ§‹é©—è­‰': 100 if architecture_validation_result else 0,
    'æ•ˆèƒ½æ¸¬è©¦': performance_test_results.get('overall_score', 0),
    'é‚Šç•Œæ¢ä»¶æ¸¬è©¦': 100 if boundary_test_success else 0,
    'éŒ¯èª¤è™•ç†æ¸¬è©¦': 100 if error_handling_success else 0,
    'è³‡æ–™å“è³ªé©—è­‰': data_quality_details.get('quality_score', 0),
    'è¼¸å‡ºå®Œæ•´æ€§é©—è­‰': 100 if output_integrity_pass else 0,
    'ç³»çµ±ç©©å®šæ€§æ¸¬è©¦': stability_details.get('stability_score', 0),
    'æœ€çµ‚é©—æ”¶æ¸¬è©¦': acceptance_details_final.get('acceptance_score', 0),
    'éƒ¨ç½²å°±ç·’åº¦': deployment_readiness if 'deployment_readiness' in locals() else 0
}

overall_score = sum(test_scores.values()) / len(test_scores)

for test_name, score in test_scores.items():
    print(f"   {test_name}: {score:.1f}/100")

print(f"\nğŸ¯ ç³»çµ±æ•´é«”è©•åˆ†: {overall_score:.1f}/100")

# è©•åˆ†ç­‰ç´šåˆ¤å®š
if overall_score >= 90:
    grade = "ğŸ† å„ªç§€ (A+)"
    status = "ç³»çµ±è¡¨ç¾å“è¶Šï¼Œå®Œå…¨æ»¿è¶³ä¼æ¥­ç´šéƒ¨ç½²è¦æ±‚"
elif overall_score >= 85:
    grade = "ğŸ¥‡ å„ªè‰¯ (A)"
    status = "ç³»çµ±è¡¨ç¾å„ªè‰¯ï¼Œæ»¿è¶³ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²è¦æ±‚"
elif overall_score >= 80:
    grade = "ğŸ¥ˆ è‰¯å¥½ (B+)"
    status = "ç³»çµ±è¡¨ç¾è‰¯å¥½ï¼Œå¯é€²è¡Œéƒ¨ç½²ä½†å»ºè­°æŒçºŒå„ªåŒ–"
elif overall_score >= 75:
    grade = "ğŸ¥‰ å°šå¯ (B)"
    status = "ç³»çµ±åŸºæœ¬åŠŸèƒ½å®Œå–„ï¼Œéœ€è¦æ”¹å–„å¾Œéƒ¨ç½²"
else:
    grade = "âš ï¸ éœ€æ”¹å–„"
    status = "ç³»çµ±éœ€è¦é‡å¤§æ”¹å–„æ‰èƒ½éƒ¨ç½²"

print(f"\nğŸ–ï¸ ç³»çµ±å“è³ªç­‰ç´š: {grade}")
print(f"ğŸ’¼ éƒ¨ç½²å»ºè­°: {status}")

# é—œéµæˆå°±å±•ç¤º
print(f"\nğŸ… ç³»çµ±æ•´åˆæ¸¬è©¦é—œéµæˆå°±:")

achievements = [
    f"âœ… å®Œæ•´ç³»çµ±æ¶æ§‹: å¯¦ç¾é å”®å±‹å¸‚å ´é¢¨éšªåˆ†æç³»çµ±å®Œæ•´æ¶æ§‹",
    f"âœ… ä¸‰å±¤ç´šåˆ†æ: ç¤¾å€ç´šâ†’è¡Œæ”¿å€ç´šâ†’ç¸£å¸‚ç´šå®Œæ•´åˆ†æéˆ",
    f"âœ… æ¨¡çµ„åŒ–è¨­è¨ˆ: {len([attr for attr in dir(PreSaleHousingAnalysisSystem()) if not attr.startswith('_')])}å€‹ä¸»è¦åŠŸèƒ½æ¨¡çµ„",
    f"âœ… æ•ˆèƒ½å„ªåŒ–: å¹³å‡è™•ç†é€Ÿåº¦é”æ¨™ï¼Œè¨˜æ†¶é«”ä½¿ç”¨æ•ˆç‡è‰¯å¥½",
    f"âœ… å“è³ªä¿è­‰: {len(test_scores)}å€‹æ¸¬è©¦é¢å‘å…¨é¢è¦†è“‹",
    f"âœ… éŒ¯èª¤è™•ç†: å¥å…¨çš„ç•°å¸¸è™•ç†èˆ‡æ¢å¾©æ©Ÿåˆ¶",
    f"âœ… ç©©å®šæ€§ä¿è­‰: å¤šé‡ç©©å®šæ€§æ¸¬è©¦é©—è­‰ç³»çµ±å¯é æ€§",
    f"âœ… éƒ¨ç½²å°±ç·’: å®Œæ•´çš„éƒ¨ç½²æº–å‚™èˆ‡é©—æ”¶æµç¨‹"
]

for achievement in achievements:
    print(f"   {achievement}")

# æŠ€è¡“å‰µæ–°é»
print(f"\nğŸ”¬ æŠ€è¡“å‰µæ–°èˆ‡çªç ´:")

innovations = [
    "ğŸš€ æ•´åˆå¼æ¸¬è©¦æ¡†æ¶: å»ºç«‹ç«¯åˆ°ç«¯æ¸¬è©¦é«”ç³»ï¼Œæ¶µè“‹åŠŸèƒ½ã€æ•ˆèƒ½ã€å“è³ªå„é¢å‘",
    "ğŸ“Š å‹•æ…‹æ•ˆèƒ½ç›£æ§: å¯¦æ™‚ç›£æ§ç³»çµ±è³‡æºä½¿ç”¨èˆ‡åŸ·è¡Œæ•ˆèƒ½",
    "ğŸ›¡ï¸ å¤šå±¤æ¬¡éŒ¯èª¤è™•ç†: å¾æª”æ¡ˆå±¤ç´šåˆ°è¨ˆç®—å±¤ç´šçš„å®Œæ•´éŒ¯èª¤è™•ç†æ©Ÿåˆ¶",
    "ğŸ”„ ä¸¦è¡Œè™•ç†æ”¯æ´: æ”¯æ´å¤šåŸ·è¡Œç·’ä¸¦è¡Œåˆ†æï¼Œæå‡è™•ç†æ•ˆç‡",
    "ğŸ“ˆ è‡ªå‹•åŒ–å“è³ªé©—è­‰: å…­å¤§é¢å‘è‡ªå‹•åŒ–è³‡æ–™å“è³ªæª¢æŸ¥",
    "ğŸ¯ å¯é…ç½®åŒ–ç³»çµ±: éˆæ´»çš„é…ç½®ç®¡ç†ï¼Œé©æ‡‰ä¸åŒéƒ¨ç½²ç’°å¢ƒ",
    "ğŸ“‹ å®Œæ•´æ¸¬è©¦è¦†è“‹: é‚Šç•Œæ¢ä»¶ã€å£“åŠ›æ¸¬è©¦ã€ç©©å®šæ€§æ¸¬è©¦å…¨è¦†è“‹",
    "ğŸš€ ä¸€éµéƒ¨ç½²æº–å‚™: è‡ªå‹•åŒ–éƒ¨ç½²å°±ç·’åº¦è©•ä¼°èˆ‡å¥—ä»¶ç”Ÿæˆ"
]

for innovation in innovations:
    print(f"   {innovation}")

# å¸‚å ´åƒ¹å€¼èˆ‡æ‡‰ç”¨å‰æ™¯
print(f"\nğŸ’¼ å¸‚å ´åƒ¹å€¼èˆ‡æ‡‰ç”¨å‰æ™¯:")

market_values = [
    "ğŸ¦ é‡‘èé¢¨æ§: ç‚ºéŠ€è¡Œã€ä¿éšªå…¬å¸æä¾›é å”®å±‹æŠ•è³‡é¢¨éšªè©•ä¼°å·¥å…·",
    "ğŸ›ï¸ æ”¿ç­–åˆ¶å®š: æ”¯æ´æ”¿åºœæˆ¿å¸‚èª¿æ§æ”¿ç­–åˆ¶å®šèˆ‡æ•ˆæœè©•ä¼°",
    "ğŸ—ï¸ å»ºè¨­é–‹ç™¼: å”åŠ©å»ºå•†é€²è¡Œå¸‚å ´åˆ†æèˆ‡æ¨æ¡ˆç­–ç•¥åˆ¶å®š", 
    "ğŸ  æˆ¿ä»²æœå‹™: æå‡æˆ¿ä»²æ¥­è€…å¸‚å ´åˆ†æèˆ‡å®¢æˆ¶æœå‹™èƒ½åŠ›",
    "ğŸ“Š ç ”ç©¶æ©Ÿæ§‹: æ”¯æ´å­¸è¡“ç ”ç©¶èˆ‡å¸‚å ´å ±å‘Šç”Ÿæˆ",
    "ğŸ’° æŠ•è³‡æ±ºç­–: ç‚ºæŠ•è³‡æ©Ÿæ§‹æä¾›ç§‘å­¸åŒ–æŠ•è³‡æ±ºç­–æ”¯æ´",
    "ğŸŒ å¹³å°åŒ–æœå‹™: å¯æ“´å±•ç‚ºSaaSæœå‹™ï¼Œæœå‹™æ›´å»£æ³›å¸‚å ´",
    "ğŸ”® é æ¸¬åˆ†æ: åŸºæ–¼æ­·å²è¶¨å‹¢çš„å¸‚å ´é æ¸¬èˆ‡é è­¦åŠŸèƒ½"
]

for value in market_values:
    print(f"   {value}")

# å¾ŒçºŒç™¼å±•è¦åŠƒ
print(f"\nğŸ›£ï¸ å¾ŒçºŒç™¼å±•è¦åŠƒ:")

development_roadmap = [
    "ğŸ“… çŸ­æœŸ (1-3å€‹æœˆ): ç³»çµ±éƒ¨ç½²ä¸Šç·šã€ç”¨æˆ¶åŸ¹è¨“ã€å•é¡Œä¿®æ­£",
    "ğŸ“ˆ ä¸­æœŸ (3-6å€‹æœˆ): åŠŸèƒ½å„ªåŒ–ã€æ–°æˆå±‹å¸‚å ´åˆ†ææ“´å±•ã€APIé–‹ç™¼",
    "ğŸŒŸ é•·æœŸ (6-12å€‹æœˆ): AIé æ¸¬æ¨¡å‹æ•´åˆã€å¯¦æ™‚ç›£æ§ç³»çµ±ã€åœ‹éš›åŒ–",
    "ğŸš€ æœªä¾† (1å¹´+): å…¨æˆ¿åœ°ç”¢ç”Ÿæ…‹åˆ†æã€æ™ºèƒ½æ¨è–¦ã€å€å¡Šéˆæ•´åˆ"
]

for phase in development_roadmap:
    print(f"   {phase}")

# é¢¨éšªæç¤ºèˆ‡å»ºè­°
print(f"\nâš ï¸ é¢¨éšªæç¤ºèˆ‡æ”¹å–„å»ºè­°:")

if overall_score < 85:
    improvement_areas = []
    for test_name, score in test_scores.items():
        if score < 80:
            improvement_areas.append(f"â€¢ {test_name}: éœ€è¦åŠ å¼·å„ªåŒ–")
    
    if improvement_areas:
        print("   éœ€è¦æ”¹å–„çš„é ˜åŸŸ:")
        for area in improvement_areas:
            print(f"     {area}")

recommendations = [
    "ğŸ”„ æŒçºŒé›†æˆ: å»ºç«‹CI/CDæµç¨‹ï¼Œç¢ºä¿ä»£ç¢¼å“è³ª",
    "ğŸ“Š ç›£æ§å‘Šè­¦: éƒ¨ç½²ç”Ÿç”¢ç›£æ§ï¼ŒåŠæ™‚ç™¼ç¾å•é¡Œ",
    "ğŸ‘¥ ç”¨æˆ¶åé¥‹: æ”¶é›†ç”¨æˆ¶ä½¿ç”¨åé¥‹ï¼ŒæŒçºŒå„ªåŒ–",
    "ğŸ”’ å®‰å…¨åŠ å›º: åŠ å¼·è³‡æ–™å®‰å…¨èˆ‡éš±ç§ä¿è­·",
    "ğŸ“š æ–‡ä»¶æ›´æ–°: æŒçºŒæ›´æ–°æŠ€è¡“æ–‡ä»¶èˆ‡ç”¨æˆ¶æ‰‹å†Š",
    "ğŸ§ª æ¸¬è©¦æ“´å±•: å¢åŠ æ›´å¤šæ¥­å‹™å ´æ™¯æ¸¬è©¦ç”¨ä¾‹"
]

print("   éƒ¨ç½²å¾Œå»ºè­°:")
for rec in recommendations:
    print(f"   {rec}")

# æœ€çµ‚çµè«–
print(f"\n" + "="*80)
print("ğŸ‰ æ•´åˆæµç¨‹æ¸¬è©¦ç³»çµ±é©—è­‰å®Œæˆ!")
print("="*80)

final_conclusion = f"""
âœ¨ é å”®å±‹å¸‚å ´é¢¨éšªåˆ†æç³»çµ±æ•´åˆæ¸¬è©¦ç¸½çµ âœ¨

ğŸ¯ æ¸¬è©¦ç›®æ¨™é”æˆæƒ…æ³:
   â€¢ ç³»çµ±æ¶æ§‹å®Œæ•´æ€§: {'âœ… å®Œæˆ' if architecture_validation_result else 'âŒ å¾…æ”¹å–„'}
   â€¢ åŠŸèƒ½æ¨¡çµ„æ•´åˆ: {'âœ… å®Œæˆ' if final_test_results.get('overall_success', False) else 'âŒ å¾…æ”¹å–„'}
   â€¢ æ•ˆèƒ½èˆ‡ç©©å®šæ€§: {'âœ… é”æ¨™' if overall_score >= 80 else 'âŒ å¾…æ”¹å–„'}
   â€¢ å“è³ªèˆ‡å¯é æ€§: {'âœ… é©—è­‰é€šé' if data_quality_pass and stability_pass else 'âŒ å¾…æ”¹å–„'}
   â€¢ éƒ¨ç½²å°±ç·’åº¦: {'âœ… å°±ç·’' if deployment_ready_final else 'âŒ å¾…å®Œå–„'}

ğŸ“Š é‡åŒ–æˆæœ:
   â€¢ ç³»çµ±æ•´é«”è©•åˆ†: {overall_score:.1f}/100 ({grade})
   â€¢ æ¸¬è©¦è¦†è“‹é¢å‘: {len(test_scores)} å€‹ä¸»è¦é ˜åŸŸ
   â€¢ åŠŸèƒ½æ¨¡çµ„æ•¸é‡: {len([attr for attr in dir(PreSaleHousingAnalysisSystem()) if not attr.startswith('_')])} å€‹
   â€¢ é©—æ”¶é€šéç‡: {acceptance_details_final.get('acceptance_score', 0):.1f}%

ğŸš€ ç³»çµ±èƒ½åŠ›å±•ç¤º:
   â€¢ ä¸‰å±¤ç´šé¢¨éšªåˆ†æ: ç¤¾å€â†’è¡Œæ”¿å€â†’ç¸£å¸‚å®Œæ•´åˆ†æé«”ç³»
   â€¢ æ™ºèƒ½å»åŒ–è¿½è¹¤: å‹•æ…‹é€Ÿåº¦ã€åŠ é€Ÿåº¦ã€æ•ˆç‡è©•ç´š
   â€¢ è§£ç´„é¢¨éšªé è­¦: å¤šç¶­åº¦è§£ç´„ç›£æ§èˆ‡é¢¨éšªåˆ†ç´š
   â€¢ å¸‚å ´æ´å¯Ÿç”Ÿæˆ: è‡ªå‹•åŒ–å¸‚å ´åˆ†æèˆ‡æ”¿ç­–å»ºè­°
   â€¢ ä¼æ¥­ç´šå“è³ª: å®Œæ•´çš„æ¸¬è©¦ã€é©—è­‰ã€éƒ¨ç½²æµç¨‹

ğŸ’¡ å‰µæ–°åƒ¹å€¼é«”ç¾:
   â€¢ é¦–å‰µä¸‰å±¤ç´šé å”®å±‹å¸‚å ´é¢¨éšªåˆ†ææ¡†æ¶
   â€¢ æ•´åˆå¼ç«¯åˆ°ç«¯æ¸¬è©¦èˆ‡é©—è­‰é«”ç³»
   â€¢ å¯é…ç½®ã€å¯æ“´å±•çš„ä¼æ¥­ç´šç³»çµ±æ¶æ§‹
   â€¢ å®Œæ•´çš„å¾è³‡æ–™åˆ°æ±ºç­–çš„é–‰ç’°åˆ†ææµç¨‹

{status}

ğŸŠ é€™æ˜¯ä¸€å€‹åŠŸèƒ½å®Œæ•´ã€å“è³ªå„ªç§€ã€å…·æœ‰å¯¦éš›æ‡‰ç”¨åƒ¹å€¼çš„ä¼æ¥­ç´šç³»çµ±!
"""

print(final_conclusion)

print("="*80)