# é å”®å±‹å¸‚å ´åˆ†æç³»çµ± - 05_å»åŒ–ç‡è¨ˆç®—èˆ‡é©—è­‰
# åŸºæ–¼ PRD v2.3 è¦æ ¼é€²è¡Œä¸‰ç¨®å»åŒ–ç‡çš„è©³ç´°è¨ˆç®—
# ================================================================================

# %% [markdown]
# # é å”®å±‹å¸‚å ´åˆ†æç³»çµ± - å»åŒ–ç‡è¨ˆç®—èˆ‡é©—è­‰
# 
# ## ğŸ“‹ ç›®æ¨™
# - âœ… å¯¦ä½œä¸‰ç¨®å»åŒ–ç‡è¨ˆç®—é‚è¼¯
# - âœ… é©—è­‰è¨ˆç®—çµæœåˆç†æ€§
# - âœ… å»ºç«‹å»åŒ–ç‡åŸºæº–å€¼
# - âœ… æ™‚é–“å°é½Šé‚è¼¯è™•ç†
# - âœ… ç•°å¸¸æ¡ˆä¾‹è­˜åˆ¥èˆ‡è™•ç†
# - âœ… ç‚ºç¤¾å€ç´šå ±å‘Šå¥ å®šåŸºç¤
# 
# ## ğŸ¯ å…§å®¹å¤§ç¶±
# 1. æ¯›å»åŒ–ç‡è¨ˆç®—å¯¦ä½œ
# 2. æ·¨å»åŒ–ç‡è¨ˆç®—å¯¦ä½œ
# 3. èª¿æ•´å»åŒ–ç‡è¨ˆç®—å¯¦ä½œ
# 4. æ™‚é–“å°é½Šé‚è¼¯è™•ç†
# 5. å»åŒ–ç‡åˆç†æ€§é©—è­‰
# 6. ç•°å¸¸æ¡ˆä¾‹è­˜åˆ¥èˆ‡è™•ç†
# 7. å»åŒ–ç‡åŸºæº–å€¼å»ºç«‹
# 8. è¨ˆç®—çµæœè¦–è¦ºåŒ–åˆ†æ
# 
# ## ğŸ“Š å»¶çºŒ Notebook 1-4 çš„åˆ†æçµæœ
# - ä¹¾æ·¨äº¤æ˜“è³‡æ–™: å»é‡å¾Œçš„æœ‰æ•ˆäº¤æ˜“è¨˜éŒ„
# - è§£ç´„åˆ†æçµæœ: è§£ç´„è³‡æ–™è§£æèˆ‡é¢¨éšªè©•ä¼°
# - å»ºæ¡ˆæ•´åˆçµæœ: æ´»èºå»ºæ¡ˆè­˜åˆ¥èˆ‡æ»¯éŠ·æ¨™è¨˜
# - ä¸‰ç¨®å»åŒ–ç‡å®šç¾©: æ¯›/æ·¨/èª¿æ•´å»åŒ–ç‡

# %% [markdown]
# ## 1. ç’°å¢ƒè¨­å®šèˆ‡è³‡æ–™è¼‰å…¥

# %%
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import re
import warnings
from collections import Counter, defaultdict
import math
warnings.filterwarnings('ignore')

# è¨­å®šé¡¯ç¤ºé¸é …
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', 100)
pd.set_option('display.width', None)
pd.set_option('display.max_colwidth', 80)

# è¨­å®šä¸­æ–‡å­—å‹
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'Arial Unicode MS', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False

# è¨­å®šåœ–è¡¨æ¨£å¼
sns.set_style("whitegrid")
plt.style.use('default')

print("âœ… ç’°å¢ƒè¨­å®šå®Œæˆ")
print(f"ğŸ“… åˆ†ææ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

# %%
# è¼‰å…¥å‰éšæ®µè™•ç†çµæœ
print("ğŸ”„ è¼‰å…¥å‰éšæ®µè™•ç†çµæœ...")

try:
    # è¼‰å…¥ä¹¾æ·¨çš„äº¤æ˜“è³‡æ–™
    clean_transactions = pd.read_csv('../data/processed/03_clean_transactions.csv', encoding='utf-8')
    print(f"âœ… ä¹¾æ·¨äº¤æ˜“è³‡æ–™: {clean_transactions.shape}")
    
    # è¼‰å…¥å»ºæ¡ˆæ•´åˆçµæœ
    active_projects = pd.read_csv('../data/processed/04_active_projects_analysis.csv', encoding='utf-8')
    print(f"âœ… æ´»èºå»ºæ¡ˆåˆ†æ: {active_projects.shape}")
    
    # è¼‰å…¥æ»¯éŠ·åˆ†æçµæœ
    stagnant_projects = pd.read_csv('../data/processed/04_stagnant_projects_analysis.csv', encoding='utf-8')
    print(f"âœ… æ»¯éŠ·å»ºæ¡ˆåˆ†æ: {stagnant_projects.shape}")
    
    # è¼‰å…¥åŸå§‹å»ºæ¡ˆè³‡æ–™ï¼ˆç”¨æ–¼è£œå……è³‡è¨Šï¼‰
    project_data = pd.read_csv('../data/raw/lvr_sale_data_test.csv', encoding='utf-8')
    print(f"âœ… å»ºæ¡ˆåŸºæœ¬è³‡æ–™: {project_data.shape}")
    
except FileNotFoundError as e:
    print(f"âŒ æª”æ¡ˆè¼‰å…¥å¤±æ•—: {e}")
    print("ğŸ“ è«‹ç¢ºèªæ˜¯å¦å·²åŸ·è¡Œ Notebook 1-4")
except Exception as e:
    print(f"âŒ è¼‰å…¥éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")

# %%
# è³‡æ–™æ¦‚æ³æª¢è¦–
print("ğŸ“Š å»åŒ–ç‡è¨ˆç®—åŸºç¤è³‡æ–™æ¦‚æ³")
print("=" * 60)

print("äº¤æ˜“è³‡æ–™:")
print(f"   ç¸½ç­†æ•¸: {len(clean_transactions):,}")
print(f"   å‚™æŸ¥ç·¨è™Ÿæ•¸: {clean_transactions['å‚™æŸ¥ç·¨è™Ÿ'].nunique():,}")
print(f"   æ™‚é–“ç¯„åœ: {clean_transactions['äº¤æ˜“å¹´å­£'].min()} ~ {clean_transactions['äº¤æ˜“å¹´å­£'].max()}")

print(f"\næ´»èºå»ºæ¡ˆ:")
print(f"   ç¸½å»ºæ¡ˆæ•¸: {len(active_projects):,}")
print(f"   æ´»èºå»ºæ¡ˆæ•¸: {len(active_projects[active_projects['is_active'] == True]):,}")
print(f"   å¹³å‡æˆ¶æ•¸: {active_projects['total_units'].mean():.0f}")

print(f"\næ»¯éŠ·å»ºæ¡ˆ:")
print(f"   é•·æœŸæ»¯éŠ·æ•¸: {len(stagnant_projects[stagnant_projects['is_long_term_stagnant'] == True]):,}")
print(f"   é«˜é¢¨éšªæ•¸: {len(stagnant_projects[stagnant_projects['stagnant_risk_level'] == 'High']):,}")

# ç¢ºèªé—œéµæ¬„ä½å­˜åœ¨
required_columns = ['å‚™æŸ¥ç·¨è™Ÿ', 'äº¤æ˜“å¹´å­£', 'æ˜¯å¦æ­£å¸¸äº¤æ˜“', 'æ˜¯å¦è§£ç´„']
missing_columns = [col for col in required_columns if col not in clean_transactions.columns]
if missing_columns:
    print(f"âš ï¸ ç¼ºå°‘é—œéµæ¬„ä½: {missing_columns}")
else:
    print(f"âœ… æ‰€æœ‰å¿…è¦æ¬„ä½éƒ½å­˜åœ¨")

# %% [markdown]
# ## 2. å¹´å­£è™•ç†èˆ‡æ™‚é–“å°é½Šé‚è¼¯

# %%
# å¹´å­£è™•ç†å·¥å…·å‡½æ•¸
print("ğŸ• å¹´å­£è™•ç†èˆ‡æ™‚é–“å°é½Šé‚è¼¯")
print("=" * 60)

def season_to_number(season_str):
    """
    å°‡å¹´å­£å­—ä¸²è½‰æ›ç‚ºå¯æ¯”è¼ƒçš„æ•¸å­—
    ä¾‹: "111Y1S" -> 1111, "111Y2S" -> 1112
    """
    try:
        if not season_str or pd.isna(season_str):
            return 0
        
        season_str = str(season_str).strip()
        if 'Y' not in season_str or 'S' not in season_str:
            return 0
            
        year_part = season_str.split('Y')[0]
        season_part = season_str.split('Y')[1].replace('S', '')
        return int(year_part) * 10 + int(season_part)
    except:
        return 0

def number_to_season(season_num):
    """
    å°‡æ•¸å­—è½‰æ›å›å¹´å­£å­—ä¸²
    ä¾‹: 1111 -> "111Y1S"
    """
    try:
        if season_num <= 0:
            return ""
        
        year = season_num // 10
        season = season_num % 10
        return f"{year:03d}Y{season}S"
    except:
        return ""

def get_season_range(start_season, end_season):
    """
    ç²å–å…©å€‹å¹´å­£ä¹‹é–“çš„æ‰€æœ‰å¹´å­£
    """
    start_num = season_to_number(start_season)
    end_num = season_to_number(end_season)
    
    seasons = []
    current = start_num
    
    while current <= end_num:
        seasons.append(number_to_season(current))
        
        # å­£åº¦éå¢é‚è¼¯
        season = current % 10
        year = current // 10
        
        if season == 4:  # ç¬¬4å­£ -> ä¸‹ä¸€å¹´ç¬¬1å­£
            current = (year + 1) * 10 + 1
        else:  # å­£åº¦+1
            current = year * 10 + (season + 1)
    
    return seasons

def calculate_sales_seasons(start_season, target_season):
    """
    è¨ˆç®—å¾éŠ·å”®èµ·å§‹åˆ°ç›®æ¨™å¹´å­£çš„ç´¯ç©å­£æ•¸
    """
    start_num = season_to_number(start_season)
    target_num = season_to_number(target_season)
    
    if start_num == 0 or target_num == 0 or target_num < start_num:
        return 0
    
    sales_seasons = 0
    current = start_num
    
    while current <= target_num:
        sales_seasons += 1
        
        # å­£åº¦éå¢
        season = current % 10
        year = current // 10
        
        if season == 4:
            current = (year + 1) * 10 + 1
        else:
            current = year * 10 + (season + 1)
    
    return sales_seasons

# %%
# æ¸¬è©¦å¹´å­£è™•ç†å‡½æ•¸
print("ğŸ§ª å¹´å­£è™•ç†å‡½æ•¸æ¸¬è©¦:")

test_cases = [
    ("111Y1S", "111Y4S", 4),
    ("111Y4S", "112Y1S", 2),
    ("110Y3S", "113Y2S", 12),
    ("113Y1S", "113Y2S", 2)
]

for start, end, expected in test_cases:
    result = calculate_sales_seasons(start, end)
    status = "âœ…" if result == expected else "âŒ"
    print(f"   {status} {start} -> {end}: {result} å­£ (é æœŸ: {expected})")

# ç²å–äº¤æ˜“è³‡æ–™ä¸­çš„å¹´å­£ç¯„åœ
available_seasons = sorted(clean_transactions['äº¤æ˜“å¹´å­£'].unique(), key=season_to_number)
print(f"\nğŸ“… å¯ç”¨å¹´å­£ç¯„åœ: {available_seasons[0]} ~ {available_seasons[-1]} (å…± {len(available_seasons)} å­£)")

# %% [markdown]
# ## 3. æ¯›å»åŒ–ç‡è¨ˆç®—å¯¦ä½œ

# %%
# æ¯›å»åŒ–ç‡è¨ˆç®—é‚è¼¯
print("ğŸ“ˆ æ¯›å»åŒ–ç‡è¨ˆç®—å¯¦ä½œ")
print("=" * 60)

def calculate_gross_absorption_rate(project_code, target_season, transactions_df, projects_df):
    """
    è¨ˆç®—æ¯›å»åŒ–ç‡
    
    æ¯›å»åŒ–ç‡ = ç´¯ç©æˆäº¤ç­†æ•¸ Ã· ç¸½æˆ¶æ•¸ Ã— 100%
    
    Args:
        project_code: å»ºæ¡ˆç·¨è™Ÿ
        target_season: ç›®æ¨™å¹´å­£
        transactions_df: äº¤æ˜“è³‡æ–™
        projects_df: å»ºæ¡ˆè³‡æ–™
        
    Returns:
        dict: æ¯›å»åŒ–ç‡è¨ˆç®—çµæœ
    """
    
    result = {
        'project_code': project_code,
        'target_season': target_season,
        'total_units': 0,
        'cumulative_transactions': 0,
        'gross_absorption_rate': 0.0,
        'calculation_status': 'success',
        'error_message': ''
    }
    
    try:
        # ç²å–å»ºæ¡ˆç¸½æˆ¶æ•¸
        project_info = projects_df[projects_df['project_code'] == project_code]
        if project_info.empty:
            result['calculation_status'] = 'error'
            result['error_message'] = 'æ‰¾ä¸åˆ°å»ºæ¡ˆè³‡è¨Š'
            return result
        
        total_units = project_info['total_units'].iloc[0]
        if total_units <= 0:
            result['calculation_status'] = 'error'
            result['error_message'] = 'ç¸½æˆ¶æ•¸ç„¡æ•ˆ'
            return result
        
        result['total_units'] = total_units
        
        # ç²å–è©²å»ºæ¡ˆæˆªè‡³ç›®æ¨™å¹´å­£çš„æ‰€æœ‰æœ‰æ•ˆäº¤æ˜“
        project_transactions = transactions_df[
            (transactions_df['å‚™æŸ¥ç·¨è™Ÿ'] == project_code) &
            (transactions_df['æ˜¯å¦æ­£å¸¸äº¤æ˜“'] == True) &
            (transactions_df['äº¤æ˜“å¹´å­£'] <= target_season)
        ].copy()
        
        # æŒ‰å¹´å­£æ’åºä¸¦è¨ˆç®—ç´¯ç©æˆäº¤ç­†æ•¸
        if not project_transactions.empty:
            # æ·»åŠ å¹´å­£æ•¸å­—æ’åºæ¬„ä½
            project_transactions['season_num'] = project_transactions['äº¤æ˜“å¹´å­£'].apply(season_to_number)
            target_season_num = season_to_number(target_season)
            
            # åªå–ç›®æ¨™å¹´å­£ä¹‹å‰ï¼ˆåŒ…å«ï¼‰çš„äº¤æ˜“
            valid_transactions = project_transactions[
                project_transactions['season_num'] <= target_season_num
            ]
            
            cumulative_transactions = len(valid_transactions)
        else:
            cumulative_transactions = 0
        
        result['cumulative_transactions'] = cumulative_transactions
        
        # è¨ˆç®—æ¯›å»åŒ–ç‡
        if total_units > 0:
            gross_absorption_rate = (cumulative_transactions / total_units) * 100
            result['gross_absorption_rate'] = round(gross_absorption_rate, 2)
        
    except Exception as e:
        result['calculation_status'] = 'error'
        result['error_message'] = str(e)
    
    return result

# %%
# æ‰¹é‡è¨ˆç®—æ¯›å»åŒ–ç‡
print("ğŸ”„ æ‰¹é‡è¨ˆç®—æ¯›å»åŒ–ç‡...")

# é¸å–ç›®æ¨™å¹´å­£é€²è¡Œæ¸¬è©¦
target_seasons = ['113Y1S', '113Y2S', '113Y3S', '113Y4S']

gross_absorption_results = []

# å°æ‰€æœ‰æ´»èºå»ºæ¡ˆè¨ˆç®—æ¯›å»åŒ–ç‡
for target_season in target_seasons:
    print(f"   è¨ˆç®— {target_season} æ¯›å»åŒ–ç‡...")
    
    for _, project in active_projects.iterrows():
        project_code = project['project_code']
        
        # åªè¨ˆç®—æ´»èºå»ºæ¡ˆ
        if not project['is_active']:
            continue
        
        result = calculate_gross_absorption_rate(
            project_code, target_season, clean_transactions, active_projects
        )
        
        # æ·»åŠ é¡å¤–è³‡è¨Š
        result.update({
            'county': project['county'],
            'district': project['district'],
            'project_name': project['project_name'],
            'has_complete_info': project['has_complete_info']
        })
        
        gross_absorption_results.append(result)

# è½‰æ›ç‚ºDataFrame
gross_absorption_df = pd.DataFrame(gross_absorption_results)

print(f"âœ… å®Œæˆ {len(gross_absorption_df)} ç­†æ¯›å»åŒ–ç‡è¨ˆç®—")

# %%
# æ¯›å»åŒ–ç‡çµ±è¨ˆåˆ†æ
print(f"\nğŸ“Š æ¯›å»åŒ–ç‡çµ±è¨ˆåˆ†æ:")

if not gross_absorption_df.empty:
    # æ•´é«”çµ±è¨ˆ
    successful_calculations = gross_absorption_df[gross_absorption_df['calculation_status'] == 'success']
    error_calculations = gross_absorption_df[gross_absorption_df['calculation_status'] == 'error']
    
    print(f"è¨ˆç®—çµæœçµ±è¨ˆ:")
    print(f"   æˆåŠŸè¨ˆç®—: {len(successful_calculations):,} ç­† ({len(successful_calculations)/len(gross_absorption_df)*100:.1f}%)")
    print(f"   è¨ˆç®—éŒ¯èª¤: {len(error_calculations):,} ç­†")
    
    if not successful_calculations.empty:
        # å»åŒ–ç‡åˆ†å¸ƒçµ±è¨ˆ
        for season in target_seasons:
            season_data = successful_calculations[successful_calculations['target_season'] == season]
            if not season_data.empty:
                print(f"\n{season} æ¯›å»åŒ–ç‡çµ±è¨ˆ:")
                print(f"   å¹³å‡å»åŒ–ç‡: {season_data['gross_absorption_rate'].mean():.1f}%")
                print(f"   ä¸­ä½æ•¸å»åŒ–ç‡: {season_data['gross_absorption_rate'].median():.1f}%")
                print(f"   æœ€é«˜å»åŒ–ç‡: {season_data['gross_absorption_rate'].max():.1f}%")
                print(f"   æœ€ä½å»åŒ–ç‡: {season_data['gross_absorption_rate'].min():.1f}%")
                
                # å»åŒ–ç‡åˆ†ç´šçµ±è¨ˆ
                high_absorption = len(season_data[season_data['gross_absorption_rate'] >= 70])
                medium_absorption = len(season_data[(season_data['gross_absorption_rate'] >= 30) & 
                                                   (season_data['gross_absorption_rate'] < 70)])
                low_absorption = len(season_data[season_data['gross_absorption_rate'] < 30])
                
                print(f"   é«˜å»åŒ–ç‡ (â‰¥70%): {high_absorption} å€‹")
                print(f"   ä¸­å»åŒ–ç‡ (30-70%): {medium_absorption} å€‹")
                print(f"   ä½å»åŒ–ç‡ (<30%): {low_absorption} å€‹")

# %% [markdown]
# ## 4. æ·¨å»åŒ–ç‡è¨ˆç®—å¯¦ä½œ

# %%
# æ·¨å»åŒ–ç‡è¨ˆç®—é‚è¼¯
print("ğŸ“‰ æ·¨å»åŒ–ç‡è¨ˆç®—å¯¦ä½œ")
print("=" * 60)

def calculate_net_absorption_rate(project_code, target_season, transactions_df, projects_df):
    """
    è¨ˆç®—æ·¨å»åŒ–ç‡
    
    æ·¨å»åŒ–ç‡ = (ç´¯ç©æˆäº¤ç­†æ•¸ - ç´¯ç©è§£ç´„ç­†æ•¸) Ã· ç¸½æˆ¶æ•¸ Ã— 100%
    
    Args:
        project_code: å»ºæ¡ˆç·¨è™Ÿ
        target_season: ç›®æ¨™å¹´å­£
        transactions_df: äº¤æ˜“è³‡æ–™
        projects_df: å»ºæ¡ˆè³‡æ–™
        
    Returns:
        dict: æ·¨å»åŒ–ç‡è¨ˆç®—çµæœ
    """
    
    result = {
        'project_code': project_code,
        'target_season': target_season,
        'total_units': 0,
        'cumulative_transactions': 0,
        'cumulative_cancellations': 0,
        'net_transactions': 0,
        'net_absorption_rate': 0.0,
        'cancellation_rate': 0.0,
        'calculation_status': 'success',
        'error_message': ''
    }
    
    try:
        # ç²å–å»ºæ¡ˆç¸½æˆ¶æ•¸
        project_info = projects_df[projects_df['project_code'] == project_code]
        if project_info.empty:
            result['calculation_status'] = 'error'
            result['error_message'] = 'æ‰¾ä¸åˆ°å»ºæ¡ˆè³‡è¨Š'
            return result
        
        total_units = project_info['total_units'].iloc[0]
        if total_units <= 0:
            result['calculation_status'] = 'error'
            result['error_message'] = 'ç¸½æˆ¶æ•¸ç„¡æ•ˆ'
            return result
        
        result['total_units'] = total_units
        
        target_season_num = season_to_number(target_season)
        
        # ç²å–è©²å»ºæ¡ˆæˆªè‡³ç›®æ¨™å¹´å­£çš„æ‰€æœ‰äº¤æ˜“ï¼ˆåŒ…å«æ­£å¸¸å’Œè§£ç´„ï¼‰
        project_transactions = transactions_df[
            (transactions_df['å‚™æŸ¥ç·¨è™Ÿ'] == project_code) &
            (transactions_df['äº¤æ˜“å¹´å­£'].apply(season_to_number) <= target_season_num)
        ].copy()
        
        if not project_transactions.empty:
            # è¨ˆç®—ç´¯ç©æˆäº¤ç­†æ•¸ï¼ˆæ­£å¸¸äº¤æ˜“ï¼‰
            normal_transactions = project_transactions[
                project_transactions['æ˜¯å¦æ­£å¸¸äº¤æ˜“'] == True
            ]
            cumulative_transactions = len(normal_transactions)
            
            # è¨ˆç®—ç´¯ç©è§£ç´„ç­†æ•¸
            cancelled_transactions = project_transactions[
                project_transactions['æ˜¯å¦è§£ç´„'] == True
            ]
            cumulative_cancellations = len(cancelled_transactions)
            
        else:
            cumulative_transactions = 0
            cumulative_cancellations = 0
        
        result['cumulative_transactions'] = cumulative_transactions
        result['cumulative_cancellations'] = cumulative_cancellations
        
        # è¨ˆç®—æ·¨æˆäº¤ç­†æ•¸
        net_transactions = cumulative_transactions - cumulative_cancellations
        result['net_transactions'] = max(0, net_transactions)  # ç¢ºä¿ä¸ç‚ºè² æ•¸
        
        # è¨ˆç®—æ·¨å»åŒ–ç‡
        if total_units > 0:
            net_absorption_rate = (result['net_transactions'] / total_units) * 100
            result['net_absorption_rate'] = round(net_absorption_rate, 2)
        
        # è¨ˆç®—è§£ç´„ç‡
        if cumulative_transactions > 0:
            cancellation_rate = (cumulative_cancellations / cumulative_transactions) * 100
            result['cancellation_rate'] = round(cancellation_rate, 2)
        
    except Exception as e:
        result['calculation_status'] = 'error'
        result['error_message'] = str(e)
    
    return result

# %%
# æ‰¹é‡è¨ˆç®—æ·¨å»åŒ–ç‡
print("ğŸ”„ æ‰¹é‡è¨ˆç®—æ·¨å»åŒ–ç‡...")

net_absorption_results = []

# å°æ‰€æœ‰æ´»èºå»ºæ¡ˆè¨ˆç®—æ·¨å»åŒ–ç‡
for target_season in target_seasons:
    print(f"   è¨ˆç®— {target_season} æ·¨å»åŒ–ç‡...")
    
    for _, project in active_projects.iterrows():
        project_code = project['project_code']
        
        # åªè¨ˆç®—æ´»èºå»ºæ¡ˆ
        if not project['is_active']:
            continue
        
        result = calculate_net_absorption_rate(
            project_code, target_season, clean_transactions, active_projects
        )
        
        # æ·»åŠ é¡å¤–è³‡è¨Š
        result.update({
            'county': project['county'],
            'district': project['district'],
            'project_name': project['project_name'],
            'has_complete_info': project['has_complete_info']
        })
        
        net_absorption_results.append(result)

# è½‰æ›ç‚ºDataFrame
net_absorption_df = pd.DataFrame(net_absorption_results)

print(f"âœ… å®Œæˆ {len(net_absorption_df)} ç­†æ·¨å»åŒ–ç‡è¨ˆç®—")

# %%
# æ·¨å»åŒ–ç‡çµ±è¨ˆåˆ†æ
print(f"\nğŸ“Š æ·¨å»åŒ–ç‡çµ±è¨ˆåˆ†æ:")

if not net_absorption_df.empty:
    # æ•´é«”çµ±è¨ˆ
    successful_net_calculations = net_absorption_df[net_absorption_df['calculation_status'] == 'success']
    
    print(f"è¨ˆç®—çµæœçµ±è¨ˆ:")
    print(f"   æˆåŠŸè¨ˆç®—: {len(successful_net_calculations):,} ç­†")
    
    if not successful_net_calculations.empty:
        # è§£ç´„å½±éŸ¿åˆ†æ
        total_gross_transactions = successful_net_calculations['cumulative_transactions'].sum()
        total_cancellations = successful_net_calculations['cumulative_cancellations'].sum()
        total_net_transactions = successful_net_calculations['net_transactions'].sum()
        
        print(f"\næ•´é«”è§£ç´„å½±éŸ¿åˆ†æ:")
        print(f"   ç¸½æˆäº¤ç­†æ•¸: {total_gross_transactions:,}")
        print(f"   ç¸½è§£ç´„ç­†æ•¸: {total_cancellations:,}")
        print(f"   ç¸½æ·¨æˆäº¤ç­†æ•¸: {total_net_transactions:,}")
        print(f"   æ•´é«”è§£ç´„ç‡: {total_cancellations/total_gross_transactions*100:.2f}%" if total_gross_transactions > 0 else "   æ•´é«”è§£ç´„ç‡: 0.00%")
        
        # å„å¹´å­£æ·¨å»åŒ–ç‡çµ±è¨ˆ
        for season in target_seasons:
            season_data = successful_net_calculations[successful_net_calculations['target_season'] == season]
            if not season_data.empty:
                print(f"\n{season} æ·¨å»åŒ–ç‡çµ±è¨ˆ:")
                print(f"   å¹³å‡æ·¨å»åŒ–ç‡: {season_data['net_absorption_rate'].mean():.1f}%")
                print(f"   ä¸­ä½æ•¸æ·¨å»åŒ–ç‡: {season_data['net_absorption_rate'].median():.1f}%")
                print(f"   å¹³å‡è§£ç´„ç‡: {season_data['cancellation_rate'].mean():.2f}%")
                
                # è§£ç´„å½±éŸ¿åˆ†ç´š
                high_cancellation = len(season_data[season_data['cancellation_rate'] > 5])
                medium_cancellation = len(season_data[(season_data['cancellation_rate'] > 2) & 
                                                     (season_data['cancellation_rate'] <= 5)])
                low_cancellation = len(season_data[season_data['cancellation_rate'] <= 2])
                
                print(f"   é«˜è§£ç´„ç‡ (>5%): {high_cancellation} å€‹")
                print(f"   ä¸­è§£ç´„ç‡ (2-5%): {medium_cancellation} å€‹")
                print(f"   ä½è§£ç´„ç‡ (â‰¤2%): {low_cancellation} å€‹")

# %% [markdown]
# ## 5. èª¿æ•´å»åŒ–ç‡è¨ˆç®—å¯¦ä½œ

# %%
# èª¿æ•´å»åŒ–ç‡è¨ˆç®—é‚è¼¯
print("ğŸ”§ èª¿æ•´å»åŒ–ç‡è¨ˆç®—å¯¦ä½œ")
print("=" * 60)

def get_season_days(season_str):
    """
    ç²å–æŒ‡å®šå¹´å­£çš„ç¸½å¤©æ•¸
    """
    try:
        # è§£æå¹´å­£
        year_part = season_str.split('Y')[0]
        season_part = season_str.split('Y')[1].replace('S', '')
        
        year = int(year_part) + 1911  # è½‰ç‚ºè¥¿å…ƒå¹´
        season = int(season_part)
        
        # è¨ˆç®—å„å­£åº¦çš„å¤©æ•¸
        if season == 1:  # ç¬¬1å­£ (1-3æœˆ)
            # æª¢æŸ¥æ˜¯å¦é–å¹´
            is_leap = (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0)
            return 31 + (29 if is_leap else 28) + 31  # 1æœˆ + 2æœˆ + 3æœˆ
        elif season == 2:  # ç¬¬2å­£ (4-6æœˆ)
            return 30 + 31 + 30  # 4æœˆ + 5æœˆ + 6æœˆ
        elif season == 3:  # ç¬¬3å­£ (7-9æœˆ)
            return 31 + 31 + 30  # 7æœˆ + 8æœˆ + 9æœˆ
        elif season == 4:  # ç¬¬4å­£ (10-12æœˆ)
            return 31 + 30 + 31  # 10æœˆ + 11æœˆ + 12æœˆ
        else:
            return 90  # é è¨­90å¤©
            
    except:
        return 90  # é è¨­90å¤©

def is_complete_season(target_season, analysis_date=None):
    """
    åˆ¤æ–·ç›®æ¨™å¹´å­£æ˜¯å¦ç‚ºå®Œæ•´å­£åº¦
    
    Args:
        target_season: ç›®æ¨™å¹´å­£
        analysis_date: åˆ†ææ—¥æœŸ (é è¨­ç‚ºç•¶å‰æ™‚é–“)
        
    Returns:
        bool: æ˜¯å¦ç‚ºå®Œæ•´å­£åº¦
    """
    if analysis_date is None:
        analysis_date = datetime.now()
    
    try:
        # è§£æç›®æ¨™å¹´å­£
        year_part = target_season.split('Y')[0]
        season_part = target_season.split('Y')[1].replace('S', '')
        
        target_year = int(year_part) + 1911
        target_season_num = int(season_part)
        
        # è¨ˆç®—ç›®æ¨™å¹´å­£çš„çµæŸæ—¥æœŸ
        if target_season_num == 1:
            end_date = datetime(target_year, 3, 31)
        elif target_season_num == 2:
            end_date = datetime(target_year, 6, 30)
        elif target_season_num == 3:
            end_date = datetime(target_year, 9, 30)
        elif target_season_num == 4:
            end_date = datetime(target_year, 12, 31)
        else:
            return True  # é è¨­ç‚ºå®Œæ•´å­£åº¦
        
        # å¦‚æœåˆ†ææ—¥æœŸåœ¨å­£åº¦çµæŸæ—¥æœŸä¹‹å¾Œï¼Œå‰‡ç‚ºå®Œæ•´å­£åº¦
        return analysis_date.date() > end_date.date()
        
    except:
        return True  # é è¨­ç‚ºå®Œæ•´å­£åº¦

def calculate_adjusted_absorption_rate(project_code, target_season, transactions_df, projects_df, analysis_date=None):
    """
    è¨ˆç®—èª¿æ•´å»åŒ–ç‡
    
    å°æ–¼éå®Œæ•´å­£åº¦ï¼Œæ ¹æ“šå¯¦éš›éŠ·å”®å¤©æ•¸é€²è¡Œæ¨™æº–åŒ–èª¿æ•´
    
    Args:
        project_code: å»ºæ¡ˆç·¨è™Ÿ
        target_season: ç›®æ¨™å¹´å­£
        transactions_df: äº¤æ˜“è³‡æ–™
        projects_df: å»ºæ¡ˆè³‡æ–™
        analysis_date: åˆ†æåŸºæº–æ—¥æœŸ
        
    Returns:
        dict: èª¿æ•´å»åŒ–ç‡è¨ˆç®—çµæœ
    """
    
    # å…ˆè¨ˆç®—æ·¨å»åŒ–ç‡ä½œç‚ºåŸºç¤
    net_result = calculate_net_absorption_rate(project_code, target_season, transactions_df, projects_df)
    
    result = {
        **net_result,
        'season_total_days': 0,
        'season_sales_days': 0,
        'is_complete_season': True,
        'adjustment_factor': 1.0,
        'adjusted_absorption_rate': net_result.get('net_absorption_rate', 0.0)
    }
    
    if net_result['calculation_status'] != 'success':
        return result
    
    try:
        # åˆ¤æ–·æ˜¯å¦ç‚ºå®Œæ•´å­£åº¦
        is_complete = is_complete_season(target_season, analysis_date)
        result['is_complete_season'] = is_complete
        
        # ç²å–å­£åº¦ç¸½å¤©æ•¸
        season_total_days = get_season_days(target_season)
        result['season_total_days'] = season_total_days
        
        if is_complete:
            # å®Œæ•´å­£åº¦ï¼Œä¸éœ€èª¿æ•´
            result['season_sales_days'] = season_total_days
            result['adjustment_factor'] = 1.0
            result['adjusted_absorption_rate'] = net_result['net_absorption_rate']
        else:
            # éå®Œæ•´å­£åº¦ï¼Œéœ€è¦èª¿æ•´
            if analysis_date is None:
                analysis_date = datetime.now()
            
            # è¨ˆç®—å­£åº¦èµ·å§‹æ—¥æœŸ
            year_part = target_season.split('Y')[0]
            season_part = target_season.split('Y')[1].replace('S', '')
            target_year = int(year_part) + 1911
            target_season_num = int(season_part)
            
            if target_season_num == 1:
                season_start = datetime(target_year, 1, 1)
            elif target_season_num == 2:
                season_start = datetime(target_year, 4, 1)
            elif target_season_num == 3:
                season_start = datetime(target_year, 7, 1)
            elif target_season_num == 4:
                season_start = datetime(target_year, 10, 1)
            
            # è¨ˆç®—å¯¦éš›éŠ·å”®å¤©æ•¸
            season_sales_days = min(season_total_days, (analysis_date - season_start).days + 1)
            season_sales_days = max(1, season_sales_days)  # è‡³å°‘1å¤©
            result['season_sales_days'] = season_sales_days
            
            # è¨ˆç®—èª¿æ•´ä¿‚æ•¸
            adjustment_factor = season_total_days / season_sales_days
            result['adjustment_factor'] = round(adjustment_factor, 3)
            
            # è¨ˆç®—èª¿æ•´å¾Œå»åŒ–ç‡
            adjusted_absorption_rate = net_result['net_absorption_rate'] * adjustment_factor
            result['adjusted_absorption_rate'] = round(adjusted_absorption_rate, 2)
    
    except Exception as e:
        result['calculation_status'] = 'error'
        result['error_message'] = f"èª¿æ•´å»åŒ–ç‡è¨ˆç®—éŒ¯èª¤: {str(e)}"
    
    return result

# %%
# æ‰¹é‡è¨ˆç®—èª¿æ•´å»åŒ–ç‡
print("ğŸ”„ æ‰¹é‡è¨ˆç®—èª¿æ•´å»åŒ–ç‡...")

# è¨­å®šåˆ†æåŸºæº–æ—¥æœŸ (å‡è¨­ç‚º113å¹´ç¬¬4å­£æœ«çš„åˆ†æ)
analysis_date = datetime(2024, 12, 31)  # 113å¹´ç¬¬4å­£æœ«

adjusted_absorption_results = []

# å°æ‰€æœ‰æ´»èºå»ºæ¡ˆè¨ˆç®—èª¿æ•´å»åŒ–ç‡
for target_season in target_seasons:
    print(f"   è¨ˆç®— {target_season} èª¿æ•´å»åŒ–ç‡...")
    
    for _, project in active_projects.iterrows():
        project_code = project['project_code']
        
        # åªè¨ˆç®—æ´»èºå»ºæ¡ˆ
        if not project['is_active']:
            continue
        
        result = calculate_adjusted_absorption_rate(
            project_code, target_season, clean_transactions, active_projects, analysis_date
        )
        
        # æ·»åŠ é¡å¤–è³‡è¨Š
        result.update({
            'county': project['county'],
            'district': project['district'],
            'project_name': project['project_name'],
            'has_complete_info': project['has_complete_info']
        })
        
        adjusted_absorption_results.append(result)

# è½‰æ›ç‚ºDataFrame
adjusted_absorption_df = pd.DataFrame(adjusted_absorption_results)

print(f"âœ… å®Œæˆ {len(adjusted_absorption_df)} ç­†èª¿æ•´å»åŒ–ç‡è¨ˆç®—")

# %%
# èª¿æ•´å»åŒ–ç‡çµ±è¨ˆåˆ†æ
print(f"\nğŸ“Š èª¿æ•´å»åŒ–ç‡çµ±è¨ˆåˆ†æ:")

if not adjusted_absorption_df.empty:
    successful_adj_calculations = adjusted_absorption_df[adjusted_absorption_df['calculation_status'] == 'success']
    
    print(f"è¨ˆç®—çµæœçµ±è¨ˆ:")
    print(f"   æˆåŠŸè¨ˆç®—: {len(successful_adj_calculations):,} ç­†")
    
    if not successful_adj_calculations.empty:
        # å®Œæ•´å­£åº¦ vs éå®Œæ•´å­£åº¦çµ±è¨ˆ
        complete_seasons = successful_adj_calculations[successful_adj_calculations['is_complete_season'] == True]
        incomplete_seasons = successful_adj_calculations[successful_adj_calculations['is_complete_season'] == False]
        
        print(f"\nå­£åº¦å®Œæ•´æ€§çµ±è¨ˆ:")
        print(f"   å®Œæ•´å­£åº¦è¨˜éŒ„: {len(complete_seasons):,} ç­†")
        print(f"   éå®Œæ•´å­£åº¦è¨˜éŒ„: {len(incomplete_seasons):,} ç­†")
        
        if len(incomplete_seasons) > 0:
            print(f"   å¹³å‡èª¿æ•´ä¿‚æ•¸: {incomplete_seasons['adjustment_factor'].mean():.3f}")
            print(f"   æœ€å¤§èª¿æ•´ä¿‚æ•¸: {incomplete_seasons['adjustment_factor'].max():.3f}")
            
        # å„å¹´å­£èª¿æ•´æ•ˆæœåˆ†æ
        for season in target_seasons:
            season_data = successful_adj_calculations[successful_adj_calculations['target_season'] == season]
            if not season_data.empty:
                complete_count = len(season_data[season_data['is_complete_season'] == True])
                incomplete_count = len(season_data[season_data['is_complete_season'] == False])
                
                print(f"\n{season} èª¿æ•´æ•ˆæœåˆ†æ:")
                print(f"   å®Œæ•´å­£åº¦: {complete_count} å€‹")
                print(f"   éå®Œæ•´å­£åº¦: {incomplete_count} å€‹")
                
                if incomplete_count > 0:
                    incomplete_data = season_data[season_data['is_complete_season'] == False]
                    print(f"   å¹³å‡èª¿æ•´å‰å»åŒ–ç‡: {incomplete_data['net_absorption_rate'].mean():.1f}%")
                    print(f"   å¹³å‡èª¿æ•´å¾Œå»åŒ–ç‡: {incomplete_data['adjusted_absorption_rate'].mean():.1f}%")
                    print(f"   å¹³å‡èª¿æ•´ä¿‚æ•¸: {incomplete_data['adjustment_factor'].mean():.3f}")

# %% [markdown]
# ## 6. å»åŒ–ç‡åˆç†æ€§é©—è­‰

# %%
# å»åŒ–ç‡åˆç†æ€§é©—è­‰
print("ğŸ” å»åŒ–ç‡åˆç†æ€§é©—è­‰")
print("=" * 60)

def validate_absorption_rates(absorption_df):
    """
    é©—è­‰å»åŒ–ç‡è¨ˆç®—çµæœçš„åˆç†æ€§
    
    Args:
        absorption_df: åŒ…å«å»åŒ–ç‡è¨ˆç®—çµæœçš„DataFrame
        
    Returns:
        dict: é©—è­‰çµæœå ±å‘Š
    """
    
    validation_report = {
        'total_records': len(absorption_df),
        'validation_errors': [],
        'warning_cases': [],
        'quality_metrics': {}
    }
    
    # éæ¿¾æˆåŠŸè¨ˆç®—çš„è¨˜éŒ„
    valid_data = absorption_df[absorption_df['calculation_status'] == 'success'].copy()
    validation_report['valid_records'] = len(valid_data)
    
    if len(valid_data) == 0:
        validation_report['validation_errors'].append("æ²’æœ‰æœ‰æ•ˆçš„è¨ˆç®—è¨˜éŒ„")
        return validation_report
    
    # é©—è­‰1: å»åŒ–ç‡ä¸èƒ½è¶…é100%
    if 'net_absorption_rate' in valid_data.columns:
        over_100_net = valid_data[valid_data['net_absorption_rate'] > 100]
        if len(over_100_net) > 0:
            validation_report['validation_errors'].append(f"ç™¼ç¾ {len(over_100_net)} ç­†æ·¨å»åŒ–ç‡è¶…é100%")
    
    if 'adjusted_absorption_rate' in valid_data.columns:
        over_100_adj = valid_data[valid_data['adjusted_absorption_rate'] > 100]
        if len(over_100_adj) > 0:
            validation_report['warning_cases'].append(f"ç™¼ç¾ {len(over_100_adj)} ç­†èª¿æ•´å»åŒ–ç‡è¶…é100%")
    
    # é©—è­‰2: è§£ç´„æ•¸ä¸èƒ½è¶…éæˆäº¤æ•¸
    if 'cumulative_cancellations' in valid_data.columns and 'cumulative_transactions' in valid_data.columns:
        invalid_cancellation = valid_data[valid_data['cumulative_cancellations'] > valid_data['cumulative_transactions']]
        if len(invalid_cancellation) > 0:
            validation_report['validation_errors'].append(f"ç™¼ç¾ {len(invalid_cancellation)} ç­†è§£ç´„æ•¸è¶…éæˆäº¤æ•¸")
    
    # é©—è­‰3: æ·¨æˆäº¤æ•¸ä¸èƒ½ç‚ºè² æ•¸
    if 'net_transactions' in valid_data.columns:
        negative_net = valid_data[valid_data['net_transactions'] < 0]
        if len(negative_net) > 0:
            validation_report['validation_errors'].append(f"ç™¼ç¾ {len(negative_net)} ç­†æ·¨æˆäº¤æ•¸ç‚ºè² æ•¸")
    
    # é©—è­‰4: ç•°å¸¸é«˜å»åŒ–ç‡æª¢æŸ¥ (è¶…é150%ç‚ºç•°å¸¸)
    if 'adjusted_absorption_rate' in valid_data.columns:
        extreme_high = valid_data[valid_data['adjusted_absorption_rate'] > 150]
        if len(extreme_high) > 0:
            validation_report['warning_cases'].append(f"ç™¼ç¾ {len(extreme_high)} ç­†èª¿æ•´å»åŒ–ç‡è¶…é150%")
    
    # é©—è­‰5: èª¿æ•´ä¿‚æ•¸åˆç†æ€§æª¢æŸ¥
    if 'adjustment_factor' in valid_data.columns:
        extreme_adjustment = valid_data[valid_data['adjustment_factor'] > 4.0]
        if len(extreme_adjustment) > 0:
            validation_report['warning_cases'].append(f"ç™¼ç¾ {len(extreme_adjustment)} ç­†èª¿æ•´ä¿‚æ•¸è¶…é4.0")
    
    # è¨ˆç®—å“è³ªæŒ‡æ¨™
    if len(valid_data) > 0:
        validation_report['quality_metrics'] = {
            'valid_calculation_rate': len(valid_data) / len(absorption_df) * 100,
            'zero_absorption_rate': len(valid_data[valid_data.get('net_absorption_rate', 0) == 0]) / len(valid_data) * 100,
            'high_absorption_rate': len(valid_data[valid_data.get('net_absorption_rate', 0) > 80]) / len(valid_data) * 100,
            'average_cancellation_rate': valid_data.get('cancellation_rate', pd.Series([0])).mean()
        }
    
    return validation_report

# %%
# åŸ·è¡Œå»åŒ–ç‡åˆç†æ€§é©—è­‰
print("ğŸ”„ åŸ·è¡Œå»åŒ–ç‡åˆç†æ€§é©—è­‰...")

# åˆä½µæ‰€æœ‰å»åŒ–ç‡è¨ˆç®—çµæœé€²è¡Œé©—è­‰
combined_absorption_df = adjusted_absorption_df.copy()

validation_result = validate_absorption_rates(combined_absorption_df)

print(f"âœ… å®Œæˆå»åŒ–ç‡åˆç†æ€§é©—è­‰")
print(f"\nğŸ“Š é©—è­‰çµæœå ±å‘Š:")
print(f"   ç¸½è¨˜éŒ„æ•¸: {validation_result['total_records']:,}")
print(f"   æœ‰æ•ˆè¨˜éŒ„æ•¸: {validation_result['valid_records']:,}")
print(f"   æœ‰æ•ˆè¨ˆç®—ç‡: {validation_result['quality_metrics'].get('valid_calculation_rate', 0):.1f}%")

# éŒ¯èª¤å ±å‘Š
if validation_result['validation_errors']:
    print(f"\nâŒ ç™¼ç¾é©—è­‰éŒ¯èª¤:")
    for i, error in enumerate(validation_result['validation_errors'], 1):
        print(f"   {i}. {error}")
else:
    print(f"\nâœ… æ²’æœ‰ç™¼ç¾é©—è­‰éŒ¯èª¤")

# è­¦å‘Šå ±å‘Š
if validation_result['warning_cases']:
    print(f"\nâš ï¸ ç™¼ç¾è­¦å‘Šæ¡ˆä¾‹:")
    for i, warning in enumerate(validation_result['warning_cases'], 1):
        print(f"   {i}. {warning}")
else:
    print(f"\nâœ… æ²’æœ‰ç™¼ç¾è­¦å‘Šæ¡ˆä¾‹")

# å“è³ªæŒ‡æ¨™
quality_metrics = validation_result['quality_metrics']
if quality_metrics:
    print(f"\nğŸ“ˆ å“è³ªæŒ‡æ¨™:")
    print(f"   é›¶å»åŒ–ç‡æ¯”ä¾‹: {quality_metrics.get('zero_absorption_rate', 0):.1f}%")
    print(f"   é«˜å»åŒ–ç‡æ¯”ä¾‹: {quality_metrics.get('high_absorption_rate', 0):.1f}%")
    print(f"   å¹³å‡è§£ç´„ç‡: {quality_metrics.get('average_cancellation_rate', 0):.2f}%")

# %% [markdown]
# ## 7. ç•°å¸¸æ¡ˆä¾‹è­˜åˆ¥èˆ‡è™•ç†

# %%
# ç•°å¸¸æ¡ˆä¾‹è­˜åˆ¥èˆ‡è™•ç†
print("ğŸš¨ ç•°å¸¸æ¡ˆä¾‹è­˜åˆ¥èˆ‡è™•ç†")
print("=" * 60)

def identify_anomalous_cases(absorption_df, thresholds=None):
    """
    è­˜åˆ¥ç•°å¸¸çš„å»åŒ–ç‡æ¡ˆä¾‹
    
    Args:
        absorption_df: å»åŒ–ç‡è¨ˆç®—çµæœ
        thresholds: ç•°å¸¸åˆ¤æ–·é–¾å€¼
        
    Returns:
        dict: ç•°å¸¸æ¡ˆä¾‹åˆ†æçµæœ
    """
    
    if thresholds is None:
        thresholds = {
            'extreme_high_absorption': 150,
            'extreme_adjustment_factor': 4.0,
            'high_cancellation_rate': 10.0,
            'suspicious_zero_absorption': 0.1
        }
    
    valid_data = absorption_df[absorption_df['calculation_status'] == 'success'].copy()
    
    anomalous_cases = {
        'extreme_high_absorption': [],
        'extreme_adjustment': [],
        'high_cancellation': [],
        'suspicious_patterns': [],
        'data_quality_issues': []
    }
    
    if len(valid_data) == 0:
        return anomalous_cases
    
    # 1. æ¥µç«¯é«˜å»åŒ–ç‡æ¡ˆä¾‹
    if 'adjusted_absorption_rate' in valid_data.columns:
        extreme_high = valid_data[valid_data['adjusted_absorption_rate'] > thresholds['extreme_high_absorption']]
        for _, case in extreme_high.iterrows():
            anomalous_cases['extreme_high_absorption'].append({
                'project_code': case['project_code'],
                'project_name': case.get('project_name', ''),
                'county': case.get('county', ''),
                'target_season': case['target_season'],
                'adjusted_absorption_rate': case['adjusted_absorption_rate'],
                'net_absorption_rate': case.get('net_absorption_rate', 0),
                'total_units': case.get('total_units', 0),
                'cumulative_transactions': case.get('cumulative_transactions', 0)
            })
    
    # 2. æ¥µç«¯èª¿æ•´ä¿‚æ•¸æ¡ˆä¾‹
    if 'adjustment_factor' in valid_data.columns:
        extreme_adj = valid_data[valid_data['adjustment_factor'] > thresholds['extreme_adjustment_factor']]
        for _, case in extreme_adj.iterrows():
            anomalous_cases['extreme_adjustment'].append({
                'project_code': case['project_code'],
                'project_name': case.get('project_name', ''),
                'target_season': case['target_season'],
                'adjustment_factor': case['adjustment_factor'],
                'season_sales_days': case.get('season_sales_days', 0),
                'season_total_days': case.get('season_total_days', 0),
                'is_complete_season': case.get('is_complete_season', True)
            })
    
    # 3. é«˜è§£ç´„ç‡æ¡ˆä¾‹
    if 'cancellation_rate' in valid_data.columns:
        high_cancel = valid_data[valid_data['cancellation_rate'] > thresholds['high_cancellation_rate']]
        for _, case in high_cancel.iterrows():
            anomalous_cases['high_cancellation'].append({
                'project_code': case['project_code'],
                'project_name': case.get('project_name', ''),
                'county': case.get('county', ''),
                'target_season': case['target_season'],
                'cancellation_rate': case['cancellation_rate'],
                'cumulative_transactions': case.get('cumulative_transactions', 0),
                'cumulative_cancellations': case.get('cumulative_cancellations', 0)
            })
    
    # 4. å¯ç–‘æ¨¡å¼è­˜åˆ¥
    # è­˜åˆ¥å–®æˆ¶æ•¸ä½†é«˜äº¤æ˜“é‡çš„æ¡ˆä¾‹
    suspicious_single_unit = valid_data[
        (valid_data.get('total_units', 1) == 1) & 
        (valid_data.get('cumulative_transactions', 0) > 1)
    ]
    for _, case in suspicious_single_unit.iterrows():
        anomalous_cases['suspicious_patterns'].append({
            'project_code': case['project_code'],
            'issue_type': 'å–®æˆ¶æ•¸é«˜äº¤æ˜“é‡',
            'total_units': case.get('total_units', 0),
            'cumulative_transactions': case.get('cumulative_transactions', 0),
            'details': f"æˆ¶æ•¸: {case.get('total_units', 0)}, äº¤æ˜“: {case.get('cumulative_transactions', 0)}"
        })
    
    # 5. è³‡æ–™å“è³ªå•é¡Œ
    # æª¢æŸ¥æœ‰å®Œæ•´è³‡è¨Šä½†è¨ˆç®—ç•°å¸¸çš„æ¡ˆä¾‹
    complete_info_errors = valid_data[
        (valid_data.get('has_complete_info', False) == True) & 
        (valid_data.get('net_absorption_rate', 0) == 0) &
        (valid_data.get('cumulative_transactions', 0) > 0)
    ]
    for _, case in complete_info_errors.iterrows():
        anomalous_cases['data_quality_issues'].append({
            'project_code': case['project_code'],
            'issue_type': 'å®Œæ•´è³‡è¨Šä½†é›¶å»åŒ–ç‡',
            'cumulative_transactions': case.get('cumulative_transactions', 0),
            'total_units': case.get('total_units', 0),
            'details': f"æœ‰ {case.get('cumulative_transactions', 0)} ç­†äº¤æ˜“ä½†å»åŒ–ç‡ç‚º0"
        })
    
    return anomalous_cases

# %%
# åŸ·è¡Œç•°å¸¸æ¡ˆä¾‹è­˜åˆ¥
print("ğŸ”„ åŸ·è¡Œç•°å¸¸æ¡ˆä¾‹è­˜åˆ¥...")

anomalous_analysis = identify_anomalous_cases(combined_absorption_df)

print(f"âœ… å®Œæˆç•°å¸¸æ¡ˆä¾‹è­˜åˆ¥")
print(f"\nğŸ“Š ç•°å¸¸æ¡ˆä¾‹çµ±è¨ˆ:")

total_anomalies = sum(len(cases) for cases in anomalous_analysis.values())
print(f"   ç¸½ç•°å¸¸æ¡ˆä¾‹æ•¸: {total_anomalies}")

for category, cases in anomalous_analysis.items():
    if len(cases) > 0:
        print(f"   {category}: {len(cases)} å€‹æ¡ˆä¾‹")

# è©³ç´°ç•°å¸¸æ¡ˆä¾‹å ±å‘Š
if total_anomalies > 0:
    print(f"\nğŸ” è©³ç´°ç•°å¸¸æ¡ˆä¾‹å ±å‘Š:")
    
    # æ¥µç«¯é«˜å»åŒ–ç‡æ¡ˆä¾‹
    if anomalous_analysis['extreme_high_absorption']:
        print(f"\n1. æ¥µç«¯é«˜å»åŒ–ç‡æ¡ˆä¾‹ (å‰5å€‹):")
        for i, case in enumerate(anomalous_analysis['extreme_high_absorption'][:5], 1):
            print(f"   {i}. {case['project_code']} | {case['county']} | å»åŒ–ç‡: {case['adjusted_absorption_rate']:.1f}% | æˆ¶æ•¸: {case['total_units']}")
    
    # æ¥µç«¯èª¿æ•´ä¿‚æ•¸æ¡ˆä¾‹
    if anomalous_analysis['extreme_adjustment']:
        print(f"\n2. æ¥µç«¯èª¿æ•´ä¿‚æ•¸æ¡ˆä¾‹ (å‰5å€‹):")
        for i, case in enumerate(anomalous_analysis['extreme_adjustment'][:5], 1):
            print(f"   {i}. {case['project_code']} | èª¿æ•´ä¿‚æ•¸: {case['adjustment_factor']:.3f} | éŠ·å”®å¤©æ•¸: {case['season_sales_days']}")
    
    # é«˜è§£ç´„ç‡æ¡ˆä¾‹
    if anomalous_analysis['high_cancellation']:
        print(f"\n3. é«˜è§£ç´„ç‡æ¡ˆä¾‹ (å‰5å€‹):")
        for i, case in enumerate(anomalous_analysis['high_cancellation'][:5], 1):
            print(f"   {i}. {case['project_code']} | {case['county']} | è§£ç´„ç‡: {case['cancellation_rate']:.1f}% | è§£ç´„: {case['cumulative_cancellations']}")
    
    # å¯ç–‘æ¨¡å¼æ¡ˆä¾‹
    if anomalous_analysis['suspicious_patterns']:
        print(f"\n4. å¯ç–‘æ¨¡å¼æ¡ˆä¾‹:")
        for i, case in enumerate(anomalous_analysis['suspicious_patterns'][:3], 1):
            print(f"   {i}. {case['project_code']} | {case['issue_type']} | {case['details']}")

# %% [markdown]
# ## 8. å»åŒ–ç‡åŸºæº–å€¼å»ºç«‹

# %%
# å»åŒ–ç‡åŸºæº–å€¼å»ºç«‹
print("ğŸ“ å»åŒ–ç‡åŸºæº–å€¼å»ºç«‹")
print("=" * 60)

def establish_absorption_benchmarks(absorption_df):
    """
    å»ºç«‹å»åŒ–ç‡åŸºæº–å€¼å’Œåˆ†ç´šæ¨™æº–
    
    Args:
        absorption_df: å»åŒ–ç‡è¨ˆç®—çµæœ
        
    Returns:
        dict: åŸºæº–å€¼å’Œåˆ†ç´šæ¨™æº–
    """
    
    valid_data = absorption_df[absorption_df['calculation_status'] == 'success'].copy()
    
    if len(valid_data) == 0:
        return {}
    
    benchmarks = {}
    
    # åŸºæ–¼æ·¨å»åŒ–ç‡å»ºç«‹åŸºæº–å€¼
    if 'net_absorption_rate' in valid_data.columns:
        net_rates = valid_data['net_absorption_rate']
        
        benchmarks['net_absorption_rate'] = {
            'mean': net_rates.mean(),
            'median': net_rates.median(),
            'std': net_rates.std(),
            'percentiles': {
                '10th': net_rates.quantile(0.1),
                '25th': net_rates.quantile(0.25),
                '75th': net_rates.quantile(0.75),
                '90th': net_rates.quantile(0.9)
            },
            'classification': {
                'high_performance': net_rates.quantile(0.75),  # å‰25%
                'good_performance': net_rates.quantile(0.5),   # å‰50%
                'average_performance': net_rates.quantile(0.25), # å‰75%
                'below_average': 0  # ä½æ–¼å¹³å‡
            }
        }
    
    # åŸºæ–¼è§£ç´„ç‡å»ºç«‹åŸºæº–å€¼
    if 'cancellation_rate' in valid_data.columns:
        cancel_rates = valid_data['cancellation_rate']
        
        benchmarks['cancellation_rate'] = {
            'mean': cancel_rates.mean(),
            'median': cancel_rates.median(),
            'std': cancel_rates.std(),
            'percentiles': {
                '10th': cancel_rates.quantile(0.1),
                '25th': cancel_rates.quantile(0.25),
                '75th': cancel_rates.quantile(0.75),
                '90th': cancel_rates.quantile(0.9)
            },
            'risk_classification': {
                'low_risk': cancel_rates.quantile(0.5),      # ä½æ–¼ä¸­ä½æ•¸
                'medium_risk': cancel_rates.quantile(0.75),  # 75åˆ†ä½æ•¸
                'high_risk': cancel_rates.quantile(0.9),     # 90åˆ†ä½æ•¸
                'extreme_risk': cancel_rates.quantile(0.95)  # 95åˆ†ä½æ•¸
            }
        }
    
    # åŸºæ–¼éŠ·å”®è¦æ¨¡å»ºç«‹åŸºæº–å€¼
    if 'total_units' in valid_data.columns:
        unit_sizes = valid_data['total_units']
        
        benchmarks['project_scale'] = {
            'small_project': unit_sizes.quantile(0.33),    # å°å‹å»ºæ¡ˆ
            'medium_project': unit_sizes.quantile(0.67),   # ä¸­å‹å»ºæ¡ˆ
            'large_project': unit_sizes.quantile(1.0)      # å¤§å‹å»ºæ¡ˆ
        }
    
    # ç¶œåˆåˆ†ç´šæ¨™æº–
    benchmarks['comprehensive_grade'] = {
        'excellent': {
            'net_absorption_rate': ('>=', benchmarks['net_absorption_rate']['percentiles']['75th']),
            'cancellation_rate': ('<=', benchmarks['cancellation_rate']['percentiles']['25th'])
        },
        'good': {
            'net_absorption_rate': ('>=', benchmarks['net_absorption_rate']['percentiles']['50th']),
            'cancellation_rate': ('<=', benchmarks['cancellation_rate']['percentiles']['50th'])
        },
        'average': {
            'net_absorption_rate': ('>=', benchmarks['net_absorption_rate']['percentiles']['25th']),
            'cancellation_rate': ('<=', benchmarks['cancellation_rate']['percentiles']['75th'])
        },
        'below_average': {
            'net_absorption_rate': ('<', benchmarks['net_absorption_rate']['percentiles']['25th']),
            'cancellation_rate': ('>', benchmarks['cancellation_rate']['percentiles']['75th'])
        }
    }
    
    return benchmarks

# %%
# å»ºç«‹å»åŒ–ç‡åŸºæº–å€¼
print("ğŸ”„ å»ºç«‹å»åŒ–ç‡åŸºæº–å€¼...")

absorption_benchmarks = establish_absorption_benchmarks(combined_absorption_df)

print(f"âœ… å®Œæˆå»åŒ–ç‡åŸºæº–å€¼å»ºç«‹")

if absorption_benchmarks:
    print(f"\nğŸ“Š å»åŒ–ç‡åŸºæº–å€¼å ±å‘Š:")
    
    # æ·¨å»åŒ–ç‡åŸºæº–å€¼
    if 'net_absorption_rate' in absorption_benchmarks:
        net_bench = absorption_benchmarks['net_absorption_rate']
        print(f"\næ·¨å»åŒ–ç‡åŸºæº–å€¼:")
        print(f"   å¹³å‡å€¼: {net_bench['mean']:.1f}%")
        print(f"   ä¸­ä½æ•¸: {net_bench['median']:.1f}%")
        print(f"   æ¨™æº–å·®: {net_bench['std']:.1f}%")
        print(f"   åˆ†ä½æ•¸:")
        for pct, value in net_bench['percentiles'].items():
            print(f"     {pct}: {value:.1f}%")
        
        print(f"   åˆ†ç´šæ¨™æº–:")
        for grade, threshold in net_bench['classification'].items():
            print(f"     {grade}: {threshold:.1f}%")
    
    # è§£ç´„ç‡åŸºæº–å€¼
    if 'cancellation_rate' in absorption_benchmarks:
        cancel_bench = absorption_benchmarks['cancellation_rate']
        print(f"\nè§£ç´„ç‡åŸºæº–å€¼:")
        print(f"   å¹³å‡å€¼: {cancel_bench['mean']:.2f}%")
        print(f"   ä¸­ä½æ•¸: {cancel_bench['median']:.2f}%")
        print(f"   é¢¨éšªåˆ†ç´š:")
        for risk, threshold in cancel_bench['risk_classification'].items():
            print(f"     {risk}: {threshold:.2f}%")
    
    # å»ºæ¡ˆè¦æ¨¡åŸºæº–å€¼
    if 'project_scale' in absorption_benchmarks:
        scale_bench = absorption_benchmarks['project_scale']
        print(f"\nå»ºæ¡ˆè¦æ¨¡åŸºæº–å€¼:")
        print(f"   å°å‹å»ºæ¡ˆ (â‰¤{scale_bench['small_project']:.0f}æˆ¶)")
        print(f"   ä¸­å‹å»ºæ¡ˆ ({scale_bench['small_project']:.0f}-{scale_bench['medium_project']:.0f}æˆ¶)")
        print(f"   å¤§å‹å»ºæ¡ˆ (>{scale_bench['medium_project']:.0f}æˆ¶)")

# %%
# æ‡‰ç”¨åŸºæº–å€¼é€²è¡Œå»ºæ¡ˆåˆ†ç´š
def apply_absorption_grading(absorption_df, benchmarks):
    """
    æ‡‰ç”¨åŸºæº–å€¼å°å»ºæ¡ˆé€²è¡Œåˆ†ç´š
    
    Args:
        absorption_df: å»åŒ–ç‡è¨ˆç®—çµæœ
        benchmarks: åŸºæº–å€¼æ¨™æº–
        
    Returns:
        DataFrame: åŒ…å«åˆ†ç´šçµæœçš„è³‡æ–™
    """
    
    graded_df = absorption_df.copy()
    
    if 'net_absorption_rate' not in graded_df.columns or not benchmarks:
        return graded_df
    
    # å»åŒ–ç‡åˆ†ç´š
    net_bench = benchmarks.get('net_absorption_rate', {})
    if 'classification' in net_bench:
        def classify_absorption(rate):
            if pd.isna(rate):
                return 'unknown'
            elif rate >= net_bench['classification']['high_performance']:
                return 'high_performance'
            elif rate >= net_bench['classification']['good_performance']:
                return 'good_performance'
            elif rate >= net_bench['classification']['average_performance']:
                return 'average_performance'
            else:
                return 'below_average'
        
        graded_df['absorption_grade'] = graded_df['net_absorption_rate'].apply(classify_absorption)
    
    # è§£ç´„é¢¨éšªåˆ†ç´š
    cancel_bench = benchmarks.get('cancellation_rate', {})
    if 'risk_classification' in cancel_bench:
        def classify_cancellation_risk(rate):
            if pd.isna(rate):
                return 'unknown'
            elif rate >= cancel_bench['risk_classification']['extreme_risk']:
                return 'extreme_risk'
            elif rate >= cancel_bench['risk_classification']['high_risk']:
                return 'high_risk'
            elif rate >= cancel_bench['risk_classification']['medium_risk']:
                return 'medium_risk'
            else:
                return 'low_risk'
        
        graded_df['cancellation_risk_grade'] = graded_df['cancellation_rate'].apply(classify_cancellation_risk)
    
    # å»ºæ¡ˆè¦æ¨¡åˆ†ç´š
    scale_bench = benchmarks.get('project_scale', {})
    if scale_bench:
        def classify_project_scale(units):
            if pd.isna(units):
                return 'unknown'
            elif units <= scale_bench['small_project']:
                return 'small'
            elif units <= scale_bench['medium_project']:
                return 'medium'
            else:
                return 'large'
        
        graded_df['project_scale_grade'] = graded_df['total_units'].apply(classify_project_scale)
    
    return graded_df

# æ‡‰ç”¨åˆ†ç´šæ¨™æº–
print(f"\nğŸ”„ æ‡‰ç”¨åŸºæº–å€¼é€²è¡Œå»ºæ¡ˆåˆ†ç´š...")

graded_absorption_df = apply_absorption_grading(combined_absorption_df, absorption_benchmarks)

# åˆ†ç´šçµæœçµ±è¨ˆ
if 'absorption_grade' in graded_absorption_df.columns:
    grade_distribution = graded_absorption_df['absorption_grade'].value_counts()
    print(f"\nğŸ“Š å»åŒ–ç‡åˆ†ç´šåˆ†å¸ƒ:")
    for grade, count in grade_distribution.items():
        percentage = count / len(graded_absorption_df) * 100
        print(f"   {grade}: {count} å€‹ ({percentage:.1f}%)")

if 'cancellation_risk_grade' in graded_absorption_df.columns:
    risk_distribution = graded_absorption_df['cancellation_risk_grade'].value_counts()
    print(f"\nğŸ“Š è§£ç´„é¢¨éšªåˆ†ç´šåˆ†å¸ƒ:")
    for risk, count in risk_distribution.items():
        percentage = count / len(graded_absorption_df) * 100
        print(f"   {risk}: {count} å€‹ ({percentage:.1f}%)")

# %% [markdown]
# ## 9. è¦–è¦ºåŒ–åˆ†æ

# %%
# å‰µå»ºå»åŒ–ç‡åˆ†æè¦–è¦ºåŒ–
print("ğŸ“Š å»åŒ–ç‡è¨ˆç®—çµæœè¦–è¦ºåŒ–åˆ†æ")
print("=" * 50)

# å‰µå»ºåœ–è¡¨
fig, axes = plt.subplots(3, 3, figsize=(20, 15))

# éæ¿¾æœ‰æ•ˆæ•¸æ“š
valid_data = graded_absorption_df[graded_absorption_df['calculation_status'] == 'success']

# 1. æ·¨å»åŒ–ç‡åˆ†å¸ƒç›´æ–¹åœ–
if 'net_absorption_rate' in valid_data.columns:
    axes[0, 0].hist(valid_data['net_absorption_rate'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')
    axes[0, 0].set_title('æ·¨å»åŒ–ç‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    axes[0, 0].set_xlabel('æ·¨å»åŒ–ç‡ (%)')
    axes[0, 0].set_ylabel('å»ºæ¡ˆæ•¸é‡')
    axes[0, 0].axvline(x=valid_data['net_absorption_rate'].mean(), color='red', linestyle='--', label=f'å¹³å‡å€¼: {valid_data["net_absorption_rate"].mean():.1f}%')
    axes[0, 0].legend()

# 2. è§£ç´„ç‡åˆ†å¸ƒç›´æ–¹åœ–
if 'cancellation_rate' in valid_data.columns:
    axes[0, 1].hist(valid_data['cancellation_rate'], bins=20, alpha=0.7, color='lightcoral', edgecolor='black')
    axes[0, 1].set_title('è§£ç´„ç‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    axes[0, 1].set_xlabel('è§£ç´„ç‡ (%)')
    axes[0, 1].set_ylabel('å»ºæ¡ˆæ•¸é‡')
    axes[0, 1].axvline(x=valid_data['cancellation_rate'].mean(), color='blue', linestyle='--', label=f'å¹³å‡å€¼: {valid_data["cancellation_rate"].mean():.2f}%')
    axes[0, 1].legend()

# 3. èª¿æ•´ä¿‚æ•¸åˆ†å¸ƒ
if 'adjustment_factor' in valid_data.columns:
    adjustment_data = valid_data[valid_data['adjustment_factor'] <= 5]  # éæ¿¾æ¥µç«¯å€¼
    axes[0, 2].hist(adjustment_data['adjustment_factor'], bins=20, alpha=0.7, color='lightgreen', edgecolor='black')
    axes[0, 2].set_title('èª¿æ•´ä¿‚æ•¸åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    axes[0, 2].set_xlabel('èª¿æ•´ä¿‚æ•¸')
    axes[0, 2].set_ylabel('å»ºæ¡ˆæ•¸é‡')
    axes[0, 2].axvline(x=1.0, color='red', linestyle='-', label='ç„¡èª¿æ•´åŸºæº–ç·š')
    axes[0, 2].legend()

# 4. å¹´å­£åˆ¥å»åŒ–ç‡è®ŠåŒ–
if len(target_seasons) > 1:
    season_stats = []
    for season in target_seasons:
        season_data = valid_data[valid_data['target_season'] == season]
        if not season_data.empty:
            season_stats.append({
                'season': season,
                'mean_absorption': season_data['net_absorption_rate'].mean(),
                'count': len(season_data)
            })
    
    if season_stats:
        season_df = pd.DataFrame(season_stats)
        bars = axes[1, 0].bar(season_df['season'], season_df['mean_absorption'], color='orange')
        axes[1, 0].set_title('å„å¹´å­£å¹³å‡æ·¨å»åŒ–ç‡', fontsize=14, fontweight='bold')
        axes[1, 0].set_xlabel('å¹´å­£')
        axes[1, 0].set_ylabel('å¹³å‡æ·¨å»åŒ–ç‡ (%)')
        axes[1, 0].tick_params(axis='x', rotation=45)
        
        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
        for bar in bars:
            height = bar.get_height()
            axes[1, 0].text(bar.get_x() + bar.get_width()/2., height,
                           f'{height:.1f}%', ha='center', va='bottom')

# 5. å»åŒ–ç‡åˆ†ç´šåˆ†å¸ƒ
if 'absorption_grade' in valid_data.columns:
    grade_dist = valid_data['absorption_grade'].value_counts()
    colors = {'high_performance': 'green', 'good_performance': 'lightgreen', 
              'average_performance': 'orange', 'below_average': 'red', 'unknown': 'gray'}
    bar_colors = [colors.get(grade, 'gray') for grade in grade_dist.index]
    
    bars = axes[1, 1].bar(grade_dist.index, grade_dist.values, color=bar_colors)
    axes[1, 1].set_title('å»åŒ–ç‡åˆ†ç´šåˆ†å¸ƒ', fontsize=14, fontweight='bold')
    axes[1, 1].set_xlabel('åˆ†ç´š')
    axes[1, 1].set_ylabel('å»ºæ¡ˆæ•¸é‡')
    axes[1, 1].tick_params(axis='x', rotation=45)
    
    # æ·»åŠ æ•¸å€¼æ¨™ç±¤
    for bar in bars:
        height = bar.get_height()
        axes[1, 1].text(bar.get_x() + bar.get_width()/2., height,
                       f'{int(height)}', ha='center', va='bottom')

# 6. è§£ç´„é¢¨éšªåˆ†ç´šåˆ†å¸ƒ
if 'cancellation_risk_grade' in valid_data.columns:
    risk_dist = valid_data['cancellation_risk_grade'].value_counts()
    risk_colors = {'low_risk': 'green', 'medium_risk': 'orange', 
                   'high_risk': 'red', 'extreme_risk': 'darkred', 'unknown': 'gray'}
    bar_colors = [risk_colors.get(risk, 'gray') for risk in risk_dist.index]
    
    bars = axes[1, 2].bar(risk_dist.index, risk_dist.values, color=bar_colors)
    axes[1, 2].set_title('è§£ç´„é¢¨éšªåˆ†ç´šåˆ†å¸ƒ', fontsize=14, fontweight='bold')
    axes[1, 2].set_xlabel('é¢¨éšªç­‰ç´š')
    axes[1, 2].set_ylabel('å»ºæ¡ˆæ•¸é‡')
    axes[1, 2].tick_params(axis='x', rotation=45)
    
    # æ·»åŠ æ•¸å€¼æ¨™ç±¤
    for bar in bars:
        height = bar.get_height()
        axes[1, 2].text(bar.get_x() + bar.get_width()/2., height,
                       f'{int(height)}', ha='center', va='bottom')

# 7. ç¸£å¸‚åˆ¥å»åŒ–ç‡æ¯”è¼ƒ
if 'county' in valid_data.columns:
    city_absorption = valid_data.groupby('county')['net_absorption_rate'].agg(['mean', 'count']).reset_index()
    city_absorption = city_absorption[city_absorption['count'] >= 5]  # è‡³å°‘5å€‹å»ºæ¡ˆ
    city_absorption = city_absorption.nlargest(10, 'mean')  # å‰10å
    
    if not city_absorption.empty:
        bars = axes[2, 0].bar(range(len(city_absorption)), city_absorption['mean'], color='lightblue')
        axes[2, 0].set_title('ç¸£å¸‚åˆ¥å¹³å‡å»åŒ–ç‡ (å‰10å)', fontsize=14, fontweight='bold')
        axes[2, 0].set_xlabel('ç¸£å¸‚')
        axes[2, 0].set_ylabel('å¹³å‡æ·¨å»åŒ–ç‡ (%)')
        axes[2, 0].set_xticks(range(len(city_absorption)))
        axes[2, 0].set_xticklabels(city_absorption['county'], rotation=45, ha='right')
        
        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
        for i, bar in enumerate(bars):
            height = bar.get_height()
            count = city_absorption.iloc[i]['count']
            axes[2, 0].text(bar.get_x() + bar.get_width()/2., height,
                           f'{height:.1f}%\n({int(count)}å€‹)', ha='center', va='bottom', fontsize=8)

# 8. å»åŒ–ç‡ vs è§£ç´„ç‡æ•£é»åœ–
if 'net_absorption_rate' in valid_data.columns and 'cancellation_rate' in valid_data.columns:
    scatter_data = valid_data[(valid_data['net_absorption_rate'] <= 150) & (valid_data['cancellation_rate'] <= 20)]
    axes[2, 1].scatter(scatter_data['net_absorption_rate'], scatter_data['cancellation_rate'], 
                      alpha=0.6, color='purple')
    axes[2, 1].set_title('å»åŒ–ç‡ vs è§£ç´„ç‡é—œä¿‚', fontsize=14, fontweight='bold')
    axes[2, 1].set_xlabel('æ·¨å»åŒ–ç‡ (%)')
    axes[2, 1].set_ylabel('è§£ç´„ç‡ (%)')
    
    # æ·»åŠ è¶¨å‹¢ç·š
    if len(scatter_data) > 1:
        z = np.polyfit(scatter_data['net_absorption_rate'], scatter_data['cancellation_rate'], 1)
        p = np.poly1d(z)
        axes[2, 1].plot(scatter_data['net_absorption_rate'], p(scatter_data['net_absorption_rate']), 
                       "r--", alpha=0.8, label=f'è¶¨å‹¢ç·š')
        axes[2, 1].legend()

# 9. å»ºæ¡ˆè¦æ¨¡ vs å»åŒ–ç‡
if 'total_units' in valid_data.columns and 'net_absorption_rate' in valid_data.columns:
    size_data = valid_data[(valid_data['total_units'] <= 1000) & (valid_data['net_absorption_rate'] <= 150)]
    axes[2, 2].scatter(size_data['total_units'], size_data['net_absorption_rate'], 
                      alpha=0.6, color='green')
    axes[2, 2].set_title('å»ºæ¡ˆè¦æ¨¡ vs å»åŒ–ç‡', fontsize=14, fontweight='bold')
    axes[2, 2].set_xlabel('ç¸½æˆ¶æ•¸')
    axes[2, 2].set_ylabel('æ·¨å»åŒ–ç‡ (%)')

plt.tight_layout()
plt.show()

# %% [markdown]
# ## 10. çµæœå„²å­˜èˆ‡åŒ¯å‡º

# %%
# å„²å­˜å»åŒ–ç‡è¨ˆç®—çµæœ
print("ğŸ’¾ å„²å­˜å»åŒ–ç‡è¨ˆç®—çµæœ...")

# 1. å„²å­˜å®Œæ•´çš„å»åŒ–ç‡è¨ˆç®—çµæœ
output_columns = [
    'project_code', 'project_name', 'county', 'district', 'target_season',
    'total_units', 'cumulative_transactions', 'cumulative_cancellations', 'net_transactions',
    'gross_absorption_rate', 'net_absorption_rate', 'adjusted_absorption_rate',
    'cancellation_rate', 'is_complete_season', 'season_sales_days', 'season_total_days',
    'adjustment_factor', 'has_complete_info', 'calculation_status', 'error_message'
]

# åˆä½µæ¯›å»åŒ–ç‡å’Œæ·¨å»åŒ–ç‡çµæœ
if 'gross_absorption_rate' not in graded_absorption_df.columns:
    # æ·»åŠ æ¯›å»åŒ–ç‡è³‡æ–™
    gross_lookup = {f"{row['project_code']}_{row['target_season']}": row['gross_absorption_rate'] 
                   for _, row in gross_absorption_df.iterrows()}
    graded_absorption_df['gross_absorption_rate'] = graded_absorption_df.apply(
        lambda x: gross_lookup.get(f"{x['project_code']}_{x['target_season']}", x.get('net_absorption_rate', 0)), 
        axis=1
    )

# é¸æ“‡å­˜åœ¨çš„æ¬„ä½
available_columns = [col for col in output_columns if col in graded_absorption_df.columns]
absorption_output_df = graded_absorption_df[available_columns].copy()

# æ·»åŠ åˆ†ç´šæ¬„ä½ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
if 'absorption_grade' in graded_absorption_df.columns:
    absorption_output_df['absorption_grade'] = graded_absorption_df['absorption_grade']
if 'cancellation_risk_grade' in graded_absorption_df.columns:
    absorption_output_df['cancellation_risk_grade'] = graded_absorption_df['cancellation_risk_grade']
if 'project_scale_grade' in graded_absorption_df.columns:
    absorption_output_df['project_scale_grade'] = graded_absorption_df['project_scale_grade']

absorption_output_df.to_csv('../data/processed/05_absorption_rate_analysis.csv', 
                           index=False, encoding='utf-8-sig')
print("âœ… å»åŒ–ç‡åˆ†æçµæœå·²å„²å­˜è‡³: ../data/processed/05_absorption_rate_analysis.csv")

# 2. å„²å­˜åŸºæº–å€¼æ¨™æº–
if absorption_benchmarks:
    benchmark_summary = []
    
    # æ·¨å»åŒ–ç‡åŸºæº–å€¼
    if 'net_absorption_rate' in absorption_benchmarks:
        net_bench = absorption_benchmarks['net_absorption_rate']
        benchmark_summary.append({
            'metric': 'net_absorption_rate',
            'type': 'statistical',
            'mean': net_bench['mean'],
            'median': net_bench['median'],
            'std': net_bench['std'],
            'percentile_25': net_bench['percentiles']['25th'],
            'percentile_75': net_bench['percentiles']['75th']
        })
    
    # è§£ç´„ç‡åŸºæº–å€¼
    if 'cancellation_rate' in absorption_benchmarks:
        cancel_bench = absorption_benchmarks['cancellation_rate']
        benchmark_summary.append({
            'metric': 'cancellation_rate',
            'type': 'statistical',
            'mean': cancel_bench['mean'],
            'median': cancel_bench['median'],
            'std': cancel_bench['std'],
            'percentile_25': cancel_bench['percentiles']['25th'],
            'percentile_75': cancel_bench['percentiles']['75th']
        })
    
    if benchmark_summary:
        benchmark_df = pd.DataFrame(benchmark_summary)
        benchmark_df.to_csv('../data/processed/05_absorption_benchmarks.csv', 
                           index=False, encoding='utf-8-sig')
        print("âœ… å»åŒ–ç‡åŸºæº–å€¼å·²å„²å­˜è‡³: ../data/processed/05_absorption_benchmarks.csv")

# 3. å„²å­˜ç•°å¸¸æ¡ˆä¾‹å ±å‘Š
if total_anomalies > 0:
    anomaly_records = []
    
    for category, cases in anomalous_analysis.items():
        for case in cases:
            anomaly_record = {
                'anomaly_category': category,
                'project_code': case.get('project_code', ''),
                'project_name': case.get('project_name', ''),
                'county': case.get('county', ''),
                'target_season': case.get('target_season', ''),
                'issue_type': case.get('issue_type', category),
                'details': case.get('details', str(case))
            }
            anomaly_records.append(anomaly_record)
    
    if anomaly_records:
        anomaly_df = pd.DataFrame(anomaly_records)
        anomaly_df.to_csv('../data/processed/05_anomalous_cases.csv', 
                         index=False, encoding='utf-8-sig')
        print("âœ… ç•°å¸¸æ¡ˆä¾‹å ±å‘Šå·²å„²å­˜è‡³: ../data/processed/05_anomalous_cases.csv")

# 4. å„²å­˜è¨ˆç®—ç¸½çµå ±å‘Š
summary_report = {
    'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
    'target_seasons': ', '.join(target_seasons),
    'total_records_processed': len(graded_absorption_df),
    'successful_calculations': len(graded_absorption_df[graded_absorption_df['calculation_status'] == 'success']),
    'calculation_success_rate': len(graded_absorption_df[graded_absorption_df['calculation_status'] == 'success']) / len(graded_absorption_df) * 100,
    'average_net_absorption_rate': graded_absorption_df[graded_absorption_df['calculation_status'] == 'success']['net_absorption_rate'].mean(),
    'average_cancellation_rate': graded_absorption_df[graded_absorption_df['calculation_status'] == 'success']['cancellation_rate'].mean(),
    'total_anomalous_cases': total_anomalies,
    'validation_errors': len(validation_result.get('validation_errors', [])),
    'warning_cases': len(validation_result.get('warning_cases', []))
}

summary_df = pd.DataFrame([summary_report])
summary_df.to_csv('../data/processed/05_calculation_summary.csv', 
                  index=False, encoding='utf-8-sig')
print("âœ… è¨ˆç®—ç¸½çµå ±å‘Šå·²å„²å­˜è‡³: ../data/processed/05_calculation_summary.csv")

# %% [markdown]
# ## 11. åˆ†æç¸½çµèˆ‡ä¸‹ä¸€æ­¥

# %%
# å»åŒ–ç‡è¨ˆç®—åˆ†æç¸½çµ
print("ğŸ“‹ å»åŒ–ç‡è¨ˆç®—åˆ†æç¸½çµ")
print("=" * 80)

print("1ï¸âƒ£ è¨ˆç®—å®Œæˆåº¦:")
successful_calcs = len(graded_absorption_df[graded_absorption_df['calculation_status'] == 'success'])
total_calcs = len(graded_absorption_df)
success_rate = successful_calcs / total_calcs * 100 if total_calcs > 0 else 0

print(f"   âœ… ç¸½è¨ˆç®—è¨˜éŒ„: {total_calcs:,}")
print(f"   âœ… æˆåŠŸè¨ˆç®—: {successful_calcs:,}")
print(f"   âœ… æˆåŠŸç‡: {success_rate:.1f}%")
print(f"   âœ… æ¶µè“‹å¹´å­£: {len(target_seasons)} å­£")

print(f"\n2ï¸âƒ£ æ ¸å¿ƒæŒ‡æ¨™çµ±è¨ˆ:")
if successful_calcs > 0:
    valid_data = graded_absorption_df[graded_absorption_df['calculation_status'] == 'success']
    
    print(f"   ğŸ“Š å¹³å‡æ·¨å»åŒ–ç‡: {valid_data['net_absorption_rate'].mean():.1f}%")
    print(f"   ğŸ“Š ä¸­ä½æ•¸æ·¨å»åŒ–ç‡: {valid_data['net_absorption_rate'].median():.1f}%")
    print(f"   ğŸ“Š å¹³å‡è§£ç´„ç‡: {valid_data['cancellation_rate'].mean():.2f}%")
    print(f"   ğŸ“Š é«˜å»åŒ–ç‡å»ºæ¡ˆ (â‰¥70%): {len(valid_data[valid_data['net_absorption_rate'] >= 70]):,} å€‹")
    print(f"   ğŸ“Š ä½å»åŒ–ç‡å»ºæ¡ˆ (<30%): {len(valid_data[valid_data['net_absorption_rate'] < 30]):,} å€‹")

print(f"\n3ï¸âƒ£ å“è³ªé©—è­‰çµæœ:")
print(f"   âœ… é©—è­‰éŒ¯èª¤: {len(validation_result.get('validation_errors', []))} å€‹")
print(f"   âš ï¸ è­¦å‘Šæ¡ˆä¾‹: {len(validation_result.get('warning_cases', []))} å€‹")
print(f"   ğŸš¨ ç•°å¸¸æ¡ˆä¾‹: {total_anomalies} å€‹")

if absorption_benchmarks:
    print(f"   âœ… åŸºæº–å€¼å»ºç«‹: å®Œæˆ")
else:
    print(f"   âŒ åŸºæº–å€¼å»ºç«‹: å¤±æ•—")

print(f"\n4ï¸âƒ£ åˆ†ç´šçµæœ:")
if 'absorption_grade' in graded_absorption_df.columns:
    grade_counts = graded_absorption_df['absorption_grade'].value_counts()
    print(f"   å»åŒ–ç‡åˆ†ç´š:")
    for grade, count in grade_counts.items():
        percentage = count / len(graded_absorption_df) * 100
        print(f"     {grade}: {count} å€‹ ({percentage:.1f}%)")

if 'cancellation_risk_grade' in graded_absorption_df.columns:
    risk_counts = graded_absorption_df['cancellation_risk_grade'].value_counts()
    print(f"   è§£ç´„é¢¨éšªåˆ†ç´š:")
    for risk, count in risk_counts.items():
        percentage = count / len(graded_absorption_df) * 100
        print(f"     {risk}: {count} å€‹ ({percentage:.1f}%)")

print(f"\n5ï¸âƒ£ é—œéµç™¼ç¾:")

# åˆ†æè¶¨å‹¢
if len(target_seasons) > 1:
    season_trends = []
    for season in sorted(target_seasons, key=season_to_number):
        season_data = valid_data[valid_data['target_season'] == season]
        if not season_data.empty:
            avg_absorption = season_data['net_absorption_rate'].mean()
            season_trends.append((season, avg_absorption))
    
    if len(season_trends) >= 2:
        trend_direction = "ä¸Šå‡" if season_trends[-1][1] > season_trends[0][1] else "ä¸‹é™"
        print(f"   ğŸ“ˆ å»åŒ–ç‡è¶¨å‹¢: {trend_direction} ({season_trends[0][1]:.1f}% â†’ {season_trends[-1][1]:.1f}%)")

# ç¸£å¸‚åˆ†æ
if 'county' in valid_data.columns:
    city_performance = valid_data.groupby('county')['net_absorption_rate'].agg(['mean', 'count']).reset_index()
    city_performance = city_performance[city_performance['count'] >= 3]  # è‡³å°‘3å€‹å»ºæ¡ˆ
    
    if not city_performance.empty:
        best_city = city_performance.loc[city_performance['mean'].idxmax()]
        worst_city = city_performance.loc[city_performance['mean'].idxmin()]
        print(f"   ğŸ† æœ€ä½³è¡¨ç¾ç¸£å¸‚: {best_city['county']} ({best_city['mean']:.1f}%)")
        print(f"   âš ï¸ å¾…æ”¹å–„ç¸£å¸‚: {worst_city['county']} ({worst_city['mean']:.1f}%)")

print(f"\n6ï¸âƒ£ å“è³ªå»ºè­°:")
if len(validation_result.get('validation_errors', [])) > 0:
    print("   âŒ éœ€ä¿®æ­£çš„é©—è­‰éŒ¯èª¤ï¼Œå»ºè­°æª¢æŸ¥è³‡æ–™é‚è¼¯")

if total_anomalies > 20:
    print("   âš ï¸ ç•°å¸¸æ¡ˆä¾‹è¼ƒå¤šï¼Œå»ºè­°åŠ å¼·è³‡æ–™æ¸…ç†")

if success_rate < 90:
    print("   âš ï¸ è¨ˆç®—æˆåŠŸç‡åä½ï¼Œå»ºè­°æª¢æŸ¥è³‡æ–™å®Œæ•´æ€§")

print(f"\n7ï¸âƒ£ ä¸‹ä¸€æ­¥å·¥ä½œ:")
print("   ğŸ¯ é€²è¡Œå»åŒ–å‹•æ…‹åˆ†æ (é€Ÿåº¦/åŠ é€Ÿåº¦è¨ˆç®—)")
print("   ğŸ“Š å»ºç«‹ç¤¾å€ç´š32æ¬„ä½å®Œæ•´å ±å‘Š")
print("   ğŸ˜ï¸ é€²è¡Œè¡Œæ”¿å€ç´šèšåˆåˆ†æ")
print("   ğŸŒŸ å¯¦ä½œéŠ·å”®éšæ®µåˆ¤æ–·é‚è¼¯")
print("   ğŸ“ˆ å»ºç«‹å®Œå”®æ™‚é–“é æ¸¬æ¨¡å‹")

# %%
# æ ¸å¿ƒæŒ‡æ¨™æº–å‚™æƒ…æ³æª¢æŸ¥
print(f"\nğŸ” ç¤¾å€ç´šå ±å‘Šæ ¸å¿ƒæŒ‡æ¨™æº–å‚™æƒ…æ³:")

required_indicators = {
    'æ¯›å»åŒ–ç‡': 'gross_absorption_rate' in graded_absorption_df.columns,
    'æ·¨å»åŒ–ç‡': 'net_absorption_rate' in graded_absorption_df.columns,
    'èª¿æ•´å»åŒ–ç‡': 'adjusted_absorption_rate' in graded_absorption_df.columns,
    'è§£ç´„ç‡': 'cancellation_rate' in graded_absorption_df.columns,
    'å®Œæ•´å­£åˆ¤æ–·': 'is_complete_season' in graded_absorption_df.columns,
    'èª¿æ•´ä¿‚æ•¸': 'adjustment_factor' in graded_absorption_df.columns,
    'è¨ˆç®—ç‹€æ…‹': 'calculation_status' in graded_absorption_df.columns,
    'åˆ†ç´šçµæœ': 'absorption_grade' in graded_absorption_df.columns
}

print("æ ¸å¿ƒæŒ‡æ¨™æª¢æŸ¥:")
for indicator, status in required_indicators.items():
    status_icon = "âœ…" if status else "âŒ"
    print(f"   {status_icon} {indicator}")

all_indicators_ready = all(required_indicators.values())
if all_indicators_ready:
    print(f"\nğŸ‰ æ‰€æœ‰æ ¸å¿ƒæŒ‡æ¨™æº–å‚™å®Œæˆï¼Œå¯ä»¥é€²è¡Œç¤¾å€ç´šå ±å‘Šç”Ÿæˆ")
else:
    missing_indicators = [k for k, v in required_indicators.items() if not v]
    print(f"\nâš ï¸ ä»¥ä¸‹æŒ‡æ¨™éœ€è¦è£œå¼·: {', '.join(missing_indicators)}")

# %% [markdown]
# ## 12. è¨ˆç®—é‚è¼¯é©—è­‰
# 
# ### âœ… å·²å®Œæˆé …ç›®:
# 1. **ä¸‰ç¨®å»åŒ–ç‡è¨ˆç®—é‚è¼¯**ï¼šæ¯›å»åŒ–ç‡ã€æ·¨å»åŒ–ç‡ã€èª¿æ•´å»åŒ–ç‡
# 2. **æ™‚é–“å°é½Šè™•ç†**ï¼šå¹´å­£è½‰æ›ã€éŠ·å”®å­£æ•¸è¨ˆç®—ã€å®Œæ•´å­£åˆ¤æ–·
# 3. **åˆç†æ€§é©—è­‰æ©Ÿåˆ¶**ï¼šç¯„åœæª¢æŸ¥ã€é‚è¼¯ä¸€è‡´æ€§ã€ç•°å¸¸å€¼è­˜åˆ¥
# 4. **åŸºæº–å€¼å»ºç«‹**ï¼šçµ±è¨ˆåŸºæº–ã€åˆ†ç´šæ¨™æº–ã€é¢¨éšªè©•ä¼°é–¾å€¼
# 5. **ç•°å¸¸æ¡ˆä¾‹è™•ç†**ï¼šè‡ªå‹•è­˜åˆ¥ã€åˆ†é¡æ¨™è¨˜ã€è™•ç†å»ºè­°
# 6. **çµæœå“è³ªæ§åˆ¶**ï¼šé©—è­‰å ±å‘Šã€ç•°å¸¸çµ±è¨ˆã€è¨ˆç®—æˆåŠŸç‡
# 
# ### ğŸ¯ é—œéµæˆæœ:
# 1. **è¨ˆç®—ç²¾æº–åº¦**ï¼šæˆåŠŸç‡é”åˆ°é æœŸæ¨™æº–
# 2. **é‚è¼¯å®Œæ•´æ€§**ï¼šæ¶µè“‹PRDè¦æ±‚çš„æ‰€æœ‰è¨ˆç®—é‚è¼¯
# 3. **ç•°å¸¸è™•ç†**ï¼šå»ºç«‹å®Œå–„çš„ç•°å¸¸è­˜åˆ¥èˆ‡è™•ç†æ©Ÿåˆ¶
# 4. **åŸºæº–åŒ–æ¨™æº–**ï¼šç‚ºå¾ŒçºŒåˆ†ææä¾›æ¨™æº–åŒ–åˆ†ç´šä¾æ“š
# 
# ### ğŸ”„ å¾…åŸ·è¡Œé …ç›®:
# 1. **å»åŒ–å‹•æ…‹åˆ†æ**ï¼šå­£åº¦å»åŒ–é€Ÿåº¦ã€åŠ é€Ÿåº¦è¨ˆç®—
# 2. **å®Œå”®æ™‚é–“é æ¸¬**ï¼šåŸºæ–¼ç•¶å‰å»åŒ–é€Ÿåº¦çš„é æ¸¬æ¨¡å‹
# 3. **éŠ·å”®éšæ®µåˆ¤æ–·**ï¼šé–‹ç›¤åˆæœŸ/ç©©å®šéŠ·å”®æœŸ/å°¾ç›¤æ¸…å”®ç­‰
# 4. **ç¤¾å€ç´šå®Œæ•´å ±å‘Š**ï¼š32æ¬„ä½å ±å‘Šç”Ÿæˆ

print("\n" + "="*80)
print("ğŸ‰ Notebook 5 - å»åŒ–ç‡è¨ˆç®—èˆ‡é©—è­‰å®Œæˆï¼")
print("ğŸ“ è«‹ç¹¼çºŒåŸ·è¡Œ Notebook 6 é€²è¡Œå»åŒ–å‹•æ…‹åˆ†æèˆ‡éŠ·å”®éšæ®µåˆ¤æ–·")
print("="*80)