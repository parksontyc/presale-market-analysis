# é å”®å±‹å¸‚å ´åˆ†æç³»çµ± - 10_è§£ç´„èˆ‡å»åŒ–å‹•æ…‹å°ˆé …åˆ†æè¦–è¦ºåŒ–
# åŸºæ–¼ PRD v2.3 è¦æ ¼é€²è¡Œå°ˆé …åˆ†æèˆ‡è¦–è¦ºåŒ–å±•ç¤º
# ================================================================================

# %% [markdown]
# # é å”®å±‹å¸‚å ´åˆ†æç³»çµ± - è§£ç´„èˆ‡å»åŒ–å‹•æ…‹å°ˆé …åˆ†æè¦–è¦ºåŒ–
# 
# ## ğŸ“‹ ç›®æ¨™
# - âœ… å¯¦ä½œè§£ç´„è¶¨å‹¢å°ˆé …åˆ†æ
# - âœ… å»ºç«‹å»åŒ–é€Ÿåº¦å°ˆé …åˆ†æ
# - âœ… é–‹ç™¼æ•ˆç‡æ’åå°ˆé …åˆ†æ
# - âœ… å‰µå»ºè¦–è¦ºåŒ–åˆ†æåœ–è¡¨
# - âœ… ç”Ÿæˆå¸‚å ´æ´å¯Ÿå ±å‘Š
# - âœ… æä¾›æ”¿ç­–å»ºè­°æ–¹æ¡ˆ
# 
# ## ğŸ¯ å…§å®¹å¤§ç¶±
# 1. ç’°å¢ƒè¨­å®šèˆ‡è³‡æ–™è¼‰å…¥
# 2. è§£ç´„è¶¨å‹¢å°ˆé …åˆ†æ
# 3. å»åŒ–é€Ÿåº¦å°ˆé …åˆ†æ
# 4. æ•ˆç‡æ’åå°ˆé …åˆ†æ
# 5. é¢¨éšªé è­¦è¦–è¦ºåŒ–
# 6. ç†±é»å€åŸŸåˆ†æè¦–è¦ºåŒ–
# 7. ä¸‰å±¤ç´šå°æ¯”åˆ†æ
# 8. å¸‚å ´æ´å¯Ÿåˆ†æ
# 9. æ”¿ç­–å»ºè­°ç”Ÿæˆ
# 10. äº’å‹•å¼DashboardåŸå‹
# 11. åˆ†æå ±å‘Šç”Ÿæˆ
# 12. çµæœè¼¸å‡ºèˆ‡ç¸½çµ
# 
# ## ğŸ“Š å°ˆé …åˆ†ææ¶æ§‹
# - ğŸ”´ **è§£ç´„å°ˆé …**: è§£ç´„ç‡è¶¨å‹¢ã€é¢¨éšªè©•ä¼°ã€ç©ºé–“åˆ†å¸ƒ
# - ğŸš€ **å»åŒ–å°ˆé …**: å»åŒ–é€Ÿåº¦ã€åŠ é€Ÿåº¦ã€æ•ˆç‡è©•ç´š
# - ğŸ† **æ•ˆç‡å°ˆé …**: æ’ååˆ†æã€è¡¨ç¾åˆ†ç´šã€å°æ¯”è©•ä¼°
# - ğŸ“ˆ **è¶¨å‹¢å°ˆé …**: æ™‚é–“åºåˆ—ã€å­£ç¯€æ€§ã€é æ¸¬æ¨¡å‹
# - ğŸ—ºï¸ **ç©ºé–“å°ˆé …**: ç†±åŠ›åœ–ã€å€åŸŸèšé›†ã€é¢¨éšªåœ°åœ–

# %% [markdown]
# ## 1. ç’°å¢ƒè¨­å®šèˆ‡è³‡æ–™è¼‰å…¥

# %%
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.figure_factory as ff
from datetime import datetime, timedelta
import re
import warnings
from collections import Counter, defaultdict
import math
from scipy import stats
import json
import glob
import os
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
warnings.filterwarnings('ignore')

# è¨­å®šé¡¯ç¤ºé¸é …
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', 100)
pd.set_option('display.width', None)
pd.set_option('display.max_colwidth', 80)

# è¨­å®šä¸­æ–‡å­—å‹
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'Arial Unicode MS', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False

# è¨­å®šåœ–è¡¨æ¨£å¼
sns.set_style("whitegrid")
plt.style.use('seaborn-v0_8')

# è¨­å®šplotlyä¸­æ–‡å­—å‹
import plotly.io as pio
pio.kaleido.scope.mathjax = None

print("âœ… ç’°å¢ƒè¨­å®šå®Œæˆ")
print(f"ğŸ“… åˆ†ææ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

# %%
# è¼‰å…¥ä¸‰å±¤ç´šå®Œæ•´å ±å‘Šè³‡æ–™
print("ğŸ”„ è¼‰å…¥ä¸‰å±¤ç´šå®Œæ•´å ±å‘Šè³‡æ–™...")

try:
    # è¼‰å…¥æœ€æ–°çš„ä¸‰å±¤ç´šå ±å‘Š
    def load_latest_report(file_pattern):
        files = glob.glob(f'../data/processed/{file_pattern}')
        if files:
            latest_file = max(files, key=os.path.getctime)
            return pd.read_csv(latest_file, encoding='utf-8'), os.path.basename(latest_file)
        return None, None
    
    # è¼‰å…¥ç¤¾å€ç´šå ±å‘Š
    community_report, community_file = load_latest_report('community_level_comprehensive_report_*.csv')
    if community_report is None:
        community_report = pd.read_csv('../data/processed/community_level_comprehensive_report.csv', encoding='utf-8')
        community_file = 'community_level_comprehensive_report.csv'
    
    # è¼‰å…¥è¡Œæ”¿å€ç´šå ±å‘Š
    district_report, district_file = load_latest_report('district_level_comprehensive_report_*.csv')
    if district_report is None:
        print("âŒ æ‰¾ä¸åˆ°è¡Œæ”¿å€ç´šå ±å‘Šï¼Œè«‹å…ˆåŸ·è¡Œ Notebook 9")
        raise FileNotFoundError("è¡Œæ”¿å€ç´šå ±å‘Šæœªæ‰¾åˆ°")
    
    # è¼‰å…¥ç¸£å¸‚ç´šå ±å‘Š
    city_report, city_file = load_latest_report('city_level_comprehensive_report_*.csv')
    if city_report is None:
        print("âŒ æ‰¾ä¸åˆ°ç¸£å¸‚ç´šå ±å‘Šï¼Œè«‹å…ˆåŸ·è¡Œ Notebook 9")
        raise FileNotFoundError("ç¸£å¸‚ç´šå ±å‘Šæœªæ‰¾åˆ°")
    
    print(f"âœ… è³‡æ–™è¼‰å…¥å®Œæˆ:")
    print(f"   ç¤¾å€ç´šå ±å‘Š: {community_file} ({len(community_report):,} ç­†)")
    print(f"   è¡Œæ”¿å€ç´šå ±å‘Š: {district_file} ({len(district_report):,} ç­†)")
    print(f"   ç¸£å¸‚ç´šå ±å‘Š: {city_file} ({len(city_report):,} ç­†)")
    
    # è¼‰å…¥è¼”åŠ©åˆ†æè³‡æ–™
    try:
        # è¼‰å…¥è¶¨å‹¢åˆ†æçµæœ
        trend_files = glob.glob('../data/processed/cross_level_trend_analysis_*.json')
        if trend_files:
            latest_trend_file = max(trend_files, key=os.path.getctime)
            with open(latest_trend_file, 'r', encoding='utf-8') as f:
                trend_analysis = json.load(f)
            print(f"âœ… è¶¨å‹¢åˆ†æè³‡æ–™è¼‰å…¥: {os.path.basename(latest_trend_file)}")
        else:
            trend_analysis = {}
        
        # è¼‰å…¥ç†±é»åˆ†æçµæœ
        hotspot_files = glob.glob('../data/processed/hotspot_analysis_results_*.json')
        if hotspot_files:
            latest_hotspot_file = max(hotspot_files, key=os.path.getctime)
            with open(latest_hotspot_file, 'r', encoding='utf-8') as f:
                hotspot_analysis = json.load(f)
            print(f"âœ… ç†±é»åˆ†æè³‡æ–™è¼‰å…¥: {os.path.basename(latest_hotspot_file)}")
        else:
            hotspot_analysis = {}
    except:
        trend_analysis = {}
        hotspot_analysis = {}
        print("âš ï¸ éƒ¨åˆ†è¼”åŠ©åˆ†æè³‡æ–™è¼‰å…¥å¤±æ•—ï¼Œä½¿ç”¨ç©ºç™½è³‡æ–™")

except Exception as e:
    print(f"âŒ è³‡æ–™è¼‰å…¥å¤±æ•—: {e}")
    raise

# %%
# è³‡æ–™é è™•ç†èˆ‡é©—è­‰
print(f"\nğŸ“Š è³‡æ–™é è™•ç†èˆ‡é©—è­‰:")

# é©—è­‰é—œéµæ¬„ä½å­˜åœ¨æ€§
required_community_cols = ['å‚™æŸ¥ç·¨è™Ÿ', 'ç¸£å¸‚', 'è¡Œæ”¿å€', 'å¹´å­£', 'æ·¨å»åŒ–ç‡(%)', 'ç´¯ç©è§£ç´„ç‡(%)']
required_district_cols = ['ç¸£å¸‚', 'è¡Œæ”¿å€', 'å¹´å­£', 'æ•´é«”æ·¨å»åŒ–ç‡(%)', 'å€åŸŸè§£ç´„ç‡(%)']
required_city_cols = ['ç¸£å¸‚', 'å¹´å­£', 'ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)', 'ç¸£å¸‚è§£ç´„ç‡(%)']

missing_community = [col for col in required_community_cols if col not in community_report.columns]
missing_district = [col for col in required_district_cols if col not in district_report.columns]
missing_city = [col for col in required_city_cols if col not in city_report.columns]

if missing_community:
    print(f"âš ï¸ ç¤¾å€ç´šå ±å‘Šç¼ºå¤±æ¬„ä½: {missing_community}")
if missing_district:
    print(f"âš ï¸ è¡Œæ”¿å€ç´šå ±å‘Šç¼ºå¤±æ¬„ä½: {missing_district}")
if missing_city:
    print(f"âš ï¸ ç¸£å¸‚ç´šå ±å‘Šç¼ºå¤±æ¬„ä½: {missing_city}")

if not (missing_community or missing_district or missing_city):
    print("âœ… æ‰€æœ‰å¿…è¦æ¬„ä½é©—è­‰é€šé")

# è³‡æ–™æ¸…ç†
def clean_numeric_columns(df, columns):
    """æ¸…ç†æ•¸å€¼æ¬„ä½"""
    for col in columns:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
            df[col] = df[col].fillna(0)
    return df

# æ¸…ç†æ•¸å€¼æ¬„ä½
numeric_cols_community = ['æ·¨å»åŒ–ç‡(%)', 'ç´¯ç©è§£ç´„ç‡(%)', 'å­£åº¦å»åŒ–é€Ÿåº¦(æˆ¶/å­£)', 'å¹³å‡äº¤æ˜“å–®åƒ¹(è¬/åª)']
numeric_cols_district = ['æ•´é«”æ·¨å»åŒ–ç‡(%)', 'å€åŸŸè§£ç´„ç‡(%)', 'å€åŸŸå¹³å‡å»åŒ–é€Ÿåº¦(æˆ¶/å­£)', 'é•·æœŸæ»¯éŠ·å½±éŸ¿åº¦(%)']
numeric_cols_city = ['ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)', 'ç¸£å¸‚è§£ç´„ç‡(%)', 'ç¸£å¸‚å¹³å‡å»åŒ–é€Ÿåº¦(æˆ¶/å­£)', 'é•·æœŸæ»¯éŠ·å»ºæ¡ˆå æ¯”(%)']

community_report = clean_numeric_columns(community_report, numeric_cols_community)
district_report = clean_numeric_columns(district_report, numeric_cols_district)
city_report = clean_numeric_columns(city_report, numeric_cols_city)

print(f"è³‡æ–™æ¸…ç†å®Œæˆ")

# %% [markdown]
# ## 2. è§£ç´„è¶¨å‹¢å°ˆé …åˆ†æ

# %%
# è§£ç´„è¶¨å‹¢å°ˆé …åˆ†æ
print("ğŸ”´ è§£ç´„è¶¨å‹¢å°ˆé …åˆ†æ")
print("=" * 50)

def comprehensive_cancellation_analysis():
    """
    ç¶œåˆè§£ç´„è¶¨å‹¢åˆ†æ
    
    Returns:
        dict: è§£ç´„åˆ†æçµæœ
    """
    
    cancellation_analysis = {
        'temporal_trends': {},
        'spatial_patterns': {},
        'risk_assessment': {},
        'market_impact': {},
        'insights': []
    }
    
    try:
        print("ğŸ”„ åˆ†æè§£ç´„æ™‚é–“è¶¨å‹¢...")
        
        # 1. æ™‚é–“è¶¨å‹¢åˆ†æ
        seasons = sorted(community_report['å¹´å­£'].unique())
        temporal_data = []
        
        for season in seasons:
            season_data = community_report[community_report['å¹´å­£'] == season]
            
            # è¨ˆç®—è©²å­£è§£ç´„æŒ‡æ¨™
            total_projects = len(season_data)
            high_cancellation_projects = len(season_data[season_data['ç´¯ç©è§£ç´„ç‡(%)'] > 5])
            avg_cancellation_rate = season_data['ç´¯ç©è§£ç´„ç‡(%)'].mean()
            max_cancellation_rate = season_data['ç´¯ç©è§£ç´„ç‡(%)'].max()
            
            # è§£ç´„é¢¨éšªé …ç›®çµ±è¨ˆ
            if 'è§£ç´„è­¦ç¤º' in season_data.columns:
                risk_distribution = season_data['è§£ç´„è­¦ç¤º'].value_counts()
                high_risk_count = sum([count for risk, count in risk_distribution.items() if 'ğŸ”´' in str(risk)])
            else:
                high_risk_count = high_cancellation_projects
            
            temporal_data.append({
                'season': season,
                'total_projects': total_projects,
                'high_cancellation_projects': high_cancellation_projects,
                'high_cancellation_ratio': high_cancellation_projects / total_projects * 100 if total_projects > 0 else 0,
                'avg_cancellation_rate': avg_cancellation_rate,
                'max_cancellation_rate': max_cancellation_rate,
                'high_risk_count': high_risk_count,
                'high_risk_ratio': high_risk_count / total_projects * 100 if total_projects > 0 else 0
            })
        
        cancellation_analysis['temporal_trends'] = temporal_data
        
        print("ğŸ”„ åˆ†æè§£ç´„ç©ºé–“åˆ†å¸ƒ...")
        
        # 2. ç©ºé–“åˆ†å¸ƒåˆ†æ
        spatial_data = {}
        
        # ç¸£å¸‚å±¤ç´šåˆ†æ
        county_cancellation = community_report.groupby('ç¸£å¸‚').agg({
            'ç´¯ç©è§£ç´„ç‡(%)': ['mean', 'max', 'count'],
            'å‚™æŸ¥ç·¨è™Ÿ': 'count'
        }).round(2)
        
        # æ‰å¹³åŒ–æ¬„ä½åç¨±
        county_cancellation.columns = ['avg_cancellation', 'max_cancellation', 'projects_with_cancellation', 'total_projects']
        county_cancellation['high_cancellation_ratio'] = (
            community_report[community_report['ç´¯ç©è§£ç´„ç‡(%)'] > 5]
            .groupby('ç¸£å¸‚')['å‚™æŸ¥ç·¨è™Ÿ'].count() / 
            community_report.groupby('ç¸£å¸‚')['å‚™æŸ¥ç·¨è™Ÿ'].count() * 100
        ).fillna(0)
        
        spatial_data['county_analysis'] = county_cancellation.to_dict('index')
        
        # è¡Œæ”¿å€å±¤ç´šåˆ†æï¼ˆé«˜é¢¨éšªå€åŸŸï¼‰
        high_risk_districts = district_report[district_report['å€åŸŸè§£ç´„ç‡(%)'] > 3]
        if not high_risk_districts.empty:
            spatial_data['high_risk_districts'] = high_risk_districts[
                ['ç¸£å¸‚', 'è¡Œæ”¿å€', 'å¹´å­£', 'å€åŸŸè§£ç´„ç‡(%)', 'å€åŸŸè§£ç´„é¢¨éšªç­‰ç´š']
            ].to_dict('records')
        
        cancellation_analysis['spatial_patterns'] = spatial_data
        
        print("ğŸ”„ é€²è¡Œè§£ç´„é¢¨éšªè©•ä¼°...")
        
        # 3. é¢¨éšªè©•ä¼°
        risk_metrics = {
            'overall_risk_level': 'LOW',
            'market_average': community_report['ç´¯ç©è§£ç´„ç‡(%)'].mean(),
            'risk_concentration': {},
            'trend_direction': 'STABLE'
        }
        
        # æ•´é«”é¢¨éšªç­‰ç´šè©•ä¼°
        high_risk_ratio = len(community_report[community_report['ç´¯ç©è§£ç´„ç‡(%)'] > 5]) / len(community_report) * 100
        
        if high_risk_ratio > 15:
            risk_metrics['overall_risk_level'] = 'HIGH'
        elif high_risk_ratio > 8:
            risk_metrics['overall_risk_level'] = 'MEDIUM'
        
        # é¢¨éšªé›†ä¸­åº¦åˆ†æ
        risk_by_county = community_report[community_report['ç´¯ç©è§£ç´„ç‡(%)'] > 5]['ç¸£å¸‚'].value_counts()
        if not risk_by_county.empty:
            risk_metrics['risk_concentration'] = risk_by_county.head(5).to_dict()
        
        # è¶¨å‹¢æ–¹å‘åˆ¤æ–·
        if len(temporal_data) >= 2:
            recent_ratio = temporal_data[-1]['high_cancellation_ratio']
            early_ratio = temporal_data[0]['high_cancellation_ratio']
            
            if recent_ratio > early_ratio * 1.2:
                risk_metrics['trend_direction'] = 'INCREASING'
            elif recent_ratio < early_ratio * 0.8:
                risk_metrics['trend_direction'] = 'DECREASING'
        
        cancellation_analysis['risk_assessment'] = risk_metrics
        
        print("ğŸ”„ è©•ä¼°å¸‚å ´å½±éŸ¿...")
        
        # 4. å¸‚å ´å½±éŸ¿åˆ†æ
        market_impact = {
            'affected_projects_count': len(community_report[community_report['ç´¯ç©è§£ç´„ç‡(%)'] > 0]),
            'total_cancellation_cases': community_report['ç´¯ç©è§£ç´„ç­†æ•¸'].sum(),
            'economic_impact_estimate': 'MEDIUM',
            'correlation_with_absorption': 0
        }
        
        # è¨ˆç®—è§£ç´„ç‡èˆ‡å»åŒ–ç‡çš„ç›¸é—œæ€§
        if len(community_report) > 10:
            correlation = community_report['ç´¯ç©è§£ç´„ç‡(%)'].corr(community_report['æ·¨å»åŒ–ç‡(%)'])
            market_impact['correlation_with_absorption'] = correlation
        
        # ç¶“æ¿Ÿå½±éŸ¿è©•ä¼°
        avg_cancellation = community_report['ç´¯ç©è§£ç´„ç‡(%)'].mean()
        if avg_cancellation > 3:
            market_impact['economic_impact_estimate'] = 'HIGH'
        elif avg_cancellation < 1:
            market_impact['economic_impact_estimate'] = 'LOW'
        
        cancellation_analysis['market_impact'] = market_impact
        
        # 5. ç”Ÿæˆæ´å¯Ÿ
        insights = []
        
        if risk_metrics['overall_risk_level'] == 'HIGH':
            insights.append("å¸‚å ´è§£ç´„é¢¨éšªåé«˜ï¼Œéœ€è¦å¯†åˆ‡ç›£æ§è§£ç´„è¶¨å‹¢")
        
        if risk_metrics['trend_direction'] == 'INCREASING':
            insights.append("è§£ç´„ç‡å‘ˆç¾ä¸Šå‡è¶¨å‹¢ï¼Œå»ºè­°åŠ å¼·é¢¨éšªç®¡æ§")
        
        if len(risk_metrics['risk_concentration']) > 3:
            insights.append("è§£ç´„é¢¨éšªå­˜åœ¨åœ°å€é›†ä¸­ç¾è±¡ï¼Œéœ€é—œæ³¨ç‰¹å®šå€åŸŸ")
        
        if market_impact['correlation_with_absorption'] < -0.3:
            insights.append("è§£ç´„ç‡èˆ‡å»åŒ–ç‡å‘ˆç¾è² ç›¸é—œï¼Œè§£ç´„å¯èƒ½å½±éŸ¿éŠ·å”®è¡¨ç¾")
        
        if not insights:
            insights.append("æ•´é«”è§£ç´„é¢¨éšªæ§åˆ¶è‰¯å¥½ï¼Œå¸‚å ´ç‹€æ³ç©©å®š")
        
        cancellation_analysis['insights'] = insights
        
        print("âœ… è§£ç´„è¶¨å‹¢å°ˆé …åˆ†æå®Œæˆ")
        
        return cancellation_analysis
    
    except Exception as e:
        print(f"âŒ è§£ç´„åˆ†æéŒ¯èª¤: {e}")
        cancellation_analysis['error'] = str(e)
        return cancellation_analysis

# %%
# åŸ·è¡Œè§£ç´„è¶¨å‹¢åˆ†æ
cancellation_analysis_result = comprehensive_cancellation_analysis()

# é¡¯ç¤ºåˆ†æçµæœ
print(f"\nğŸ”´ è§£ç´„è¶¨å‹¢åˆ†æçµæœ:")

if 'temporal_trends' in cancellation_analysis_result:
    temporal_data = cancellation_analysis_result['temporal_trends']
    if temporal_data:
        print(f"æ™‚é–“è¶¨å‹¢åˆ†æ ({len(temporal_data)} å€‹å¹´å­£):")
        latest_data = temporal_data[-1]
        print(f"   æœ€æ–°å­£åº¦: {latest_data['season']}")
        print(f"   é«˜è§£ç´„ç‡å»ºæ¡ˆæ¯”ä¾‹: {latest_data['high_cancellation_ratio']:.1f}%")
        print(f"   å¹³å‡è§£ç´„ç‡: {latest_data['avg_cancellation_rate']:.2f}%")
        print(f"   é«˜é¢¨éšªå»ºæ¡ˆæ¯”ä¾‹: {latest_data['high_risk_ratio']:.1f}%")

if 'risk_assessment' in cancellation_analysis_result:
    risk_data = cancellation_analysis_result['risk_assessment']
    print(f"\né¢¨éšªè©•ä¼°:")
    print(f"   æ•´é«”é¢¨éšªç­‰ç´š: {risk_data.get('overall_risk_level', 'N/A')}")
    print(f"   å¸‚å ´å¹³å‡è§£ç´„ç‡: {risk_data.get('market_average', 0):.2f}%")
    print(f"   è¶¨å‹¢æ–¹å‘: {risk_data.get('trend_direction', 'N/A')}")

if 'insights' in cancellation_analysis_result:
    insights = cancellation_analysis_result['insights']
    print(f"\næ´å¯Ÿå»ºè­°:")
    for i, insight in enumerate(insights, 1):
        print(f"   {i}. {insight}")

# %% [markdown]
# ## 3. å»åŒ–é€Ÿåº¦å°ˆé …åˆ†æ

# %%
# å»åŒ–é€Ÿåº¦å°ˆé …åˆ†æ
print("ğŸš€ å»åŒ–é€Ÿåº¦å°ˆé …åˆ†æ")
print("=" * 50)

def comprehensive_absorption_analysis():
    """
    ç¶œåˆå»åŒ–é€Ÿåº¦å°ˆé …åˆ†æ
    
    Returns:
        dict: å»åŒ–åˆ†æçµæœ
    """
    
    absorption_analysis = {
        'speed_distribution': {},
        'efficiency_ranking': {},
        'temporal_dynamics': {},
        'performance_clustering': {},
        'predictive_insights': {}
    }
    
    try:
        print("ğŸ”„ åˆ†æå»åŒ–é€Ÿåº¦åˆ†å¸ƒ...")
        
        # 1. å»åŒ–é€Ÿåº¦åˆ†å¸ƒåˆ†æ
        speed_stats = {}
        
        # ç¤¾å€ç´šå»åŒ–é€Ÿåº¦çµ±è¨ˆ
        if 'å­£åº¦å»åŒ–é€Ÿåº¦(æˆ¶/å­£)' in community_report.columns:
            valid_speeds = community_report[community_report['å­£åº¦å»åŒ–é€Ÿåº¦(æˆ¶/å­£)'] > 0]['å­£åº¦å»åŒ–é€Ÿåº¦(æˆ¶/å­£)']
            
            speed_stats['community_level'] = {
                'mean': valid_speeds.mean(),
                'median': valid_speeds.median(),
                'std': valid_speeds.std(),
                'q25': valid_speeds.quantile(0.25),
                'q75': valid_speeds.quantile(0.75),
                'max': valid_speeds.max(),
                'samples': len(valid_speeds)
            }
            
            # é€Ÿåº¦åˆ†ç´šçµ±è¨ˆ
            speed_categories = {
                'high_speed': len(valid_speeds[valid_speeds >= 3]),  # é«˜é€Ÿå»åŒ–
                'normal_speed': len(valid_speeds[(valid_speeds >= 1) & (valid_speeds < 3)]),  # æ­£å¸¸å»åŒ–
                'slow_speed': len(valid_speeds[(valid_speeds > 0) & (valid_speeds < 1)])  # ç·©æ…¢å»åŒ–
            }
            
            total_with_speed = sum(speed_categories.values())
            speed_stats['speed_distribution'] = {
                category: {'count': count, 'percentage': count/total_with_speed*100}
                for category, count in speed_categories.items()
            } if total_with_speed > 0 else {}
        
        # è¡Œæ”¿å€ç´šå»åŒ–é€Ÿåº¦çµ±è¨ˆ
        if 'å€åŸŸå¹³å‡å»åŒ–é€Ÿåº¦(æˆ¶/å­£)' in district_report.columns:
            district_speeds = district_report[district_report['å€åŸŸå¹³å‡å»åŒ–é€Ÿåº¦(æˆ¶/å­£)'] > 0]['å€åŸŸå¹³å‡å»åŒ–é€Ÿåº¦(æˆ¶/å­£)']
            
            speed_stats['district_level'] = {
                'mean': district_speeds.mean(),
                'median': district_speeds.median(),
                'std': district_speeds.std(),
                'samples': len(district_speeds)
            }
        
        absorption_analysis['speed_distribution'] = speed_stats
        
        print("ğŸ”„ å»ºç«‹æ•ˆç‡æ’ååˆ†æ...")
        
        # 2. æ•ˆç‡æ’ååˆ†æ
        efficiency_data = {}
        
        # ç¤¾å€ç´šæ•ˆç‡è©•ç´šåˆ†å¸ƒ
        if 'å»åŒ–æ•ˆç‡è©•ç´š' in community_report.columns:
            efficiency_dist = community_report['å»åŒ–æ•ˆç‡è©•ç´š'].value_counts()
            efficiency_data['community_efficiency'] = efficiency_dist.to_dict()
        
        # ç¸£å¸‚ç´šè¡¨ç¾åˆ†ç´šåˆ†å¸ƒ
        if 'ç¸£å¸‚å»åŒ–è¡¨ç¾åˆ†ç´š' in city_report.columns:
            performance_dist = city_report['ç¸£å¸‚å»åŒ–è¡¨ç¾åˆ†ç´š'].value_counts()
            efficiency_data['city_performance'] = performance_dist.to_dict()
        
        # é ‚ç´šè¡¨ç¾ç¸£å¸‚è­˜åˆ¥
        if 'ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)' in city_report.columns:
            top_cities = city_report.nlargest(5, 'ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)')[
                ['ç¸£å¸‚', 'ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)', 'ç¸£å¸‚å¹³å‡å»åŒ–é€Ÿåº¦(æˆ¶/å­£)']
            ].to_dict('records')
            efficiency_data['top_performers'] = top_cities
        
        absorption_analysis['efficiency_ranking'] = efficiency_data
        
        print("ğŸ”„ åˆ†ææ™‚é–“å‹•æ…‹...")
        
        # 3. æ™‚é–“å‹•æ…‹åˆ†æ
        temporal_analysis = {}
        
        seasons = sorted(community_report['å¹´å­£'].unique())
        if len(seasons) > 1:
            seasonal_performance = []
            
            for season in seasons:
                season_data = community_report[community_report['å¹´å­£'] == season]
                
                # è¨ˆç®—è©²å­£åº¦å»åŒ–æŒ‡æ¨™
                avg_absorption = season_data['æ·¨å»åŒ–ç‡(%)'].mean()
                avg_speed = season_data['å­£åº¦å»åŒ–é€Ÿåº¦(æˆ¶/å­£)'].mean() if 'å­£åº¦å»åŒ–é€Ÿåº¦(æˆ¶/å­£)' in season_data.columns else 0
                completion_rate = len(season_data[season_data['æ·¨å»åŒ–ç‡(%)'] >= 100]) / len(season_data) * 100
                
                seasonal_performance.append({
                    'season': season,
                    'avg_absorption_rate': avg_absorption,
                    'avg_speed': avg_speed,
                    'completion_rate': completion_rate,
                    'total_projects': len(season_data)
                })
            
            temporal_analysis['seasonal_trends'] = seasonal_performance
            
            # è¨ˆç®—è¶¨å‹¢è®ŠåŒ–
            if len(seasonal_performance) >= 2:
                first_season = seasonal_performance[0]
                last_season = seasonal_performance[-1]
                
                absorption_change = last_season['avg_absorption_rate'] - first_season['avg_absorption_rate']
                speed_change = last_season['avg_speed'] - first_season['avg_speed']
                completion_change = last_season['completion_rate'] - first_season['completion_rate']
                
                temporal_analysis['trend_changes'] = {
                    'absorption_rate_change': absorption_change,
                    'speed_change': speed_change,
                    'completion_rate_change': completion_change,
                    'period': f"{first_season['season']} â†’ {last_season['season']}"
                }
        
        absorption_analysis['temporal_dynamics'] = temporal_analysis
        
        print("ğŸ”„ åŸ·è¡Œè¡¨ç¾ç¾¤é›†åˆ†æ...")
        
        # 4. è¡¨ç¾ç¾¤é›†åˆ†æ
        clustering_data = {}
        
        # æº–å‚™èšé¡åˆ†ææ•¸æ“š
        if len(community_report) > 10:
            features = []
            feature_names = []
            
            # é¸æ“‡é—œéµç‰¹å¾µ
            if 'æ·¨å»åŒ–ç‡(%)' in community_report.columns:
                features.append(community_report['æ·¨å»åŒ–ç‡(%)'].fillna(0))
                feature_names.append('å»åŒ–ç‡')
            
            if 'å­£åº¦å»åŒ–é€Ÿåº¦(æˆ¶/å­£)' in community_report.columns:
                features.append(community_report['å­£åº¦å»åŒ–é€Ÿåº¦(æˆ¶/å­£)'].fillna(0))
                feature_names.append('å»åŒ–é€Ÿåº¦')
            
            if 'ç´¯ç©è§£ç´„ç‡(%)' in community_report.columns:
                features.append(community_report['ç´¯ç©è§£ç´„ç‡(%)'].fillna(0))
                feature_names.append('è§£ç´„ç‡')
            
            if len(features) >= 2:
                # åŸ·è¡ŒK-meansèšé¡
                feature_matrix = np.column_stack(features)
                
                # æ¨™æº–åŒ–ç‰¹å¾µ
                scaler = StandardScaler()
                feature_matrix_scaled = scaler.fit_transform(feature_matrix)
                
                # K-meansèšé¡ (3å€‹ç¾¤é›†)
                kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
                clusters = kmeans.fit_predict(feature_matrix_scaled)
                
                # åˆ†æå„ç¾¤é›†ç‰¹å¾µ
                cluster_analysis = {}
                for i in range(3):
                    cluster_mask = clusters == i
                    cluster_data = community_report[cluster_mask]
                    
                    cluster_analysis[f'cluster_{i}'] = {
                        'size': len(cluster_data),
                        'avg_absorption': cluster_data['æ·¨å»åŒ–ç‡(%)'].mean(),
                        'avg_speed': cluster_data['å­£åº¦å»åŒ–é€Ÿåº¦(æˆ¶/å­£)'].mean() if 'å­£åº¦å»åŒ–é€Ÿåº¦(æˆ¶/å­£)' in cluster_data.columns else 0,
                        'avg_cancellation': cluster_data['ç´¯ç©è§£ç´„ç‡(%)'].mean(),
                        'characteristics': self._classify_cluster_characteristics(
                            cluster_data['æ·¨å»åŒ–ç‡(%)'].mean(),
                            cluster_data['å­£åº¦å»åŒ–é€Ÿåº¦(æˆ¶/å­£)'].mean() if 'å­£åº¦å»åŒ–é€Ÿåº¦(æˆ¶/å­£)' in cluster_data.columns else 0,
                            cluster_data['ç´¯ç©è§£ç´„ç‡(%)'].mean()
                        )
                    }
                
                clustering_data['cluster_analysis'] = cluster_analysis
                clustering_data['feature_names'] = feature_names
        
        absorption_analysis['performance_clustering'] = clustering_data
        
        print("ğŸ”„ ç”Ÿæˆé æ¸¬æ´å¯Ÿ...")
        
        # 5. é æ¸¬æ´å¯Ÿ
        predictive_insights = {}
        
        # åŸºæ–¼æ­·å²è¶¨å‹¢çš„é æ¸¬
        if 'trend_changes' in temporal_analysis:
            trend_data = temporal_analysis['trend_changes']
            
            # é æ¸¬ä¸‹å­£åº¦è¡¨ç¾
            if trend_data['absorption_rate_change'] > 5:
                predictive_insights['next_season_outlook'] = 'POSITIVE'
                predictive_insights['outlook_reason'] = 'å»åŒ–ç‡å‘ˆç¾ä¸Šå‡è¶¨å‹¢'
            elif trend_data['absorption_rate_change'] < -5:
                predictive_insights['next_season_outlook'] = 'NEGATIVE'
                predictive_insights['outlook_reason'] = 'å»åŒ–ç‡å‘ˆç¾ä¸‹é™è¶¨å‹¢'
            else:
                predictive_insights['next_season_outlook'] = 'STABLE'
                predictive_insights['outlook_reason'] = 'å»åŒ–ç‡ä¿æŒç©©å®š'
        
        # å¸‚å ´å¥åº·åº¦è©•ä¼°
        overall_health_score = 0
        
        if 'community_level' in speed_stats:
            avg_speed = speed_stats['community_level']['mean']
            if avg_speed >= 2.5:
                overall_health_score += 3
            elif avg_speed >= 1.5:
                overall_health_score += 2
            elif avg_speed >= 1:
                overall_health_score += 1
        
        if len(community_report) > 0:
            avg_absorption = community_report['æ·¨å»åŒ–ç‡(%)'].mean()
            if avg_absorption >= 60:
                overall_health_score += 3
            elif avg_absorption >= 40:
                overall_health_score += 2
            elif avg_absorption >= 20:
                overall_health_score += 1
        
        # å¥åº·åº¦åˆ†ç´š
        if overall_health_score >= 5:
            predictive_insights['market_health'] = 'EXCELLENT'
        elif overall_health_score >= 3:
            predictive_insights['market_health'] = 'GOOD'
        elif overall_health_score >= 1:
            predictive_insights['market_health'] = 'FAIR'
        else:
            predictive_insights['market_health'] = 'POOR'
        
        absorption_analysis['predictive_insights'] = predictive_insights
        
        print("âœ… å»åŒ–é€Ÿåº¦å°ˆé …åˆ†æå®Œæˆ")
        
        return absorption_analysis
    
    except Exception as e:
        print(f"âŒ å»åŒ–åˆ†æéŒ¯èª¤: {e}")
        absorption_analysis['error'] = str(e)
        return absorption_analysis

def _classify_cluster_characteristics(self, avg_absorption, avg_speed, avg_cancellation):
    """åˆ†é¡ç¾¤é›†ç‰¹å¾µ"""
    if avg_absorption >= 60 and avg_speed >= 2:
        return "é«˜æ•ˆè¡¨ç¾ç¾¤"
    elif avg_absorption >= 40 and avg_speed >= 1:
        return "ç©©å®šè¡¨ç¾ç¾¤"
    elif avg_cancellation > 3:
        return "é¢¨éšªé—œæ³¨ç¾¤"
    else:
        return "ä¸€èˆ¬è¡¨ç¾ç¾¤"

# å°‡å‡½æ•¸æ·»åŠ åˆ°å…¨åŸŸå‘½åç©ºé–“
def classify_cluster_characteristics(avg_absorption, avg_speed, avg_cancellation):
    """åˆ†é¡ç¾¤é›†ç‰¹å¾µ"""
    if avg_absorption >= 60 and avg_speed >= 2:
        return "é«˜æ•ˆè¡¨ç¾ç¾¤"
    elif avg_absorption >= 40 and avg_speed >= 1:
        return "ç©©å®šè¡¨ç¾ç¾¤"
    elif avg_cancellation > 3:
        return "é¢¨éšªé—œæ³¨ç¾¤"
    else:
        return "ä¸€èˆ¬è¡¨ç¾ç¾¤"

# %%
# åŸ·è¡Œå»åŒ–é€Ÿåº¦åˆ†æ
absorption_analysis_result = comprehensive_absorption_analysis()

# é¡¯ç¤ºåˆ†æçµæœ
print(f"\nğŸš€ å»åŒ–é€Ÿåº¦åˆ†æçµæœ:")

if 'speed_distribution' in absorption_analysis_result:
    speed_data = absorption_analysis_result['speed_distribution']
    
    if 'community_level' in speed_data:
        community_stats = speed_data['community_level']
        print(f"ç¤¾å€ç´šå»åŒ–é€Ÿåº¦çµ±è¨ˆ:")
        print(f"   å¹³å‡é€Ÿåº¦: {community_stats['mean']:.2f} æˆ¶/å­£")
        print(f"   ä¸­ä½æ•¸é€Ÿåº¦: {community_stats['median']:.2f} æˆ¶/å­£")
        print(f"   æœ€é«˜é€Ÿåº¦: {community_stats['max']:.2f} æˆ¶/å­£")
        print(f"   æ¨£æœ¬æ•¸: {community_stats['samples']:,}")
    
    if 'speed_distribution' in speed_data:
        dist_data = speed_data['speed_distribution']
        print(f"\nå»åŒ–é€Ÿåº¦åˆ†ç´šåˆ†å¸ƒ:")
        for category, data in dist_data.items():
            print(f"   {category}: {data['count']} å€‹ ({data['percentage']:.1f}%)")

if 'efficiency_ranking' in absorption_analysis_result:
    efficiency_data = absorption_analysis_result['efficiency_ranking']
    
    if 'top_performers' in efficiency_data:
        top_cities = efficiency_data['top_performers']
        print(f"\né ‚ç´šè¡¨ç¾ç¸£å¸‚:")
        for i, city in enumerate(top_cities[:3], 1):
            print(f"   {i}. {city['ç¸£å¸‚']}: å»åŒ–ç‡{city['ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)']:.1f}%, é€Ÿåº¦{city['ç¸£å¸‚å¹³å‡å»åŒ–é€Ÿåº¦(æˆ¶/å­£)']:.2f}æˆ¶/å­£")

if 'temporal_dynamics' in absorption_analysis_result:
    temporal_data = absorption_analysis_result['temporal_dynamics']
    
    if 'trend_changes' in temporal_data:
        trend_changes = temporal_data['trend_changes']
        print(f"\nè¶¨å‹¢è®ŠåŒ–åˆ†æ ({trend_changes['period']}):")
        print(f"   å»åŒ–ç‡è®ŠåŒ–: {trend_changes['absorption_rate_change']:+.1f}%")
        print(f"   å»åŒ–é€Ÿåº¦è®ŠåŒ–: {trend_changes['speed_change']:+.2f} æˆ¶/å­£")
        print(f"   å®Œå”®ç‡è®ŠåŒ–: {trend_changes['completion_rate_change']:+.1f}%")

if 'predictive_insights' in absorption_analysis_result:
    predictive_data = absorption_analysis_result['predictive_insights']
    print(f"\né æ¸¬æ´å¯Ÿ:")
    print(f"   å¸‚å ´å¥åº·åº¦: {predictive_data.get('market_health', 'N/A')}")
    print(f"   ä¸‹å­£å±•æœ›: {predictive_data.get('next_season_outlook', 'N/A')}")
    if 'outlook_reason' in predictive_data:
        print(f"   é æ¸¬ç†ç”±: {predictive_data['outlook_reason']}")

# %% [markdown]
# ## 4. æ•ˆç‡æ’åå°ˆé …åˆ†æ

# %%
# æ•ˆç‡æ’åå°ˆé …åˆ†æ
print("ğŸ† æ•ˆç‡æ’åå°ˆé …åˆ†æ")
print("=" * 50)

def comprehensive_efficiency_ranking_analysis():
    """
    ç¶œåˆæ•ˆç‡æ’åå°ˆé …åˆ†æ
    
    Returns:
        dict: æ•ˆç‡æ’ååˆ†æçµæœ
    """
    
    efficiency_analysis = {
        'multi_level_ranking': {},
        'performance_benchmarking': {},
        'efficiency_factors': {},
        'competitive_analysis': {},
        'improvement_opportunities': {}
    }
    
    try:
        print("ğŸ”„ å»ºç«‹å¤šå±¤ç´šæ•ˆç‡æ’å...")
        
        # 1. å¤šå±¤ç´šæ•ˆç‡æ’å
        ranking_data = {}
        
        # ç¸£å¸‚ç´šæ•ˆç‡æ’å
        if len(city_report) > 0:
            city_efficiency = city_report.copy()
            
            # è¨ˆç®—ç¶œåˆæ•ˆç‡åˆ†æ•¸
            city_efficiency['efficiency_score'] = (
                city_efficiency['ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)'] * 0.4 +
                city_efficiency['ç¸£å¸‚å¹³å‡å»åŒ–é€Ÿåº¦(æˆ¶/å­£)'] * 20 * 0.3 +  # è½‰æ›ç‚ºç™¾åˆ†æ¯”å°ºåº¦
                (100 - city_efficiency['é•·æœŸæ»¯éŠ·å»ºæ¡ˆå æ¯”(%)']) * 0.2 +
                (100 - city_efficiency['ç¸£å¸‚è§£ç´„ç‡(%)'] * 10) * 0.1  # è§£ç´„ç‡å½±éŸ¿
            )
            
            # æ’å
            city_efficiency = city_efficiency.sort_values('efficiency_score', ascending=False)
            city_efficiency['ranking'] = range(1, len(city_efficiency) + 1)
            
            ranking_data['city_ranking'] = city_efficiency[
                ['ç¸£å¸‚', 'å¹´å­£', 'efficiency_score', 'ranking', 'ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)', 
                 'ç¸£å¸‚å¹³å‡å»åŒ–é€Ÿåº¦(æˆ¶/å­£)', 'ç¸£å¸‚å»åŒ–è¡¨ç¾åˆ†ç´š']
            ].head(10).to_dict('records')
        
        # è¡Œæ”¿å€ç´šæ•ˆç‡æ’å (æŒ‰ç¸£å¸‚åˆ†çµ„)
        if len(district_report) > 0:
            district_efficiency = district_report.copy()
            
            # è¨ˆç®—è¡Œæ”¿å€æ•ˆç‡åˆ†æ•¸
            district_efficiency['efficiency_score'] = (
                district_efficiency['æ•´é«”æ·¨å»åŒ–ç‡(%)'] * 0.4 +
                district_efficiency['å€åŸŸå¹³å‡å»åŒ–é€Ÿåº¦(æˆ¶/å­£)'] * 20 * 0.3 +
                (100 - district_efficiency['é•·æœŸæ»¯éŠ·å½±éŸ¿åº¦(%)']) * 0.2 +
                (100 - district_efficiency['å€åŸŸè§£ç´„ç‡(%)'] * 10) * 0.1
            )
            
            # æŒ‰ç¸£å¸‚åˆ†çµ„æ’å
            district_rankings = {}
            for county in district_efficiency['ç¸£å¸‚'].unique():
                county_data = district_efficiency[district_efficiency['ç¸£å¸‚'] == county]
                county_data = county_data.sort_values('efficiency_score', ascending=False)
                county_data['county_ranking'] = range(1, len(county_data) + 1)
                
                district_rankings[county] = county_data[
                    ['è¡Œæ”¿å€', 'å¹´å­£', 'efficiency_score', 'county_ranking', 'æ•´é«”æ·¨å»åŒ–ç‡(%)', 
                     'å€åŸŸå¹³å‡å»åŒ–é€Ÿåº¦(æˆ¶/å­£)']
                ].head(5).to_dict('records')
            
            ranking_data['district_ranking'] = district_rankings
        
        efficiency_analysis['multi_level_ranking'] = ranking_data
        
        print("ğŸ”„ åŸ·è¡Œæ•ˆç‡åŸºæº–åˆ†æ...")
        
        # 2. æ•ˆç‡åŸºæº–åˆ†æ
        benchmarking_data = {}
        
        # å»ºç«‹æ•ˆç‡åŸºæº–
        if len(community_report) > 0:
            # å»åŒ–ç‡åŸºæº–
            absorption_benchmark = {
                'excellent': community_report['æ·¨å»åŒ–ç‡(%)'].quantile(0.9),
                'good': community_report['æ·¨å»åŒ–ç‡(%)'].quantile(0.75),
                'average': community_report['æ·¨å»åŒ–ç‡(%)'].median(),
                'poor': community_report['æ·¨å»åŒ–ç‡(%)'].quantile(0.25)
            }
            
            # å»åŒ–é€Ÿåº¦åŸºæº–
            if 'å­£åº¦å»åŒ–é€Ÿåº¦(æˆ¶/å­£)' in community_report.columns:
                speed_data = community_report[community_report['å­£åº¦å»åŒ–é€Ÿåº¦(æˆ¶/å­£)'] > 0]['å­£åº¦å»åŒ–é€Ÿåº¦(æˆ¶/å­£)']
                speed_benchmark = {
                    'excellent': speed_data.quantile(0.9),
                    'good': speed_data.quantile(0.75),
                    'average': speed_data.median(),
                    'poor': speed_data.quantile(0.25)
                }
            else:
                speed_benchmark = {}
            
            benchmarking_data['benchmarks'] = {
                'absorption_rate': absorption_benchmark,
                'absorption_speed': speed_benchmark
            }
            
            # å„ç¸£å¸‚ç›¸å°è¡¨ç¾
            county_performance = {}
            for county in community_report['ç¸£å¸‚'].unique():
                county_data = community_report[community_report['ç¸£å¸‚'] == county]
                
                avg_absorption = county_data['æ·¨å»åŒ–ç‡(%)'].mean()
                avg_speed = county_data['å­£åº¦å»åŒ–é€Ÿåº¦(æˆ¶/å­£)'].mean() if 'å­£åº¦å»åŒ–é€Ÿåº¦(æˆ¶/å­£)' in county_data.columns else 0
                
                # è¨ˆç®—ç›¸å°åŸºæº–è¡¨ç¾
                absorption_percentile = (county_data['æ·¨å»åŒ–ç‡(%)'] >= absorption_benchmark['good']).mean() * 100
                
                county_performance[county] = {
                    'avg_absorption': avg_absorption,
                    'avg_speed': avg_speed,
                    'high_performance_ratio': absorption_percentile,
                    'sample_size': len(county_data)
                }
            
            benchmarking_data['county_performance'] = county_performance
        
        efficiency_analysis['performance_benchmarking'] = benchmarking_data
        
        print("ğŸ”„ åˆ†ææ•ˆç‡å½±éŸ¿å› å­...")
        
        # 3. æ•ˆç‡å½±éŸ¿å› å­åˆ†æ
        factors_analysis = {}
        
        # åƒ¹æ ¼èˆ‡æ•ˆç‡é—œä¿‚
        if 'å¹³å‡äº¤æ˜“å–®åƒ¹(è¬/åª)' in community_report.columns:
            price_efficiency_corr = community_report['å¹³å‡äº¤æ˜“å–®åƒ¹(è¬/åª)'].corr(community_report['æ·¨å»åŒ–ç‡(%)'])
            factors_analysis['price_efficiency_correlation'] = price_efficiency_corr
        
        # è§£ç´„ç‡èˆ‡æ•ˆç‡é—œä¿‚
        cancellation_efficiency_corr = community_report['ç´¯ç©è§£ç´„ç‡(%)'].corr(community_report['æ·¨å»åŒ–ç‡(%)'])
        factors_analysis['cancellation_efficiency_correlation'] = cancellation_efficiency_corr
        
        # éŠ·å”®éšæ®µå½±éŸ¿
        if 'éŠ·å”®éšæ®µ' in community_report.columns:
            stage_efficiency = community_report.groupby('éŠ·å”®éšæ®µ')['æ·¨å»åŒ–ç‡(%)'].agg(['mean', 'count'])
            factors_analysis['stage_impact'] = stage_efficiency.to_dict('index')
        
        # æˆ¶æ•¸è¦æ¨¡å½±éŸ¿
        if 'ç¸½æˆ¶æ•¸' in community_report.columns:
            # æŒ‰æˆ¶æ•¸è¦æ¨¡åˆ†çµ„
            community_report['project_size'] = pd.cut(
                community_report['ç¸½æˆ¶æ•¸'], 
                bins=[0, 50, 100, 200, float('inf')], 
                labels=['å°å‹(â‰¤50)', 'ä¸­å‹(51-100)', 'å¤§å‹(101-200)', 'è¶…å¤§å‹(>200)']
            )
            
            size_efficiency = community_report.groupby('project_size')['æ·¨å»åŒ–ç‡(%)'].agg(['mean', 'count'])
            factors_analysis['size_impact'] = size_efficiency.to_dict('index')
        
        efficiency_analysis['efficiency_factors'] = factors_analysis
        
        print("ğŸ”„ é€²è¡Œç«¶çˆ­åˆ†æ...")
        
        # 4. ç«¶çˆ­åˆ†æ
        competitive_data = {}
        
        # åŒå€åŸŸç«¶çˆ­åˆ†æ
        if len(district_report) > 0:
            district_competition = {}
            
            for _, row in district_report.iterrows():
                county = row['ç¸£å¸‚']
                district = row['è¡Œæ”¿å€']
                
                # åŒç¸£å¸‚å…¶ä»–è¡Œæ”¿å€
                competitors = district_report[
                    (district_report['ç¸£å¸‚'] == county) & 
                    (district_report['è¡Œæ”¿å€'] != district)
                ]
                
                if not competitors.empty:
                    competitive_position = {
                        'own_absorption_rate': row['æ•´é«”æ·¨å»åŒ–ç‡(%)'],
                        'competitor_avg': competitors['æ•´é«”æ·¨å»åŒ–ç‡(%)'].mean(),
                        'competitive_advantage': row['æ•´é«”æ·¨å»åŒ–ç‡(%)'] - competitors['æ•´é«”æ·¨å»åŒ–ç‡(%)'].mean(),
                        'market_rank': (competitors['æ•´é«”æ·¨å»åŒ–ç‡(%)'] < row['æ•´é«”æ·¨å»åŒ–ç‡(%)']).sum() + 1,
                        'total_competitors': len(competitors) + 1
                    }
                    
                    district_competition[f"{county}_{district}"] = competitive_position
            
            competitive_data['district_competition'] = district_competition
        
        # ç¸£å¸‚ç«¶çˆ­åˆ†æ
        if len(city_report) > 0:
            city_competition = {}
            
            for _, row in city_report.iterrows():
                county = row['ç¸£å¸‚']
                
                # å…¶ä»–ç¸£å¸‚
                competitors = city_report[city_report['ç¸£å¸‚'] != county]
                
                if not competitors.empty:
                    competitive_position = {
                        'own_absorption_rate': row['ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)'],
                        'national_avg': competitors['ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)'].mean(),
                        'competitive_advantage': row['ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)'] - competitors['ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)'].mean(),
                        'national_rank': (competitors['ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)'] < row['ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)']).sum() + 1,
                        'total_markets': len(competitors) + 1
                    }
                    
                    city_competition[county] = competitive_position
            
            competitive_data['city_competition'] = city_competition
        
        efficiency_analysis['competitive_analysis'] = competitive_data
        
        print("ğŸ”„ è­˜åˆ¥æ”¹å–„æ©Ÿæœƒ...")
        
        # 5. æ”¹å–„æ©Ÿæœƒè­˜åˆ¥
        improvement_data = {}
        
        # ä½æ•ˆç‡é …ç›®è­˜åˆ¥
        low_efficiency_projects = community_report[
            (community_report['æ·¨å»åŒ–ç‡(%)'] < community_report['æ·¨å»åŒ–ç‡(%)'].quantile(0.25)) &
            (community_report['ç´¯ç©è§£ç´„ç‡(%)'] > community_report['ç´¯ç©è§£ç´„ç‡(%)'].quantile(0.75))
        ]
        
        if not low_efficiency_projects.empty:
            improvement_opportunities = []
            
            # æŒ‰ç¸£å¸‚åˆ†çµ„åˆ†æ
            for county in low_efficiency_projects['ç¸£å¸‚'].unique():
                county_low_eff = low_efficiency_projects[low_efficiency_projects['ç¸£å¸‚'] == county]
                
                improvement_opportunities.append({
                    'county': county,
                    'low_efficiency_count': len(county_low_eff),
                    'avg_absorption': county_low_eff['æ·¨å»åŒ–ç‡(%)'].mean(),
                    'avg_cancellation': county_low_eff['ç´¯ç©è§£ç´„ç‡(%)'].mean(),
                    'improvement_potential': 'HIGH' if len(county_low_eff) > 5 else 'MEDIUM'
                })
            
            improvement_data['improvement_opportunities'] = improvement_opportunities
        
        # æœ€ä½³å¯¦è¸æ¡ˆä¾‹
        best_practices = community_report[
            (community_report['æ·¨å»åŒ–ç‡(%)'] > community_report['æ·¨å»åŒ–ç‡(%)'].quantile(0.9)) &
            (community_report['ç´¯ç©è§£ç´„ç‡(%)'] < community_report['ç´¯ç©è§£ç´„ç‡(%)'].quantile(0.1))
        ]
        
        if not best_practices.empty:
            improvement_data['best_practices'] = best_practices[
                ['ç¸£å¸‚', 'è¡Œæ”¿å€', 'ç¤¾å€åç¨±', 'æ·¨å»åŒ–ç‡(%)', 'å­£åº¦å»åŒ–é€Ÿåº¦(æˆ¶/å­£)', 'ç´¯ç©è§£ç´„ç‡(%)']
            ].head(10).to_dict('records')
        
        efficiency_analysis['improvement_opportunities'] = improvement_data
        
        print("âœ… æ•ˆç‡æ’åå°ˆé …åˆ†æå®Œæˆ")
        
        return efficiency_analysis
    
    except Exception as e:
        print(f"âŒ æ•ˆç‡æ’ååˆ†æéŒ¯èª¤: {e}")
        efficiency_analysis['error'] = str(e)
        return efficiency_analysis

# %%
# åŸ·è¡Œæ•ˆç‡æ’ååˆ†æ
efficiency_analysis_result = comprehensive_efficiency_ranking_analysis()

# é¡¯ç¤ºåˆ†æçµæœ
print(f"\nğŸ† æ•ˆç‡æ’ååˆ†æçµæœ:")

if 'multi_level_ranking' in efficiency_analysis_result:
    ranking_data = efficiency_analysis_result['multi_level_ranking']
    
    if 'city_ranking' in ranking_data:
        top_cities = ranking_data['city_ranking'][:5]
        print(f"ç¸£å¸‚æ•ˆç‡æ’å (å‰5å):")
        for city in top_cities:
            print(f"   {city['ranking']}. {city['ç¸£å¸‚']}: æ•ˆç‡åˆ†æ•¸{city['efficiency_score']:.1f}, å»åŒ–ç‡{city['ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)']:.1f}%")

if 'competitive_analysis' in efficiency_analysis_result:
    competitive_data = efficiency_analysis_result['competitive_analysis']
    
    if 'city_competition' in competitive_data:
        print(f"\nç¸£å¸‚ç«¶çˆ­å„ªå‹¢åˆ†æ (å‰3å):")
        city_advantages = sorted(
            competitive_data['city_competition'].items(), 
            key=lambda x: x[1]['competitive_advantage'], 
            reverse=True
        )[:3]
        
        for county, data in city_advantages:
            print(f"   {county}: ç«¶çˆ­å„ªå‹¢{data['competitive_advantage']:+.1f}%, å…¨åœ‹æ’å{data['national_rank']}/{data['total_markets']}")

if 'improvement_opportunities' in efficiency_analysis_result:
    improvement_data = efficiency_analysis_result['improvement_opportunities']
    
    if 'improvement_opportunities' in improvement_data:
        print(f"\næ”¹å–„æ©Ÿæœƒè­˜åˆ¥:")
        for opp in improvement_data['improvement_opportunities'][:3]:
            print(f"   {opp['county']}: {opp['low_efficiency_count']}å€‹ä½æ•ˆé …ç›®, æ”¹å–„æ½›åŠ›{opp['improvement_potential']}")
    
    if 'best_practices' in improvement_data:
        best_cases = improvement_data['best_practices'][:3]
        print(f"\næœ€ä½³å¯¦è¸æ¡ˆä¾‹:")
        for case in best_cases:
            print(f"   {case['ç¸£å¸‚']}{case['è¡Œæ”¿å€']}-{case.get('ç¤¾å€åç¨±', 'N/A')}: å»åŒ–ç‡{case['æ·¨å»åŒ–ç‡(%)']:.1f}%")

# %% [markdown]
# ## 5. é¢¨éšªé è­¦è¦–è¦ºåŒ–

# %%
# é¢¨éšªé è­¦è¦–è¦ºåŒ–
print("ğŸš¨ é¢¨éšªé è­¦è¦–è¦ºåŒ–")
print("=" * 50)

# å‰µå»ºé¢¨éšªé è­¦ç¶œåˆDashboard
def create_risk_warning_dashboard():
    """å‰µå»ºé¢¨éšªé è­¦è¦–è¦ºåŒ–Dashboard"""
    
    print("ğŸ”„ å‰µå»ºé¢¨éšªé è­¦è¦–è¦ºåŒ–...")
    
    # å‰µå»ºå­åœ–ä½ˆå±€
    fig = make_subplots(
        rows=3, cols=3,
        subplot_titles=[
            'ç¸£å¸‚é¢¨éšªç­‰ç´šåˆ†å¸ƒ', 'è¡Œæ”¿å€é¢¨éšªç†±åŠ›åœ–', 'è§£ç´„ç‡è¶¨å‹¢',
            'æ»¯éŠ·å»ºæ¡ˆåˆ†å¸ƒ', 'é¢¨éšªé›†ä¸­åº¦åˆ†æ', 'å»åŒ–ç‡vsè§£ç´„ç‡æ•£é»åœ–',
            'é«˜é¢¨éšªå€åŸŸæ’å', 'é¢¨éšªé è­¦å„€è¡¨æ¿', 'å¸‚å ´å¥åº·åº¦æŒ‡æ¨™'
        ],
        specs=[
            [{"type": "pie"}, {"type": "heatmap"}, {"type": "scatter"}],
            [{"type": "bar"}, {"type": "bar"}, {"type": "scatter"}],
            [{"type": "bar"}, {"type": "indicator"}, {"type": "bar"}]
        ],
        vertical_spacing=0.08,
        horizontal_spacing=0.1
    )
    
    # 1. ç¸£å¸‚é¢¨éšªç­‰ç´šåˆ†å¸ƒ (é¤…åœ–)
    if 'ç¸£å¸‚é¢¨éšªç­‰ç´š' in city_report.columns:
        risk_dist = city_report['ç¸£å¸‚é¢¨éšªç­‰ç´š'].value_counts()
        
        colors = []
        for risk in risk_dist.index:
            if 'ğŸ”´' in str(risk):
                colors.append('red')
            elif 'ğŸŸ¡' in str(risk):
                colors.append('orange')
            else:
                colors.append('green')
        
        fig.add_trace(
            go.Pie(
                labels=risk_dist.index,
                values=risk_dist.values,
                marker_colors=colors,
                name="ç¸£å¸‚é¢¨éšªåˆ†å¸ƒ"
            ),
            row=1, col=1
        )
    
    # 2. è¡Œæ”¿å€é¢¨éšªç†±åŠ›åœ–
    if len(district_report) > 0:
        # æº–å‚™ç†±åŠ›åœ–æ•¸æ“š
        risk_matrix_data = []
        counties = district_report['ç¸£å¸‚'].unique()[:10]  # é™åˆ¶é¡¯ç¤ºå‰10å€‹ç¸£å¸‚
        
        for county in counties:
            county_districts = district_report[district_report['ç¸£å¸‚'] == county]
            risk_scores = []
            
            for _, row in county_districts.iterrows():
                # è½‰æ›é¢¨éšªç­‰ç´šç‚ºæ•¸å€¼
                risk_level = str(row.get('é¢¨éšªç­‰ç´š', ''))
                if 'ğŸ”´' in risk_level:
                    risk_scores.append(3)
                elif 'ğŸŸ¡' in risk_level:
                    risk_scores.append(2)
                else:
                    risk_scores.append(1)
            
            if risk_scores:
                risk_matrix_data.append(risk_scores[:5])  # é™åˆ¶æ¯ç¸£å¸‚é¡¯ç¤º5å€‹è¡Œæ”¿å€
        
        if risk_matrix_data:
            fig.add_trace(
                go.Heatmap(
                    z=risk_matrix_data,
                    y=counties[:len(risk_matrix_data)],
                    colorscale=['green', 'yellow', 'red'],
                    showscale=False
                ),
                row=1, col=2
            )
    
    # 3. è§£ç´„ç‡è¶¨å‹¢
    if 'temporal_trends' in cancellation_analysis_result:
        temporal_data = cancellation_analysis_result['temporal_trends']
        seasons = [item['season'] for item in temporal_data]
        cancellation_rates = [item['avg_cancellation_rate'] for item in temporal_data]
        
        fig.add_trace(
            go.Scatter(
                x=seasons,
                y=cancellation_rates,
                mode='lines+markers',
                name='å¹³å‡è§£ç´„ç‡',
                line=dict(color='red', width=3),
                marker=dict(size=8)
            ),
            row=1, col=3
        )
    
    # 4. æ»¯éŠ·å»ºæ¡ˆåˆ†å¸ƒ
    if 'é•·æœŸæ»¯éŠ·å»ºæ¡ˆå æ¯”(%)' in city_report.columns:
        stagnant_data = city_report.nlargest(10, 'é•·æœŸæ»¯éŠ·å»ºæ¡ˆå æ¯”(%)')
        
        fig.add_trace(
            go.Bar(
                x=stagnant_data['ç¸£å¸‚'],
                y=stagnant_data['é•·æœŸæ»¯éŠ·å»ºæ¡ˆå æ¯”(%)'],
                marker_color='orange',
                name='æ»¯éŠ·å»ºæ¡ˆå æ¯”'
            ),
            row=2, col=1
        )
    
    # 5. é¢¨éšªé›†ä¸­åº¦åˆ†æ
    if 'risk_assessment' in cancellation_analysis_result:
        risk_concentration = cancellation_analysis_result['risk_assessment'].get('risk_concentration', {})
        
        if risk_concentration:
            counties = list(risk_concentration.keys())[:8]
            risk_counts = [risk_concentration[county] for county in counties]
            
            fig.add_trace(
                go.Bar(
                    x=counties,
                    y=risk_counts,
                    marker_color='red',
                    name='é«˜é¢¨éšªå»ºæ¡ˆæ•¸'
                ),
                row=2, col=2
            )
    
    # 6. å»åŒ–ç‡vsè§£ç´„ç‡æ•£é»åœ–
    fig.add_trace(
        go.Scatter(
            x=community_report['æ·¨å»åŒ–ç‡(%)'],
            y=community_report['ç´¯ç©è§£ç´„ç‡(%)'],
            mode='markers',
            marker=dict(
                size=6,
                color=community_report['ç´¯ç©è§£ç´„ç‡(%)'],
                colorscale='RdYlGn_r',
                showscale=False
            ),
            text=community_report['ç¸£å¸‚'] + ' - ' + community_report['è¡Œæ”¿å€'],
            name='å»ºæ¡ˆåˆ†å¸ƒ'
        ),
        row=2, col=3
    )
    
    # 7. é«˜é¢¨éšªå€åŸŸæ’å
    high_risk_districts = district_report[district_report['å€åŸŸè§£ç´„ç‡(%)'] > 2].nlargest(8, 'å€åŸŸè§£ç´„ç‡(%)')
    
    if not high_risk_districts.empty:
        district_labels = high_risk_districts['ç¸£å¸‚'] + '-' + high_risk_districts['è¡Œæ”¿å€']
        
        fig.add_trace(
            go.Bar(
                x=district_labels,
                y=high_risk_districts['å€åŸŸè§£ç´„ç‡(%)'],
                marker_color='red',
                name='å€åŸŸè§£ç´„ç‡'
            ),
            row=3, col=1
        )
    
    # 8. é¢¨éšªé è­¦å„€è¡¨æ¿
    if 'risk_assessment' in cancellation_analysis_result:
        overall_risk = cancellation_analysis_result['risk_assessment'].get('overall_risk_level', 'LOW')
        
        # è½‰æ›é¢¨éšªç­‰ç´šç‚ºæ•¸å€¼
        risk_value = {'LOW': 1, 'MEDIUM': 2, 'HIGH': 3}.get(overall_risk, 1)
        
        fig.add_trace(
            go.Indicator(
                mode="gauge+number+delta",
                value=risk_value,
                domain={'x': [0, 1], 'y': [0, 1]},
                title={'text': "æ•´é«”é¢¨éšªç­‰ç´š"},
                gauge={
                    'axis': {'range': [None, 3]},
                    'bar': {'color': "red" if risk_value >= 2.5 else "orange" if risk_value >= 1.5 else "green"},
                    'steps': [
                        {'range': [0, 1], 'color': "lightgreen"},
                        {'range': [1, 2], 'color': "yellow"},
                        {'range': [2, 3], 'color': "lightcoral"}
                    ],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': 2.5
                    }
                }
            ),
            row=3, col=2
        )
    
    # 9. å¸‚å ´å¥åº·åº¦æŒ‡æ¨™
    if 'predictive_insights' in absorption_analysis_result:
        health_data = absorption_analysis_result['predictive_insights']
        market_health = health_data.get('market_health', 'FAIR')
        
        health_values = {'POOR': 1, 'FAIR': 2, 'GOOD': 3, 'EXCELLENT': 4}
        health_score = health_values.get(market_health, 2)
        
        fig.add_trace(
            go.Bar(
                x=['å¸‚å ´å¥åº·åº¦'],
                y=[health_score],
                marker_color='green' if health_score >= 3 else 'orange' if health_score >= 2 else 'red',
                name='å¥åº·åº¦è©•åˆ†'
            ),
            row=3, col=3
        )
    
    # æ›´æ–°ä½ˆå±€
    fig.update_layout(
        title_text="é å”®å±‹å¸‚å ´é¢¨éšªé è­¦ç¶œåˆDashboard",
        title_x=0.5,
        showlegend=False,
        height=1200,
        font=dict(size=10)
    )
    
    # æ›´æ–°Xè»¸æ¨™ç±¤ï¼ˆæ—‹è½‰ï¼‰
    for i in range(1, 4):
        for j in range(1, 4):
            if not (i == 1 and j == 1) and not (i == 1 and j == 2) and not (i == 3 and j == 2):  # æ’é™¤é¤…åœ–ã€ç†±åŠ›åœ–å’Œå„€è¡¨æ¿
                fig.update_xaxes(tickangle=45, row=i, col=j)
    
    fig.show()
    
    return fig

# %%
# å‰µå»ºé¢¨éšªé è­¦Dashboard
risk_dashboard = create_risk_warning_dashboard()

print("âœ… é¢¨éšªé è­¦è¦–è¦ºåŒ–å®Œæˆ")

# %% [markdown]
# ## 6. ç†±é»å€åŸŸåˆ†æè¦–è¦ºåŒ–

# %%
# ç†±é»å€åŸŸåˆ†æè¦–è¦ºåŒ–
print("ğŸ”¥ ç†±é»å€åŸŸåˆ†æè¦–è¦ºåŒ–")
print("=" * 50)

def create_hotspot_analysis_visualization():
    """å‰µå»ºç†±é»å€åŸŸåˆ†æè¦–è¦ºåŒ–"""
    
    print("ğŸ”„ å‰µå»ºç†±é»å€åŸŸè¦–è¦ºåŒ–...")
    
    # å‰µå»ºå­åœ–ä½ˆå±€
    fig = make_subplots(
        rows=2, cols=3,
        subplot_titles=[
            'ç¸£å¸‚å»åŒ–è¡¨ç¾æ’å', 'ç†±é»è¡Œæ”¿å€åˆ†å¸ƒ', 'å»åŒ–é€Ÿåº¦vså»åŒ–ç‡',
            'æ•ˆç‡è©•ç´šåˆ†å¸ƒ', 'è¡¨ç¾è¶¨å‹¢åˆ†æ', 'ç«¶çˆ­åŠ›æŒ‡æ•¸'
        ],
        specs=[
            [{"type": "bar"}, {"type": "scatter"}, {"type": "scatter"}],
            [{"type": "pie"}, {"type": "scatter"}, {"type": "bar"}]
        ],
        vertical_spacing=0.15,
        horizontal_spacing=0.1
    )
    
    # 1. ç¸£å¸‚å»åŒ–è¡¨ç¾æ’å
    if len(city_report) > 0:
        top_cities = city_report.nlargest(10, 'ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)')
        
        # æ ¹æ“šè¡¨ç¾åˆ†ç´šè¨­å®šé¡è‰²
        colors = []
        for performance in top_cities.get('ç¸£å¸‚å»åŒ–è¡¨ç¾åˆ†ç´š', []):
            if 'ğŸ†' in str(performance):
                colors.append('gold')
            elif 'ğŸ¥‡' in str(performance):
                colors.append('silver')
            elif 'ğŸ¥ˆ' in str(performance):
                colors.append('#CD7F32')  # éŠ…è‰²
            else:
                colors.append('lightblue')
        
        fig.add_trace(
            go.Bar(
                x=top_cities['ç¸£å¸‚'],
                y=top_cities['ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)'],
                marker_color=colors if colors else 'lightblue',
                name='ç¸£å¸‚å»åŒ–ç‡',
                text=[f"{rate:.1f}%" for rate in top_cities['ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)']],
                textposition='outside'
            ),
            row=1, col=1
        )
    
    # 2. ç†±é»è¡Œæ”¿å€åˆ†å¸ƒ
    if len(district_report) > 0:
        # è­˜åˆ¥ç†±é»å€åŸŸï¼ˆå»åŒ–ç‡å’Œé€Ÿåº¦éƒ½è¼ƒé«˜çš„å€åŸŸï¼‰
        hotspot_threshold_rate = district_report['æ•´é«”æ·¨å»åŒ–ç‡(%)'].quantile(0.75)
        hotspot_threshold_speed = district_report['å€åŸŸå¹³å‡å»åŒ–é€Ÿåº¦(æˆ¶/å­£)'].quantile(0.75)
        
        # åˆ†é¡å€åŸŸ
        colors = []
        labels = []
        
        for _, row in district_report.iterrows():
            rate = row['æ•´é«”æ·¨å»åŒ–ç‡(%)']
            speed = row['å€åŸŸå¹³å‡å»åŒ–é€Ÿåº¦(æˆ¶/å­£)']
            
            if rate >= hotspot_threshold_rate and speed >= hotspot_threshold_speed:
                colors.append('red')
                labels.append('ğŸ”¥ ç†±é»å€åŸŸ')
            elif rate >= hotspot_threshold_rate or speed >= hotspot_threshold_speed:
                colors.append('orange')
                labels.append('â­ æ½›åŠ›å€åŸŸ')
            else:
                colors.append('lightblue')
                labels.append('ğŸ”µ ä¸€èˆ¬å€åŸŸ')
        
        fig.add_trace(
            go.Scatter(
                x=district_report['æ•´é«”æ·¨å»åŒ–ç‡(%)'],
                y=district_report['å€åŸŸå¹³å‡å»åŒ–é€Ÿåº¦(æˆ¶/å­£)'],
                mode='markers',
                marker=dict(
                    size=8,
                    color=colors,
                    line=dict(width=1, color='white')
                ),
                text=district_report['ç¸£å¸‚'] + '-' + district_report['è¡Œæ”¿å€'],
                name='è¡Œæ”¿å€åˆ†å¸ƒ'
            ),
            row=1, col=2
        )
    
    # 3. å»åŒ–é€Ÿåº¦vså»åŒ–ç‡ï¼ˆç¤¾å€ç´šï¼‰
    if len(community_report) > 0:
        # æŒ‰ç¸£å¸‚è‘—è‰²
        counties = community_report['ç¸£å¸‚'].unique()
        color_map = px.colors.qualitative.Set3[:len(counties)]
        county_colors = dict(zip(counties, color_map))
        
        colors = [county_colors.get(county, 'gray') for county in community_report['ç¸£å¸‚']]
        
        fig.add_trace(
            go.Scatter(
                x=community_report['æ·¨å»åŒ–ç‡(%)'],
                y=community_report.get('å­£åº¦å»åŒ–é€Ÿåº¦(æˆ¶/å­£)', [0] * len(community_report)),
                mode='markers',
                marker=dict(
                    size=5,
                    color=colors,
                    opacity=0.6
                ),
                text=community_report['ç¸£å¸‚'] + '-' + community_report.get('ç¤¾å€åç¨±', ''),
                name='å»ºæ¡ˆåˆ†å¸ƒ'
            ),
            row=1, col=3
        )
    
    # 4. æ•ˆç‡è©•ç´šåˆ†å¸ƒ
    if 'å»åŒ–æ•ˆç‡è©•ç´š' in community_report.columns:
        efficiency_dist = community_report['å»åŒ–æ•ˆç‡è©•ç´š'].value_counts()
        
        # è¨­å®šé¡è‰²
        grade_colors = []
        for grade in efficiency_dist.index:
            if 'ğŸš€' in str(grade):
                grade_colors.append('red')
            elif 'â­' in str(grade):
                grade_colors.append('orange')
            elif 'âš ï¸' in str(grade):
                grade_colors.append('yellow')
            else:
                grade_colors.append('lightblue')
        
        fig.add_trace(
            go.Pie(
                labels=efficiency_dist.index,
                values=efficiency_dist.values,
                marker_colors=grade_colors,
                name="æ•ˆç‡è©•ç´šåˆ†å¸ƒ"
            ),
            row=2, col=1
        )
    
    # 5. è¡¨ç¾è¶¨å‹¢åˆ†æ
    if 'temporal_trends' in absorption_analysis_result:
        temporal_data = absorption_analysis_result['temporal_trends']
        
        if 'seasonal_trends' in temporal_data:
            seasonal_data = temporal_data['seasonal_trends']
            seasons = [item['season'] for item in seasonal_data]
            absorption_rates = [item['avg_absorption_rate'] for item in seasonal_data]
            completion_rates = [item['completion_rate'] for item in seasonal_data]
            
            # é›™è»¸åœ–
            fig.add_trace(
                go.Scatter(
                    x=seasons,
                    y=absorption_rates,
                    mode='lines+markers',
                    name='å¹³å‡å»åŒ–ç‡',
                    line=dict(color='blue', width=3),
                    yaxis='y'
                ),
                row=2, col=2
            )
            
            fig.add_trace(
                go.Scatter(
                    x=seasons,
                    y=completion_rates,
                    mode='lines+markers',
                    name='å®Œå”®ç‡',
                    line=dict(color='green', width=3),
                    yaxis='y2'
                ),
                row=2, col=2
            )
    
    # 6. ç«¶çˆ­åŠ›æŒ‡æ•¸
    if 'competitive_analysis' in efficiency_analysis_result:
        competitive_data = efficiency_analysis_result['competitive_analysis']
        
        if 'city_competition' in competitive_data:
            city_competition = competitive_data['city_competition']
            
            # å–ç«¶çˆ­å„ªå‹¢æœ€å¤§çš„å‰8å€‹ç¸£å¸‚
            sorted_cities = sorted(
                city_competition.items(), 
                key=lambda x: x[1]['competitive_advantage'], 
                reverse=True
            )[:8]
            
            counties = [item[0] for item in sorted_cities]
            advantages = [item[1]['competitive_advantage'] for item in sorted_cities]
            
            # è¨­å®šé¡è‰²ï¼ˆæ­£å€¼ç‚ºç¶ è‰²ï¼Œè² å€¼ç‚ºç´…è‰²ï¼‰
            bar_colors = ['green' if adv > 0 else 'red' for adv in advantages]
            
            fig.add_trace(
                go.Bar(
                    x=counties,
                    y=advantages,
                    marker_color=bar_colors,
                    name='ç«¶çˆ­å„ªå‹¢',
                    text=[f"{adv:+.1f}%" for adv in advantages],
                    textposition='outside'
                ),
                row=2, col=3
            )
    
    # æ›´æ–°ä½ˆå±€
    fig.update_layout(
        title_text="ç†±é»å€åŸŸåˆ†æç¶œåˆè¦–è¦ºåŒ–",
        title_x=0.5,
        showlegend=False,
        height=800,
        font=dict(size=10)
    )
    
    # æ›´æ–°è»¸æ¨™ç±¤
    fig.update_xaxes(title_text="ç¸£å¸‚", row=1, col=1, tickangle=45)
    fig.update_yaxes(title_text="å»åŒ–ç‡(%)", row=1, col=1)
    
    fig.update_xaxes(title_text="æ•´é«”æ·¨å»åŒ–ç‡(%)", row=1, col=2)
    fig.update_yaxes(title_text="å€åŸŸå¹³å‡å»åŒ–é€Ÿåº¦(æˆ¶/å­£)", row=1, col=2)
    
    fig.update_xaxes(title_text="æ·¨å»åŒ–ç‡(%)", row=1, col=3)
    fig.update_yaxes(title_text="å­£åº¦å»åŒ–é€Ÿåº¦(æˆ¶/å­£)", row=1, col=3)
    
    fig.update_xaxes(title_text="å¹´å­£", row=2, col=2, tickangle=45)
    fig.update_yaxes(title_text="æ¯”ç‡(%)", row=2, col=2)
    
    fig.update_xaxes(title_text="ç¸£å¸‚", row=2, col=3, tickangle=45)
    fig.update_yaxes(title_text="ç«¶çˆ­å„ªå‹¢(%)", row=2, col=3)
    
    fig.show()
    
    return fig

# %%
# å‰µå»ºç†±é»å€åŸŸè¦–è¦ºåŒ–
hotspot_visualization = create_hotspot_analysis_visualization()

print("âœ… ç†±é»å€åŸŸè¦–è¦ºåŒ–å®Œæˆ")

# %% [markdown]
# ## 7. ä¸‰å±¤ç´šå°æ¯”åˆ†æ

# %%
# ä¸‰å±¤ç´šå°æ¯”åˆ†æè¦–è¦ºåŒ–
print("ğŸ“Š ä¸‰å±¤ç´šå°æ¯”åˆ†æè¦–è¦ºåŒ–")
print("=" * 50)

def create_three_level_comparison():
    """å‰µå»ºä¸‰å±¤ç´šå°æ¯”åˆ†æè¦–è¦ºåŒ–"""
    
    print("ğŸ”„ å‰µå»ºä¸‰å±¤ç´šå°æ¯”è¦–è¦ºåŒ–...")
    
    # å‰µå»ºå¤§å‹å­åœ–ä½ˆå±€
    fig = make_subplots(
        rows=3, cols=2,
        subplot_titles=[
            'ä¸‰å±¤ç´šå»åŒ–ç‡åˆ†å¸ƒå°æ¯”', 'ä¸‰å±¤ç´šé¢¨éšªç­‰ç´šåˆ†å¸ƒ',
            'ä¸‰å±¤ç´šå¹³å‡æŒ‡æ¨™å°æ¯”', 'ç¸£å¸‚å±¤ç´šè¡¨ç¾åˆ†ç´š',
            'è¡Œæ”¿å€å±¤ç´šæ•ˆç‡åˆ†å¸ƒ', 'ç¤¾å€å±¤ç´šè¡¨ç¾æ¦‚æ³'
        ],
        specs=[
            [{"type": "histogram"}, {"type": "bar"}],
            [{"type": "bar"}, {"type": "pie"}],
            [{"type": "histogram"}, {"type": "bar"}]
        ],
        vertical_spacing=0.12,
        horizontal_spacing=0.1
    )
    
    # 1. ä¸‰å±¤ç´šå»åŒ–ç‡åˆ†å¸ƒå°æ¯”
    community_absorption = community_report['æ·¨å»åŒ–ç‡(%)'][community_report['æ·¨å»åŒ–ç‡(%)'] >= 0]
    district_absorption = district_report['æ•´é«”æ·¨å»åŒ–ç‡(%)'][district_report['æ•´é«”æ·¨å»åŒ–ç‡(%)'] >= 0]
    city_absorption = city_report['ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)'][city_report['ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)'] >= 0]
    
    fig.add_trace(
        go.Histogram(
            x=community_absorption,
            name='ç¤¾å€ç´š',
            opacity=0.7,
            marker_color='lightblue',
            nbinsx=20
        ),
        row=1, col=1
    )
    
    fig.add_trace(
        go.Histogram(
            x=district_absorption,
            name='è¡Œæ”¿å€ç´š',
            opacity=0.7,
            marker_color='lightgreen',
            nbinsx=15
        ),
        row=1, col=1
    )
    
    fig.add_trace(
        go.Histogram(
            x=city_absorption,
            name='ç¸£å¸‚ç´š',
            opacity=0.7,
            marker_color='lightcoral',
            nbinsx=10
        ),
        row=1, col=1
    )
    
    # 2. ä¸‰å±¤ç´šé¢¨éšªç­‰ç´šåˆ†å¸ƒ
    # çµ±è¨ˆå„å±¤ç´šé¢¨éšªåˆ†å¸ƒ
    risk_summary = {
        'ç¤¾å€ç´š': {'ğŸŸ¢': 0, 'ğŸŸ¡': 0, 'ğŸ”´': 0},
        'è¡Œæ”¿å€ç´š': {'ğŸŸ¢': 0, 'ğŸŸ¡': 0, 'ğŸ”´': 0},
        'ç¸£å¸‚ç´š': {'ğŸŸ¢': 0, 'ğŸŸ¡': 0, 'ğŸ”´': 0}
    }
    
    # ç¤¾å€ç´šé¢¨éšªçµ±è¨ˆ
    if 'è§£ç´„è­¦ç¤º' in community_report.columns:
        for risk in community_report['è§£ç´„è­¦ç¤º']:
            risk_str = str(risk)
            if 'ğŸ”´' in risk_str:
                risk_summary['ç¤¾å€ç´š']['ğŸ”´'] += 1
            elif 'ğŸŸ¡' in risk_str:
                risk_summary['ç¤¾å€ç´š']['ğŸŸ¡'] += 1
            else:
                risk_summary['ç¤¾å€ç´š']['ğŸŸ¢'] += 1
    
    # è¡Œæ”¿å€ç´šé¢¨éšªçµ±è¨ˆ
    if 'é¢¨éšªç­‰ç´š' in district_report.columns:
        for risk in district_report['é¢¨éšªç­‰ç´š']:
            risk_str = str(risk)
            if 'ğŸ”´' in risk_str:
                risk_summary['è¡Œæ”¿å€ç´š']['ğŸ”´'] += 1
            elif 'ğŸŸ¡' in risk_str:
                risk_summary['è¡Œæ”¿å€ç´š']['ğŸŸ¡'] += 1
            else:
                risk_summary['è¡Œæ”¿å€ç´š']['ğŸŸ¢'] += 1
    
    # ç¸£å¸‚ç´šé¢¨éšªçµ±è¨ˆ
    if 'ç¸£å¸‚é¢¨éšªç­‰ç´š' in city_report.columns:
        for risk in city_report['ç¸£å¸‚é¢¨éšªç­‰ç´š']:
            risk_str = str(risk)
            if 'ğŸ”´' in risk_str:
                risk_summary['ç¸£å¸‚ç´š']['ğŸ”´'] += 1
            elif 'ğŸŸ¡' in risk_str:
                risk_summary['ç¸£å¸‚ç´š']['ğŸŸ¡'] += 1
            else:
                risk_summary['ç¸£å¸‚ç´š']['ğŸŸ¢'] += 1
    
    # ç¹ªè£½é¢¨éšªåˆ†å¸ƒæŸ±ç‹€åœ–
    levels = list(risk_summary.keys())
    green_counts = [risk_summary[level]['ğŸŸ¢'] for level in levels]
    yellow_counts = [risk_summary[level]['ğŸŸ¡'] for level in levels]
    red_counts = [risk_summary[level]['ğŸ”´'] for level in levels]
    
    fig.add_trace(
        go.Bar(name='ğŸŸ¢ ä½é¢¨éšª', x=levels, y=green_counts, marker_color='green'),
        row=1, col=2
    )
    fig.add_trace(
        go.Bar(name='ğŸŸ¡ ä¸­é¢¨éšª', x=levels, y=yellow_counts, marker_color='orange'),
        row=1, col=2
    )
    fig.add_trace(
        go.Bar(name='ğŸ”´ é«˜é¢¨éšª', x=levels, y=red_counts, marker_color='red'),
        row=1, col=2
    )
    
    # 3. ä¸‰å±¤ç´šå¹³å‡æŒ‡æ¨™å°æ¯”
    level_metrics = {
        'ç¤¾å€ç´š': {
            'å¹³å‡å»åŒ–ç‡': community_report['æ·¨å»åŒ–ç‡(%)'].mean(),
            'å¹³å‡è§£ç´„ç‡': community_report['ç´¯ç©è§£ç´„ç‡(%)'].mean(),
            'ç¸½æ¨£æœ¬æ•¸': len(community_report)
        },
        'è¡Œæ”¿å€ç´š': {
            'å¹³å‡å»åŒ–ç‡': district_report['æ•´é«”æ·¨å»åŒ–ç‡(%)'].mean(),
            'å¹³å‡è§£ç´„ç‡': district_report['å€åŸŸè§£ç´„ç‡(%)'].mean(),
            'ç¸½æ¨£æœ¬æ•¸': len(district_report)
        },
        'ç¸£å¸‚ç´š': {
            'å¹³å‡å»åŒ–ç‡': city_report['ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)'].mean(),
            'å¹³å‡è§£ç´„ç‡': city_report['ç¸£å¸‚è§£ç´„ç‡(%)'].mean(),
            'ç¸½æ¨£æœ¬æ•¸': len(city_report)
        }
    }
    
    levels = list(level_metrics.keys())
    absorption_rates = [level_metrics[level]['å¹³å‡å»åŒ–ç‡'] for level in levels]
    cancellation_rates = [level_metrics[level]['å¹³å‡è§£ç´„ç‡'] for level in levels]
    
    fig.add_trace(
        go.Bar(
            name='å¹³å‡å»åŒ–ç‡',
            x=levels,
            y=absorption_rates,
            marker_color='blue',
            text=[f"{rate:.1f}%" for rate in absorption_rates],
            textposition='outside'
        ),
        row=2, col=1
    )
    
    # æ·»åŠ æ¬¡è»¸é¡¯ç¤ºè§£ç´„ç‡
    fig.add_trace(
        go.Bar(
            name='å¹³å‡è§£ç´„ç‡',
            x=levels,
            y=[rate * 10 for rate in cancellation_rates],  # æ”¾å¤§10å€ä»¥ä¾¿é¡¯ç¤º
            marker_color='red',
            opacity=0.6,
            text=[f"{rate:.2f}%" for rate in cancellation_rates],
            textposition='outside'
        ),
        row=2, col=1
    )
    
    # 4. ç¸£å¸‚å±¤ç´šè¡¨ç¾åˆ†ç´š
    if 'ç¸£å¸‚å»åŒ–è¡¨ç¾åˆ†ç´š' in city_report.columns:
        performance_dist = city_report['ç¸£å¸‚å»åŒ–è¡¨ç¾åˆ†ç´š'].value_counts()
        
        # è¨­å®šé¡è‰²
        performance_colors = []
        for grade in performance_dist.index:
            if 'ğŸ†' in str(grade):
                performance_colors.append('gold')
            elif 'ğŸ¥‡' in str(grade):
                performance_colors.append('silver')
            elif 'ğŸ¥ˆ' in str(grade):
                performance_colors.append('#CD7F32')
            else:
                performance_colors.append('lightblue')
        
        fig.add_trace(
            go.Pie(
                labels=performance_dist.index,
                values=performance_dist.values,
                marker_colors=performance_colors,
                name="ç¸£å¸‚è¡¨ç¾åˆ†ç´š"
            ),
            row=2, col=2
        )
    
    # 5. è¡Œæ”¿å€å±¤ç´šæ•ˆç‡åˆ†å¸ƒ
    if 'å€åŸŸå¹³å‡å»åŒ–é€Ÿåº¦(æˆ¶/å­£)' in district_report.columns:
        district_speeds = district_report['å€åŸŸå¹³å‡å»åŒ–é€Ÿåº¦(æˆ¶/å­£)'][district_report['å€åŸŸå¹³å‡å»åŒ–é€Ÿåº¦(æˆ¶/å­£)'] >= 0]
        
        fig.add_trace(
            go.Histogram(
                x=district_speeds,
                name='è¡Œæ”¿å€å»åŒ–é€Ÿåº¦',
                marker_color='lightgreen',
                nbinsx=15
            ),
            row=3, col=1
        )
    
    # 6. ç¤¾å€å±¤ç´šè¡¨ç¾æ¦‚æ³
    if 'å»åŒ–æ•ˆç‡è©•ç´š' in community_report.columns:
        efficiency_summary = community_report['å»åŒ–æ•ˆç‡è©•ç´š'].value_counts().head(8)
        
        # ç°¡åŒ–æ¨™ç±¤
        simplified_labels = []
        for label in efficiency_summary.index:
            if 'ğŸš€' in str(label):
                simplified_labels.append('é«˜æ•ˆ')
            elif 'â­' in str(label):
                simplified_labels.append('æ­£å¸¸')
            elif 'âš ï¸' in str(label):
                simplified_labels.append('ç·©æ…¢')
            elif 'ğŸŒ' in str(label):
                simplified_labels.append('æ»¯éŠ·')
            else:
                simplified_labels.append('å…¶ä»–')
        
        fig.add_trace(
            go.Bar(
                x=simplified_labels,
                y=efficiency_summary.values,
                marker_color='lightblue',
                name='æ•ˆç‡åˆ†å¸ƒ',
                text=efficiency_summary.values,
                textposition='outside'
            ),
            row=3, col=2
        )
    
    # æ›´æ–°ä½ˆå±€
    fig.update_layout(
        title_text="ä¸‰å±¤ç´šå¸‚å ´åˆ†æå°æ¯”Dashboard",
        title_x=0.5,
        showlegend=True,
        height=1000,
        font=dict(size=10),
        barmode='group'
    )
    
    # æ›´æ–°è»¸æ¨™ç±¤
    fig.update_xaxes(title_text="å»åŒ–ç‡(%)", row=1, col=1)
    fig.update_yaxes(title_text="é »æ¬¡", row=1, col=1)
    
    fig.update_xaxes(title_text="åˆ†æå±¤ç´š", row=1, col=2)
    fig.update_yaxes(title_text="æ•¸é‡", row=1, col=2)
    
    fig.update_xaxes(title_text="åˆ†æå±¤ç´š", row=2, col=1)
    fig.update_yaxes(title_text="å¹³å‡å€¼(%)", row=2, col=1)
    
    fig.update_xaxes(title_text="å»åŒ–é€Ÿåº¦(æˆ¶/å­£)", row=3, col=1)
    fig.update_yaxes(title_text="é »æ¬¡", row=3, col=1)
    
    fig.update_xaxes(title_text="æ•ˆç‡è©•ç´š", row=3, col=2)
    fig.update_yaxes(title_text="å»ºæ¡ˆæ•¸", row=3, col=2)
    
    fig.show()
    
    return fig

# %%
# å‰µå»ºä¸‰å±¤ç´šå°æ¯”è¦–è¦ºåŒ–
three_level_comparison = create_three_level_comparison()

print("âœ… ä¸‰å±¤ç´šå°æ¯”è¦–è¦ºåŒ–å®Œæˆ")

# é¡¯ç¤ºä¸‰å±¤ç´šå°æ¯”çµ±è¨ˆ
print(f"\nğŸ“Š ä¸‰å±¤ç´šå°æ¯”çµ±è¨ˆæ‘˜è¦:")

# æ¨£æœ¬æ•¸å°æ¯”
print(f"æ¨£æœ¬æ•¸å°æ¯”:")
print(f"   ç¤¾å€ç´š: {len(community_report):,} å€‹å»ºæ¡ˆ")
print(f"   è¡Œæ”¿å€ç´š: {len(district_report):,} å€‹è¡Œæ”¿å€")
print(f"   ç¸£å¸‚ç´š: {len(city_report):,} å€‹ç¸£å¸‚")

# å¹³å‡æŒ‡æ¨™å°æ¯”
print(f"\nå¹³å‡æŒ‡æ¨™å°æ¯”:")
print(f"   ç¤¾å€ç´šå¹³å‡å»åŒ–ç‡: {community_report['æ·¨å»åŒ–ç‡(%)'].mean():.1f}%")
print(f"   è¡Œæ”¿å€ç´šå¹³å‡å»åŒ–ç‡: {district_report['æ•´é«”æ·¨å»åŒ–ç‡(%)'].mean():.1f}%")
print(f"   ç¸£å¸‚ç´šå¹³å‡å»åŒ–ç‡: {city_report['ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)'].mean():.1f}%")

print(f"\n   ç¤¾å€ç´šå¹³å‡è§£ç´„ç‡: {community_report['ç´¯ç©è§£ç´„ç‡(%)'].mean():.2f}%")
print(f"   è¡Œæ”¿å€ç´šå¹³å‡è§£ç´„ç‡: {district_report['å€åŸŸè§£ç´„ç‡(%)'].mean():.2f}%")
print(f"   ç¸£å¸‚ç´šå¹³å‡è§£ç´„ç‡: {city_report['ç¸£å¸‚è§£ç´„ç‡(%)'].mean():.2f}%")

# %% [markdown]
# ## 8. å¸‚å ´æ´å¯Ÿåˆ†æ

# %%
# å¸‚å ´æ´å¯Ÿåˆ†æ
print("ğŸ’¡ å¸‚å ´æ´å¯Ÿåˆ†æ")
print("=" * 50)

def generate_comprehensive_market_insights():
    """
    ç”Ÿæˆç¶œåˆå¸‚å ´æ´å¯Ÿåˆ†æ
    
    Returns:
        dict: å¸‚å ´æ´å¯Ÿçµæœ
    """
    
    market_insights = {
        'overall_assessment': {},
        'key_findings': [],
        'risk_warnings': [],
        'opportunities': [],
        'market_dynamics': {},
        'recommendations': []
    }
    
    try:
        print("ğŸ”„ é€²è¡Œæ•´é«”å¸‚å ´è©•ä¼°...")
        
        # 1. æ•´é«”å¸‚å ´è©•ä¼°
        overall_stats = {
            'total_projects': len(community_report),
            'avg_absorption_rate': community_report['æ·¨å»åŒ–ç‡(%)'].mean(),
            'avg_cancellation_rate': community_report['ç´¯ç©è§£ç´„ç‡(%)'].mean(),
            'completion_rate': len(community_report[community_report['æ·¨å»åŒ–ç‡(%)'] >= 100]) / len(community_report) * 100,
            'high_risk_project_ratio': len(community_report[community_report['ç´¯ç©è§£ç´„ç‡(%)'] > 5]) / len(community_report) * 100
        }
        
        # å¸‚å ´å¥åº·åº¦ç¶œåˆè©•åˆ†
        health_score = 0
        
        # å»åŒ–ç‡è©•åˆ† (40%)
        if overall_stats['avg_absorption_rate'] >= 60:
            health_score += 40
        elif overall_stats['avg_absorption_rate'] >= 40:
            health_score += 30
        elif overall_stats['avg_absorption_rate'] >= 20:
            health_score += 20
        else:
            health_score += 10
        
        # è§£ç´„ç‡è©•åˆ† (30%)
        if overall_stats['avg_cancellation_rate'] < 1:
            health_score += 30
        elif overall_stats['avg_cancellation_rate'] < 2:
            health_score += 25
        elif overall_stats['avg_cancellation_rate'] < 3:
            health_score += 15
        else:
            health_score += 5
        
        # å®Œå”®ç‡è©•åˆ† (20%)
        if overall_stats['completion_rate'] >= 20:
            health_score += 20
        elif overall_stats['completion_rate'] >= 10:
            health_score += 15
        elif overall_stats['completion_rate'] >= 5:
            health_score += 10
        else:
            health_score += 5
        
        # é¢¨éšªæ§åˆ¶è©•åˆ† (10%)
        if overall_stats['high_risk_project_ratio'] < 5:
            health_score += 10
        elif overall_stats['high_risk_project_ratio'] < 10:
            health_score += 8
        elif overall_stats['high_risk_project_ratio'] < 15:
            health_score += 5
        else:
            health_score += 2
        
        overall_stats['market_health_score'] = health_score
        
        # å¸‚å ´å¥åº·åº¦åˆ†ç´š
        if health_score >= 85:
            overall_stats['market_health_grade'] = "ğŸ† å„ªç§€"
        elif health_score >= 70:
            overall_stats['market_health_grade'] = "ğŸ¥‡ è‰¯å¥½"
        elif health_score >= 55:
            overall_stats['market_health_grade'] = "ğŸ¥ˆ æ™®é€š"
        else:
            overall_stats['market_health_grade'] = "âš ï¸ éœ€æ”¹å–„"
        
        market_insights['overall_assessment'] = overall_stats
        
        print("ğŸ”„ è­˜åˆ¥é—œéµç™¼ç¾...")
        
        # 2. é—œéµç™¼ç¾
        key_findings = []
        
        # å»åŒ–è¡¨ç¾åˆ†æ
        if overall_stats['avg_absorption_rate'] > 50:
            key_findings.append(f"å¸‚å ´æ•´é«”å»åŒ–è¡¨ç¾è‰¯å¥½ï¼Œå¹³å‡å»åŒ–ç‡é”{overall_stats['avg_absorption_rate']:.1f}%")
        elif overall_stats['avg_absorption_rate'] > 30:
            key_findings.append(f"å¸‚å ´å»åŒ–è¡¨ç¾ä¸­ç­‰ï¼Œå¹³å‡å»åŒ–ç‡ç‚º{overall_stats['avg_absorption_rate']:.1f}%ï¼Œä»æœ‰æå‡ç©ºé–“")
        else:
            key_findings.append(f"å¸‚å ´å»åŒ–è¡¨ç¾åå¼±ï¼Œå¹³å‡å»åŒ–ç‡åƒ…{overall_stats['avg_absorption_rate']:.1f}%ï¼Œéœ€é—œæ³¨å»åŒ–å£“åŠ›")
        
        # è§£ç´„é¢¨éšªåˆ†æ
        if overall_stats['avg_cancellation_rate'] < 1:
            key_findings.append(f"è§£ç´„é¢¨éšªæ§åˆ¶è‰¯å¥½ï¼Œå¹³å‡è§£ç´„ç‡åƒ…{overall_stats['avg_cancellation_rate']:.2f}%")
        elif overall_stats['avg_cancellation_rate'] < 3:
            key_findings.append(f"è§£ç´„é¢¨éšªè™•æ–¼å¯æ§ç¯„åœï¼Œå¹³å‡è§£ç´„ç‡ç‚º{overall_stats['avg_cancellation_rate']:.2f}%")
        else:
            key_findings.append(f"è§£ç´„é¢¨éšªåé«˜ï¼Œå¹³å‡è§£ç´„ç‡é”{overall_stats['avg_cancellation_rate']:.2f}%ï¼Œéœ€åŠ å¼·é¢¨éšªç®¡æ§")
        
        # å®Œå”®è¡¨ç¾åˆ†æ
        if overall_stats['completion_rate'] > 15:
            key_findings.append(f"å®Œå”®è¡¨ç¾å„ªç•°ï¼Œ{overall_stats['completion_rate']:.1f}%çš„å»ºæ¡ˆå·²å®Œå”®")
        elif overall_stats['completion_rate'] > 8:
            key_findings.append(f"å®Œå”®è¡¨ç¾ä¸­ç­‰ï¼Œ{overall_stats['completion_rate']:.1f}%çš„å»ºæ¡ˆå·²å®Œå”®")
        else:
            key_findings.append(f"å®Œå”®è¡¨ç¾åä½ï¼Œåƒ…{overall_stats['completion_rate']:.1f}%çš„å»ºæ¡ˆå®Œå”®ï¼Œéœ€é—œæ³¨éŠ·å”®ç­–ç•¥")
        
        # ç¸£å¸‚å·®ç•°åˆ†æ
        if len(city_report) > 1:
            city_absorption_std = city_report['ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)'].std()
            if city_absorption_std > 20:
                key_findings.append("å„ç¸£å¸‚å»åŒ–è¡¨ç¾å·®ç•°é¡¯è‘—ï¼Œå­˜åœ¨æ˜é¡¯çš„å€åŸŸåˆ†åŒ–ç¾è±¡")
            elif city_absorption_std > 10:
                key_findings.append("å„ç¸£å¸‚å»åŒ–è¡¨ç¾å­˜åœ¨ä¸€å®šå·®ç•°ï¼Œå»ºè­°é—œæ³¨è¡¨ç¾è¼ƒå¼±çš„å€åŸŸ")
            else:
                key_findings.append("å„ç¸£å¸‚å»åŒ–è¡¨ç¾ç›¸å°å‡è¡¡ï¼Œæ•´é«”å¸‚å ´ç™¼å±•ç©©å®š")
        
        # ç†±é»å€åŸŸåˆ†æ
        if len(district_report) > 0:
            top_districts = district_report.nlargest(5, 'æ•´é«”æ·¨å»åŒ–ç‡(%)')
            hotspot_cities = top_districts['ç¸£å¸‚'].unique()
            if len(hotspot_cities) <= 2:
                key_findings.append(f"å¸‚å ´ç†±é»ä¸»è¦é›†ä¸­åœ¨{', '.join(hotspot_cities)}ç­‰å°‘æ•¸ç¸£å¸‚")
            else:
                key_findings.append(f"å¸‚å ´ç†±é»åˆ†å¸ƒè¼ƒç‚ºåˆ†æ•£ï¼Œæ¶µè“‹{', '.join(hotspot_cities[:3])}ç­‰å¤šå€‹ç¸£å¸‚")
        
        market_insights['key_findings'] = key_findings
        
        print("ğŸ”„ è­˜åˆ¥é¢¨éšªé è­¦...")
        
        # 3. é¢¨éšªé è­¦
        risk_warnings = []
        
        # é«˜è§£ç´„ç‡é è­¦
        high_cancellation_projects = len(community_report[community_report['ç´¯ç©è§£ç´„ç‡(%)'] > 10])
        if high_cancellation_projects > 0:
            risk_warnings.append(f"ç™¼ç¾{high_cancellation_projects}å€‹å»ºæ¡ˆè§£ç´„ç‡è¶…é10%ï¼Œéœ€å¯†åˆ‡ç›£æ§")
        
        # æ»¯éŠ·é è­¦
        if 'é•·æœŸæ»¯éŠ·å»ºæ¡ˆå æ¯”(%)' in city_report.columns:
            high_stagnant_cities = len(city_report[city_report['é•·æœŸæ»¯éŠ·å»ºæ¡ˆå æ¯”(%)'] > 20])
            if high_stagnant_cities > 0:
                risk_warnings.append(f"{high_stagnant_cities}å€‹ç¸£å¸‚é•·æœŸæ»¯éŠ·å»ºæ¡ˆå æ¯”è¶…é20%ï¼Œå»åŒ–å£“åŠ›è¼ƒå¤§")
        
        # å€åŸŸé›†ä¸­é¢¨éšª
        if 'risk_assessment' in cancellation_analysis_result:
            risk_concentration = cancellation_analysis_result['risk_assessment'].get('risk_concentration', {})
            if len(risk_concentration) > 0:
                max_risk_county = max(risk_concentration.items(), key=lambda x: x[1])
                if max_risk_county[1] > 10:
                    risk_warnings.append(f"{max_risk_county[0]}è§£ç´„é¢¨éšªå»ºæ¡ˆé›†ä¸­ï¼Œå…±{max_risk_county[1]}å€‹ï¼Œéœ€ç‰¹åˆ¥é—œæ³¨")
        
        # è¶¨å‹¢æƒ¡åŒ–é è­¦
        if 'temporal_trends' in cancellation_analysis_result:
            temporal_data = cancellation_analysis_result['temporal_trends']
            if len(temporal_data) >= 2:
                recent_risk = temporal_data[-1]['high_risk_ratio']
                early_risk = temporal_data[0]['high_risk_ratio']
                if recent_risk > early_risk * 1.5:
                    risk_warnings.append("é«˜é¢¨éšªå»ºæ¡ˆæ¯”ä¾‹å‘ˆç¾ä¸Šå‡è¶¨å‹¢ï¼Œå¸‚å ´é¢¨éšªå¢åŠ ")
        
        # å¸‚å ´è¡¨ç¾åˆ†åŒ–é è­¦
        if len(city_report) > 2:
            performance_gap = city_report['ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)'].max() - city_report['ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)'].min()
            if performance_gap > 40:
                risk_warnings.append(f"ç¸£å¸‚é–“å»åŒ–è¡¨ç¾å·®è·é”{performance_gap:.1f}%ï¼Œå¸‚å ´åˆ†åŒ–åš´é‡")
        
        if not risk_warnings:
            risk_warnings.append("æœªç™¼ç¾é‡å¤§å¸‚å ´é¢¨éšªï¼Œæ•´é«”é¢¨éšªæ§åˆ¶è‰¯å¥½")
        
        market_insights['risk_warnings'] = risk_warnings
        
        print("ğŸ”„ è­˜åˆ¥å¸‚å ´æ©Ÿæœƒ...")
        
        # 4. å¸‚å ´æ©Ÿæœƒè­˜åˆ¥
        opportunities = []
        
        # é«˜è¡¨ç¾å€åŸŸæ©Ÿæœƒ
        if len(district_report) > 0:
            high_performance_districts = district_report[
                (district_report['æ•´é«”æ·¨å»åŒ–ç‡(%)'] > 70) & 
                (district_report['å€åŸŸè§£ç´„ç‡(%)'] < 2)
            ]
            
            if not high_performance_districts.empty:
                opportunity_cities = high_performance_districts['ç¸£å¸‚'].unique()
                opportunities.append(f"é«˜è¡¨ç¾å€åŸŸæŠ•è³‡æ©Ÿæœƒï¼š{', '.join(opportunity_cities[:3])}ç­‰åœ°å€è¡¨ç¾å„ªç•°")
        
        # åƒ¹æ ¼çªªåœ°æ©Ÿæœƒ
        if 'å¹³å‡äº¤æ˜“å–®åƒ¹(è¬/åª)' in community_report.columns:
            # æ‰¾å‡ºåƒ¹æ ¼ç›¸å°è¼ƒä½ä½†å»åŒ–è¡¨ç¾ä¸éŒ¯çš„å€åŸŸ
            community_with_price = community_report[community_report['å¹³å‡äº¤æ˜“å–®åƒ¹(è¬/åª)'] > 0]
            if not community_with_price.empty:
                price_threshold = community_with_price['å¹³å‡äº¤æ˜“å–®åƒ¹(è¬/åª)'].quantile(0.4)  # åƒ¹æ ¼å‰40%è¼ƒä½
                absorption_threshold = community_with_price['æ·¨å»åŒ–ç‡(%)'].quantile(0.6)  # å»åŒ–ç‡å‰60%è¼ƒé«˜
                
                value_opportunities = community_with_price[
                    (community_with_price['å¹³å‡äº¤æ˜“å–®åƒ¹(è¬/åª)'] <= price_threshold) &
                    (community_with_price['æ·¨å»åŒ–ç‡(%)'] >= absorption_threshold)
                ]
                
                if not value_opportunities.empty:
                    value_cities = value_opportunities['ç¸£å¸‚'].value_counts().head(3).index.tolist()
                    opportunities.append(f"åƒ¹æ ¼çªªåœ°æ©Ÿæœƒï¼š{', '.join(value_cities)}ç­‰åœ°å€å…·æœ‰åƒ¹æ ¼å„ªå‹¢ä¸”å»åŒ–è‰¯å¥½")
        
        # æ”¹å–„æ½›åŠ›æ©Ÿæœƒ
        if 'improvement_opportunities' in efficiency_analysis_result:
            improvement_data = efficiency_analysis_result['improvement_opportunities']
            if 'improvement_opportunities' in improvement_data:
                improvement_counties = [
                    opp['county'] for opp in improvement_data['improvement_opportunities'] 
                    if opp['improvement_potential'] == 'HIGH'
                ]
                if improvement_counties:
                    opportunities.append(f"å¸‚å ´æ”¹å–„æ½›åŠ›ï¼š{', '.join(improvement_counties[:2])}ç­‰åœ°å€å…·æœ‰è¼ƒå¤§æ”¹å–„ç©ºé–“")
        
        # æ–°èˆˆç†±é»æ©Ÿæœƒ
        if 'temporal_dynamics' in absorption_analysis_result:
            temporal_data = absorption_analysis_result['temporal_dynamics']
            if 'trend_changes' in temporal_data:
                trend_changes = temporal_data['trend_changes']
                if trend_changes['absorption_rate_change'] > 10:
                    opportunities.append("æ•´é«”å¸‚å ´å‘ˆç¾ä¸Šå‡è¶¨å‹¢ï¼Œé©åˆé€²å ´æ™‚æ©Ÿ")
        
        if not opportunities:
            opportunities.append("å¸‚å ´æ©Ÿæœƒéœ€è¦æ›´è©³ç´°çš„åˆ†æï¼Œå»ºè­°æŒçºŒè§€å¯Ÿå¸‚å ´å‹•æ…‹")
        
        market_insights['opportunities'] = opportunities
        
        print("ğŸ”„ åˆ†æå¸‚å ´å‹•æ…‹...")
        
        # 5. å¸‚å ´å‹•æ…‹åˆ†æ
        market_dynamics = {}
        
        # ä¾›éœ€å¹³è¡¡åˆ†æ
        if len(community_report) > 0:
            total_supply = community_report['ç¸½æˆ¶æ•¸'].sum()
            total_sold = community_report['ç´¯ç©æˆäº¤ç­†æ•¸'].sum()
            total_cancelled = community_report['ç´¯ç©è§£ç´„ç­†æ•¸'].sum()
            
            effective_demand = total_sold - total_cancelled
            market_dynamics['supply_demand'] = {
                'total_supply': total_supply,
                'effective_demand': effective_demand,
                'absorption_ratio': effective_demand / total_supply * 100 if total_supply > 0 else 0,
                'market_balance': 'OVERSUPPLY' if effective_demand / total_supply < 0.3 else 'BALANCED' if effective_demand / total_supply < 0.7 else 'HIGH_DEMAND'
            }
        
        # é€±æœŸæ€§åˆ†æ
        if 'temporal_trends' in absorption_analysis_result:
            temporal_data = absorption_analysis_result['temporal_dynamics']
            if 'seasonal_trends' in temporal_data:
                seasonal_data = temporal_data['seasonal_trends']
                
                # è¨ˆç®—å­£ç¯€æ€§è®ŠåŒ–
                if len(seasonal_data) >= 4:
                    absorption_rates = [item['avg_absorption_rate'] for item in seasonal_data]
                    seasonal_volatility = np.std(absorption_rates) / np.mean(absorption_rates) * 100
                    
                    market_dynamics['seasonality'] = {
                        'volatility': seasonal_volatility,
                        'trend_stability': 'STABLE' if seasonal_volatility < 15 else 'VOLATILE' if seasonal_volatility < 30 else 'HIGHLY_VOLATILE',
                        'recent_trend': 'IMPROVING' if absorption_rates[-1] > absorption_rates[-2] else 'DECLINING'
                    }
        
        # ç«¶çˆ­æ¿€çƒˆåº¦åˆ†æ
        if len(district_report) > 0:
            # è¨ˆç®—å„è¡Œæ”¿å€å»ºæ¡ˆå¯†åº¦
            district_density = district_report.groupby(['ç¸£å¸‚', 'è¡Œæ”¿å€'])['æ´»èºå»ºæ¡ˆæ•¸'].sum()
            high_density_areas = len(district_density[district_density > district_density.quantile(0.8)])
            
            market_dynamics['competition'] = {
                'high_density_areas': high_density_areas,
                'competition_level': 'HIGH' if high_density_areas > len(district_density) * 0.3 else 'MEDIUM' if high_density_areas > len(district_density) * 0.1 else 'LOW',
                'market_concentration': 'DISPERSED' if len(district_report['ç¸£å¸‚'].unique()) > 8 else 'CONCENTRATED'
            }
        
        market_insights['market_dynamics'] = market_dynamics
        
        print("ğŸ”„ ç”Ÿæˆå¸‚å ´å»ºè­°...")
        
        # 6. å¸‚å ´å»ºè­°
        recommendations = []
        
        # åŸºæ–¼æ•´é«”è©•ä¼°çš„å»ºè­°
        if overall_stats['market_health_score'] < 60:
            recommendations.append("å¸‚å ´å¥åº·åº¦åä½ï¼Œå»ºè­°ï¼š(1)åŠ å¼·é¢¨éšªç›£æ§ (2)å„ªåŒ–ç”¢å“å®šä½ (3)èª¿æ•´æ¨æ¡ˆç¯€å¥")
        elif overall_stats['market_health_score'] < 80:
            recommendations.append("å¸‚å ´è¡¨ç¾ä¸­ç­‰ï¼Œå»ºè­°ï¼š(1)æŒçºŒé—œæ³¨å¸‚å ´è®ŠåŒ– (2)å·®ç•°åŒ–ç«¶çˆ­ç­–ç•¥ (3)æå‡å»åŒ–æ•ˆç‡")
        else:
            recommendations.append("å¸‚å ´è¡¨ç¾è‰¯å¥½ï¼Œå»ºè­°ï¼š(1)æŠŠæ¡å¸‚å ´æ©Ÿæœƒ (2)é©åº¦æ“´å¤§è¦æ¨¡ (3)å‰µæ–°ç”¢å“æœå‹™")
        
        # åŸºæ–¼é¢¨éšªé è­¦çš„å»ºè­°
        if len([w for w in risk_warnings if 'è§£ç´„' in w]) > 0:
            recommendations.append("è§£ç´„é¢¨éšªç®¡æ§ï¼š(1)å¼·åŒ–å®¢æˆ¶ä¿¡ç”¨å¯©æŸ¥ (2)å„ªåŒ–ä»˜æ¬¾æ¢ä»¶ (3)å»ºç«‹é è­¦æ©Ÿåˆ¶")
        
        if len([w for w in risk_warnings if 'æ»¯éŠ·' in w]) > 0:
            recommendations.append("æ»¯éŠ·å•é¡Œè™•ç†ï¼š(1)æª¢è¨ç”¢å“å®šä½ (2)èª¿æ•´åƒ¹æ ¼ç­–ç•¥ (3)åŠ å¼·è¡ŒéŠ·æ¨å»£")
        
        # åŸºæ–¼å¸‚å ´æ©Ÿæœƒçš„å»ºè­°
        if len(opportunities) > 1:
            recommendations.append("æ©ŸæœƒæŠŠæ¡ç­–ç•¥ï¼š(1)é‡é»å¸ƒå±€é«˜è¡¨ç¾å€åŸŸ (2)é—œæ³¨åƒ¹æ ¼çªªåœ°æ©Ÿæœƒ (3)åŠ å¼·å¸‚å ´ç ”ç©¶")
        
        # åŸºæ–¼å¸‚å ´å‹•æ…‹çš„å»ºè­°
        if 'supply_demand' in market_dynamics:
            balance = market_dynamics['supply_demand']['market_balance']
            if balance == 'OVERSUPPLY':
                recommendations.append("ä¾›éæ–¼æ±‚å°ç­–ï¼š(1)æ§åˆ¶æ–°å¢ä¾›çµ¦ (2)åŠ å¼·å»åŒ–åŠ›åº¦ (3)è€ƒæ…®é™åƒ¹ä¿ƒéŠ·")
            elif balance == 'HIGH_DEMAND':
                recommendations.append("ä¾›ä¸æ‡‰æ±‚ç­–ç•¥ï¼š(1)é©åº¦å¢åŠ ä¾›çµ¦ (2)å„ªåŒ–ç”¢å“çµ„åˆ (3)æé«˜ç”¢å“æº¢åƒ¹")
        
        # æ”¿ç­–å»ºè­°
        recommendations.append("æ”¿ç­–é…å¥—å»ºè­°ï¼š(1)å®Œå–„é å”®å±‹ç®¡ç†åˆ¶åº¦ (2)åŠ å¼·å¸‚å ´è³‡è¨Šé€æ˜åº¦ (3)å»ºç«‹é¢¨éšªé è­¦æ©Ÿåˆ¶")
        
        market_insights['recommendations'] = recommendations
        
        print("âœ… å¸‚å ´æ´å¯Ÿåˆ†æå®Œæˆ")
        
        return market_insights
    
    except Exception as e:
        print(f"âŒ å¸‚å ´æ´å¯Ÿåˆ†æéŒ¯èª¤: {e}")
        market_insights['error'] = str(e)
        return market_insights

# %%
# åŸ·è¡Œå¸‚å ´æ´å¯Ÿåˆ†æ
market_insights_result = generate_comprehensive_market_insights()

# é¡¯ç¤ºå¸‚å ´æ´å¯Ÿçµæœ
print(f"\nğŸ’¡ å¸‚å ´æ´å¯Ÿåˆ†æçµæœ:")

if 'overall_assessment' in market_insights_result:
    overall_data = market_insights_result['overall_assessment']
    print(f"æ•´é«”å¸‚å ´è©•ä¼°:")
    print(f"   å¸‚å ´å¥åº·åº¦: {overall_data.get('market_health_grade', 'N/A')} (åˆ†æ•¸: {overall_data.get('market_health_score', 0)}/100)")
    print(f"   å¹³å‡å»åŒ–ç‡: {overall_data.get('avg_absorption_rate', 0):.1f}%")
    print(f"   å¹³å‡è§£ç´„ç‡: {overall_data.get('avg_cancellation_rate', 0):.2f}%")
    print(f"   å®Œå”®ç‡: {overall_data.get('completion_rate', 0):.1f}%")

if 'key_findings' in market_insights_result:
    key_findings = market_insights_result['key_findings']
    print(f"\né—œéµç™¼ç¾ ({len(key_findings)} é …):")
    for i, finding in enumerate(key_findings[:5], 1):
        print(f"   {i}. {finding}")

if 'risk_warnings' in market_insights_result:
    risk_warnings = market_insights_result['risk_warnings']
    print(f"\né¢¨éšªé è­¦ ({len(risk_warnings)} é …):")
    for i, warning in enumerate(risk_warnings[:3], 1):
        print(f"   ğŸš¨ {i}. {warning}")

if 'opportunities' in market_insights_result:
    opportunities = market_insights_result['opportunities']
    print(f"\nå¸‚å ´æ©Ÿæœƒ ({len(opportunities)} é …):")
    for i, opportunity in enumerate(opportunities[:3], 1):
        print(f"   ğŸ’¡ {i}. {opportunity}")

if 'recommendations' in market_insights_result:
    recommendations = market_insights_result['recommendations']
    print(f"\nå¸‚å ´å»ºè­° ({len(recommendations)} é …):")
    for i, recommendation in enumerate(recommendations[:4], 1):
        print(f"   ğŸ“‹ {i}. {recommendation}")

# %% [markdown]
# ## 9. æ”¿ç­–å»ºè­°ç”Ÿæˆ

# %%
# æ”¿ç­–å»ºè­°ç”Ÿæˆ
print("ğŸ“‹ æ”¿ç­–å»ºè­°ç”Ÿæˆ")
print("=" * 50)

def generate_policy_recommendations():
    """
    ç”Ÿæˆæ”¿ç­–å»ºè­°
    
    Returns:
        dict: æ”¿ç­–å»ºè­°çµæœ
    """
    
    policy_recommendations = {
        'regulatory_measures': [],
        'market_supervision': [],
        'risk_management': [],
        'industry_development': [],
        'implementation_roadmap': {},
        'success_metrics': {}
    }
    
    try:
        print("ğŸ”„ ç”Ÿæˆç›£ç®¡æªæ–½å»ºè­°...")
        
        # 1. ç›£ç®¡æªæ–½å»ºè­°
        regulatory_measures = []
        
        # åŸºæ–¼è§£ç´„åˆ†æçš„ç›£ç®¡å»ºè­°
        if 'risk_assessment' in cancellation_analysis_result:
            overall_risk = cancellation_analysis_result['risk_assessment'].get('overall_risk_level', 'LOW')
            
            if overall_risk == 'HIGH':
                regulatory_measures.extend([
                    "å»ºç«‹é å”®å±‹è§£ç´„ç‡ä¸Šé™ç®¡åˆ¶æ©Ÿåˆ¶ï¼Œè¶…éé–€æª»å€¼éœ€æäº¤æ”¹å–„è¨ˆç•«",
                    "å¼·åŒ–å»ºå•†è²¡å‹™ç‹€æ³å¯©æŸ¥ï¼Œç¢ºä¿å±¥ç´„èƒ½åŠ›",
                    "å¯¦æ–½é å”®å±‹è²·è³£å¥‘ç´„æ¨™æº–åŒ–ï¼Œä¿è­·æ¶ˆè²»è€…æ¬Šç›Š"
                ])
            elif overall_risk == 'MEDIUM':
                regulatory_measures.extend([
                    "å»ºç«‹è§£ç´„ç‡å®šæœŸç›£æ§æ©Ÿåˆ¶ï¼ŒåŠæ™‚ç™¼ç¾é¢¨éšªå»ºæ¡ˆ",
                    "è¦æ±‚å»ºå•†æä¾›æ›´è©³ç´°çš„å·¥ç¨‹é€²åº¦è³‡è¨Š",
                    "åŠ å¼·é å”®å±‹å»£å‘Šå…§å®¹çœŸå¯¦æ€§æŸ¥æ ¸"
                ])
            else:
                regulatory_measures.extend([
                    "ç¶­æŒç¾æœ‰ç›£ç®¡æ¡†æ¶ï¼ŒæŒçºŒå„ªåŒ–åŸ·è¡Œæ•ˆç‡",
                    "å»ºç«‹æ­£å‘æ¿€å‹µæ©Ÿåˆ¶ï¼Œé¼“å‹µå„ªè³ªå»ºå•†ç™¼å±•"
                ])
        
        # åŸºæ–¼å»åŒ–åˆ†æçš„ç›£ç®¡å»ºè­°
        if 'overall_assessment' in market_insights_result:
            market_health = market_insights_result['overall_assessment'].get('market_health_score', 0)
            
            if market_health < 60:
                regulatory_measures.extend([
                    "å¯¦æ–½é å”®å±‹æ¨æ¡ˆç¯€å¥ç®¡æ§ï¼Œé¿å…å¸‚å ´ä¾›éæ–¼æ±‚",
                    "å»ºç«‹æ»¯éŠ·å»ºæ¡ˆè™•ç†æ©Ÿåˆ¶ï¼Œé˜²ç¯„çˆ›å°¾æ¨“é¢¨éšª",
                    "åŠ å¼·é å”®å±‹åƒ¹æ ¼åˆç†æ€§å¯©æŸ¥"
                ])
        
        # åŸºæ–¼å€åŸŸå·®ç•°çš„ç›£ç®¡å»ºè­°
        if len(city_report) > 1:
            city_std = city_report['ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)'].std()
            if city_std > 20:
                regulatory_measures.append("å»ºç«‹å€åŸŸå·®ç•°åŒ–ç›£ç®¡æ”¿ç­–ï¼Œå› åœ°åˆ¶å®œèª¿æ•´ç®¡ç†æªæ–½")
        
        policy_recommendations['regulatory_measures'] = regulatory_measures
        
        print("ğŸ”„ ç”Ÿæˆå¸‚å ´ç›£ç£å»ºè­°...")
        
        # 2. å¸‚å ´ç›£ç£å»ºè­°
        market_supervision = []
        
        # è³‡è¨Šé€æ˜åº¦æå‡
        market_supervision.extend([
            "å»ºç«‹é å”®å±‹å¸‚å ´è³‡è¨Šå…¬é–‹å¹³å°ï¼Œå®šæœŸç™¼å¸ƒå¸‚å ´çµ±è¨ˆæ•¸æ“š",
            "è¦æ±‚å»ºå•†å…¬é–‹æ›´è©³ç´°çš„éŠ·å”®é€²åº¦å’Œè²¡å‹™ç‹€æ³",
            "å»ºç«‹æ¶ˆè²»è€…æŠ•è¨´è™•ç†å’Œå…¬é–‹æ©Ÿåˆ¶"
        ])
        
        # ç›£ç£æ©Ÿåˆ¶å¼·åŒ–
        market_supervision.extend([
            "å»ºç«‹è·¨éƒ¨é–€è¯åˆç›£ç£æ©Ÿåˆ¶ï¼Œæ•´åˆç›¸é—œç®¡ç†è³‡æº",
            "å¯¦æ–½å»ºæ¡ˆå…¨ç”Ÿå‘½é€±æœŸç›£ç£ï¼Œå¾å¯©æ‰¹åˆ°äº¤å±‹å…¨ç¨‹ç®¡æ§",
            "å»ºç«‹ç¬¬ä¸‰æ–¹ç›£ç£è©•ä¼°æ©Ÿåˆ¶ï¼Œæé«˜ç›£ç£æ•ˆç‡"
        ])
        
        # æ•¸æ“šé©…å‹•ç›£ç£
        market_supervision.extend([
            "å»ºç«‹é å”®å±‹å¸‚å ´å¤§æ•¸æ“šåˆ†æå¹³å°ï¼Œæå‡ç›£ç£ç²¾æº–åº¦",
            "å¯¦æ–½é¢¨éšªé è­¦ç³»çµ±ï¼ŒåŠæ—©è­˜åˆ¥å•é¡Œå»ºæ¡ˆ",
            "å»ºç«‹å¸‚å ´å¥åº·åº¦æŒ‡æ¨™é«”ç³»ï¼Œå®šæœŸè©•ä¼°å¸‚å ´ç‹€æ³"
        ])
        
        policy_recommendations['market_supervision'] = market_supervision
        
        print("ğŸ”„ ç”Ÿæˆé¢¨éšªç®¡ç†å»ºè­°...")
        
        # 3. é¢¨éšªç®¡ç†å»ºè­°
        risk_management = []
        
        # ç³»çµ±æ€§é¢¨éšªé˜²ç¯„
        risk_management.extend([
            "å»ºç«‹é å”®å±‹å¸‚å ´ç³»çµ±æ€§é¢¨éšªç›£æ¸¬æ©Ÿåˆ¶",
            "åˆ¶å®šå¸‚å ´ç•°å¸¸æ³¢å‹•æ‡‰æ€¥é æ¡ˆ",
            "å»ºç«‹å»ºå•†ä¿¡ç”¨è©•ç´šå’Œé»‘åå–®åˆ¶åº¦"
        ])
        
        # æ¶ˆè²»è€…ä¿è­·
        risk_management.extend([
            "å®Œå–„é å”®å±‹å±¥ç´„ä¿è­‰æ©Ÿåˆ¶ï¼Œä¿éšœæ¶ˆè²»è€…æ¬Šç›Š",
            "å»ºç«‹æ¶ˆè²»è€…æ•™è‚²å®£å°é«”ç³»ï¼Œæé«˜é¢¨éšªæ„è­˜",
            "è¨­ç«‹é å”®å±‹ç³¾ç´›èª¿è§£æ©Ÿæ§‹ï¼Œå¿«é€Ÿè™•ç†çˆ­è­°"
        ])
        
        # é‡‘èé¢¨éšªæ§åˆ¶
        risk_management.extend([
            "åŠ å¼·é å”®å±‹è²¸æ¬¾é¢¨éšªç®¡æ§ï¼Œé˜²ç¯„é‡‘èé¢¨éšª",
            "å»ºç«‹å»ºå•†è³‡é‡‘æ± ç›£ç®¡æ©Ÿåˆ¶ï¼Œç¢ºä¿å°ˆæ¬¾å°ˆç”¨",
            "å¯¦æ–½é å”®å±‹ä¿éšªåˆ¶åº¦ï¼Œåˆ†æ•£å¸‚å ´é¢¨éšª"
        ])
        
        policy_recommendations['risk_management'] = risk_management
        
        print("ğŸ”„ ç”Ÿæˆç”¢æ¥­ç™¼å±•å»ºè­°...")
        
        # 4. ç”¢æ¥­ç™¼å±•å»ºè­°
        industry_development = []
        
        # ç”¢æ¥­çµæ§‹å„ªåŒ–
        industry_development.extend([
            "é¼“å‹µå»ºå•†æå‡ç”¢å“å“è³ªå’Œæœå‹™æ°´æº–",
            "æ¨å‹•é å”®å±‹ç”¢æ¥­æ•¸ä½åŒ–è½‰å‹",
            "æ”¯æ´ä¸­å°å‹å»ºå•†å¥åº·ç™¼å±•"
        ])
        
        # å‰µæ–°æ©Ÿåˆ¶æ¨å‹•
        industry_development.extend([
            "æ¨å‹•é å”®å±‹ç”¢å“å‰µæ–°å’Œæœå‹™æ¨¡å¼å‰µæ–°",
            "å»ºç«‹å„ªè³ªå»ºå•†èªè­‰å’Œçå‹µæ©Ÿåˆ¶",
            "é¼“å‹µç¶ å»ºç¯‰å’Œæ™ºæ…§å»ºç¯‰ç™¼å±•"
        ])
        
        # å¸‚å ´ç’°å¢ƒæ”¹å–„
        industry_development.extend([
            "å®Œå–„é å”®å±‹ç›¸é—œæ³•è¦é«”ç³»",
            "æå‡è¡Œæ”¿å¯©æ‰¹æ•ˆç‡å’Œæœå‹™å“è³ª",
            "å»ºç«‹å…¬å¹³ç«¶çˆ­çš„å¸‚å ´ç’°å¢ƒ"
        ])
        
        policy_recommendations['industry_development'] = industry_development
        
        print("ğŸ”„ åˆ¶å®šå¯¦æ–½è·¯ç·šåœ–...")
        
        # 5. å¯¦æ–½è·¯ç·šåœ–
        implementation_roadmap = {
            'short_term': {  # 3-6å€‹æœˆ
                'period': 'çŸ­æœŸ (3-6å€‹æœˆ)',
                'priorities': [
                    "å»ºç«‹é å”®å±‹å¸‚å ´ç›£æ§Dashboard",
                    "åˆ¶å®šè§£ç´„ç‡é è­¦æ©Ÿåˆ¶",
                    "å•Ÿå‹•è³‡è¨Šå…¬é–‹å¹³å°å»ºè¨­",
                    "å®Œå–„ç¾æœ‰æ³•è¦åŸ·è¡Œ"
                ]
            },
            'medium_term': {  # 6-18å€‹æœˆ
                'period': 'ä¸­æœŸ (6-18å€‹æœˆ)',
                'priorities': [
                    "å¯¦æ–½å»ºå•†ä¿¡ç”¨è©•ç´šåˆ¶åº¦",
                    "å»ºç«‹å€åŸŸå·®ç•°åŒ–ç›£ç®¡æ”¿ç­–",
                    "æ¨å‹•é å”®å±‹æ•¸ä½åŒ–ç®¡ç†",
                    "å¼·åŒ–è·¨éƒ¨é–€å”èª¿æ©Ÿåˆ¶"
                ]
            },
            'long_term': {  # 18å€‹æœˆä»¥ä¸Š
                'period': 'é•·æœŸ (18å€‹æœˆä»¥ä¸Š)',
                'priorities': [
                    "å»ºç«‹å®Œæ•´çš„é¢¨éšªé è­¦é«”ç³»",
                    "æ¨å‹•ç”¢æ¥­çµæ§‹å‡ç´š",
                    "å®Œå–„æ¶ˆè²»è€…ä¿è­·æ©Ÿåˆ¶",
                    "å»ºç«‹åœ‹éš›å…ˆé€²ç®¡ç†æ¨™æº–"
                ]
            }
        }
        
        policy_recommendations['implementation_roadmap'] = implementation_roadmap
        
        print("ğŸ”„ è¨­å®šæˆåŠŸæŒ‡æ¨™...")
        
        # 6. æˆåŠŸæŒ‡æ¨™
        success_metrics = {
            'market_stability': {
                'indicator': 'å¸‚å ´ç©©å®šæ€§æŒ‡æ¨™',
                'targets': {
                    'è§£ç´„ç‡æ§åˆ¶': 'å…¨å¸‚å ´å¹³å‡è§£ç´„ç‡ < 2%',
                    'å»åŒ–ç‡æå‡': 'å¹³å‡å»åŒ–ç‡ > 50%',
                    'å®Œå”®ç‡æ”¹å–„': 'å»ºæ¡ˆå®Œå”®ç‡ > 15%',
                    'é¢¨éšªå»ºæ¡ˆæ¸›å°‘': 'é«˜é¢¨éšªå»ºæ¡ˆæ¯”ä¾‹ < 10%'
                }
            },
            'consumer_protection': {
                'indicator': 'æ¶ˆè²»è€…ä¿è­·æŒ‡æ¨™',
                'targets': {
                    'æŠ•è¨´è™•ç†': 'æ¶ˆè²»è€…æŠ•è¨´è™•ç†ç‡ > 95%',
                    'ç³¾ç´›è§£æ±º': 'ç³¾ç´›èª¿è§£æˆåŠŸç‡ > 80%',
                    'è³‡è¨Šé€æ˜': 'è³‡è¨Šå…¬é–‹è¦†è“‹ç‡ > 90%',
                    'æ»¿æ„åº¦æå‡': 'æ¶ˆè²»è€…æ»¿æ„åº¦ > 85%'
                }
            },
            'industry_development': {
                'indicator': 'ç”¢æ¥­ç™¼å±•æŒ‡æ¨™',
                'targets': {
                    'ç”¢æ¥­é›†ä¸­åº¦': 'æå‡å„ªè³ªå»ºå•†å¸‚å ç‡',
                    'å‰µæ–°èƒ½åŠ›': 'æ•¸ä½åŒ–æ‡‰ç”¨æ™®åŠç‡ > 70%',
                    'æœå‹™å“è³ª': 'å»ºå•†æœå‹™è©•ç´šæå‡',
                    'ç«¶çˆ­ç’°å¢ƒ': 'å¸‚å ´ç«¶çˆ­æŒ‡æ•¸æ”¹å–„'
                }
            },
            'regulatory_effectiveness': {
                'indicator': 'ç›£ç®¡æ•ˆèƒ½æŒ‡æ¨™',
                'targets': {
                    'ç›£ç£è¦†è“‹': 'ç›£ç£æª¢æŸ¥è¦†è“‹ç‡ > 90%',
                    'é•è¦è™•ç†': 'é•è¦æ¡ˆä»¶è™•ç†ç‡ > 95%',
                    'é è­¦æº–ç¢º': 'é¢¨éšªé è­¦æº–ç¢ºç‡ > 80%',
                    'æ•ˆç‡æå‡': 'è¡Œæ”¿è™•ç†æ™‚é–“ç¸®çŸ­ > 30%'
                }
            }
        }
        
        policy_recommendations['success_metrics'] = success_metrics
        
        print("âœ… æ”¿ç­–å»ºè­°ç”Ÿæˆå®Œæˆ")
        
        return policy_recommendations
    
    except Exception as e:
        print(f"âŒ æ”¿ç­–å»ºè­°ç”ŸæˆéŒ¯èª¤: {e}")
        policy_recommendations['error'] = str(e)
        return policy_recommendations

# %%
# åŸ·è¡Œæ”¿ç­–å»ºè­°ç”Ÿæˆ
policy_recommendations_result = generate_policy_recommendations()

# é¡¯ç¤ºæ”¿ç­–å»ºè­°çµæœ
print(f"\nğŸ“‹ æ”¿ç­–å»ºè­°ç”Ÿæˆçµæœ:")

if 'regulatory_measures' in policy_recommendations_result:
    regulatory_measures = policy_recommendations_result['regulatory_measures']
    print(f"ç›£ç®¡æªæ–½å»ºè­° ({len(regulatory_measures)} é …):")
    for i, measure in enumerate(regulatory_measures[:3], 1):
        print(f"   {i}. {measure}")

if 'market_supervision' in policy_recommendations_result:
    market_supervision = policy_recommendations_result['market_supervision']
    print(f"\nå¸‚å ´ç›£ç£å»ºè­° ({len(market_supervision)} é …):")
    for i, supervision in enumerate(market_supervision[:3], 1):
        print(f"   {i}. {supervision}")

if 'risk_management' in policy_recommendations_result:
    risk_management = policy_recommendations_result['risk_management']
    print(f"\né¢¨éšªç®¡ç†å»ºè­° ({len(risk_management)} é …):")
    for i, risk_measure in enumerate(risk_management[:3], 1):
        print(f"   {i}. {risk_measure}")

if 'implementation_roadmap' in policy_recommendations_result:
    roadmap = policy_recommendations_result['implementation_roadmap']
    print(f"\nå¯¦æ–½è·¯ç·šåœ–:")
    for phase, details in roadmap.items():
        print(f"   {details['period']}:")
        for priority in details['priorities'][:2]:
            print(f"     â€¢ {priority}")

# %% [markdown]
# ## 10. äº’å‹•å¼DashboardåŸå‹

# %%
# äº’å‹•å¼DashboardåŸå‹
print("ğŸ“Š äº’å‹•å¼DashboardåŸå‹é–‹ç™¼")
print("=" * 50)

def create_interactive_dashboard_prototype():
    """
    å‰µå»ºäº’å‹•å¼DashboardåŸå‹
    
    Returns:
        dict: Dashboardçµ„ä»¶
    """
    
    print("ğŸ”„ é–‹ç™¼äº’å‹•å¼DashboardåŸå‹...")
    
    dashboard_components = {}
    
    try:
        # 1. ä¸»è¦KPIæŒ‡æ¨™æ¿
        print("ğŸ”„ å‰µå»ºKPIæŒ‡æ¨™æ¿...")
        
        # æº–å‚™KPIæ•¸æ“š
        kpi_data = {
            'total_projects': len(community_report),
            'avg_absorption_rate': community_report['æ·¨å»åŒ–ç‡(%)'].mean(),
            'avg_cancellation_rate': community_report['ç´¯ç©è§£ç´„ç‡(%)'].mean(),
            'completion_rate': len(community_report[community_report['æ·¨å»åŒ–ç‡(%)'] >= 100]) / len(community_report) * 100,
            'high_risk_projects': len(community_report[community_report['ç´¯ç©è§£ç´„ç‡(%)'] > 5]),
            'active_districts': len(district_report[district_report['æ´»èºå»ºæ¡ˆæ•¸'] > 0]),
            'total_counties': len(city_report),
            'market_health_score': market_insights_result.get('overall_assessment', {}).get('market_health_score', 0)
        }
        
        # å‰µå»ºKPIå„€è¡¨æ¿
        kpi_fig = make_subplots(
            rows=2, cols=4,
            subplot_titles=[
                'ç¸½å»ºæ¡ˆæ•¸', 'å¹³å‡å»åŒ–ç‡', 'å¹³å‡è§£ç´„ç‡', 'å®Œå”®ç‡',
                'é«˜é¢¨éšªå»ºæ¡ˆ', 'æ´»èºè¡Œæ”¿å€', 'ç¸½ç¸£å¸‚æ•¸', 'å¸‚å ´å¥åº·åº¦'
            ],
            specs=[[{"type": "indicator"}]*4, [{"type": "indicator"}]*4],
            vertical_spacing=0.3
        )
        
        # æ·»åŠ KPIæŒ‡æ¨™
        indicators_config = [
            (kpi_data['total_projects'], "ç¸½å»ºæ¡ˆæ•¸", "å€‹", 1, 1),
            (kpi_data['avg_absorption_rate'], "å¹³å‡å»åŒ–ç‡", "%", 1, 2),
            (kpi_data['avg_cancellation_rate'], "å¹³å‡è§£ç´„ç‡", "%", 1, 3),
            (kpi_data['completion_rate'], "å®Œå”®ç‡", "%", 1, 4),
            (kpi_data['high_risk_projects'], "é«˜é¢¨éšªå»ºæ¡ˆ", "å€‹", 2, 1),
            (kpi_data['active_districts'], "æ´»èºè¡Œæ”¿å€", "å€‹", 2, 2),
            (kpi_data['total_counties'], "ç¸½ç¸£å¸‚æ•¸", "å€‹", 2, 3),
            (kpi_data['market_health_score'], "å¸‚å ´å¥åº·åº¦", "åˆ†", 2, 4)
        ]
        
        for value, title, unit, row, col in indicators_config:
            # è¨­å®šé¡è‰²åŸºæ–¼å€¼çš„ç¯„åœ
            if 'ç‡' in title:
                color = "green" if value >= 50 else "orange" if value >= 30 else "red"
            elif 'å¥åº·åº¦' in title:
                color = "green" if value >= 80 else "orange" if value >= 60 else "red"
            else:
                color = "blue"
            
            kpi_fig.add_trace(
                go.Indicator(
                    mode="number",
                    value=value,
                    title={"text": f"{title}<br><span style='font-size:0.8em;color:gray'>{unit}</span>"},
                    number={"font": {"size": 40, "color": color}},
                    domain={'row': row-1, 'column': col-1}
                ),
                row=row, col=col
            )
        
        kpi_fig.update_layout(
            title_text="é å”®å±‹å¸‚å ´é—œéµæŒ‡æ¨™Dashboard",
            title_x=0.5,
            height=400
        )
        
        dashboard_components['kpi_dashboard'] = kpi_fig
        
        # 2. é¢¨éšªç›£æ§é¢æ¿
        print("ğŸ”„ å‰µå»ºé¢¨éšªç›£æ§é¢æ¿...")
        
        risk_fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=['é¢¨éšªç­‰ç´šåˆ†å¸ƒ', 'è§£ç´„ç‡è¶¨å‹¢', 'é«˜é¢¨éšªå€åŸŸåˆ†å¸ƒ', 'é¢¨éšªé è­¦ç‡ˆè™Ÿ'],
            specs=[
                [{"type": "pie"}, {"type": "scatter"}],
                [{"type": "bar"}, {"type": "indicator"}]
            ]
        )
        
        # é¢¨éšªç­‰ç´šåˆ†å¸ƒ
        if 'è§£ç´„è­¦ç¤º' in community_report.columns:
            risk_dist = community_report['è§£ç´„è­¦ç¤º'].value_counts()
            colors = ['green' if 'ğŸŸ¢' in str(idx) else 'orange' if 'ğŸŸ¡' in str(idx) else 'red' for idx in risk_dist.index]
            
            risk_fig.add_trace(
                go.Pie(
                    labels=risk_dist.index,
                    values=risk_dist.values,
                    marker_colors=colors,
                    name="é¢¨éšªåˆ†å¸ƒ"
                ),
                row=1, col=1
            )
        
        # è§£ç´„ç‡è¶¨å‹¢
        if 'temporal_trends' in cancellation_analysis_result:
            temporal_data = cancellation_analysis_result['temporal_trends']
            seasons = [item['season'] for item in temporal_data]
            cancellation_rates = [item['avg_cancellation_rate'] for item in temporal_data]
            
            risk_fig.add_trace(
                go.Scatter(
                    x=seasons,
                    y=cancellation_rates,
                    mode='lines+markers',
                    name='è§£ç´„ç‡è¶¨å‹¢',
                    line=dict(color='red', width=3)
                ),
                row=1, col=2
            )
        
        # é«˜é¢¨éšªå€åŸŸåˆ†å¸ƒ
        high_risk_counties = community_report[community_report['ç´¯ç©è§£ç´„ç‡(%)'] > 5]['ç¸£å¸‚'].value_counts().head(8)
        if not high_risk_counties.empty:
            risk_fig.add_trace(
                go.Bar(
                    x=high_risk_counties.index,
                    y=high_risk_counties.values,
                    marker_color='red',
                    name='é«˜é¢¨éšªå»ºæ¡ˆæ•¸'
                ),
                row=2, col=1
            )
        
        # é¢¨éšªé è­¦ç‡ˆè™Ÿ
        overall_risk_score = kpi_data['market_health_score']
        risk_level = "HIGH" if overall_risk_score < 60 else "MEDIUM" if overall_risk_score < 80 else "LOW"
        risk_color = "red" if risk_level == "HIGH" else "orange" if risk_level == "MEDIUM" else "green"
        
        risk_fig.add_trace(
            go.Indicator(
                mode="gauge+number",
                value=100 - overall_risk_score,  # é¢¨éšªåˆ†æ•¸èˆ‡å¥åº·åº¦ç›¸å
                title={'text': "æ•´é«”é¢¨éšªç­‰ç´š"},
                gauge={
                    'axis': {'range': [None, 100]},
                    'bar': {'color': risk_color},
                    'steps': [
                        {'range': [0, 20], 'color': "lightgreen"},
                        {'range': [20, 40], 'color': "yellow"},
                        {'range': [40, 100], 'color': "lightcoral"}
                    ]
                }
            ),
            row=2, col=2
        )
        
        risk_fig.update_layout(
            title_text="é¢¨éšªç›£æ§é¢æ¿",
            title_x=0.5,
            height=600,
            showlegend=False
        )
        
        dashboard_components['risk_dashboard'] = risk_fig
        
        # 3. å¸‚å ´è¡¨ç¾åˆ†æé¢æ¿
        print("ğŸ”„ å‰µå»ºå¸‚å ´è¡¨ç¾åˆ†æé¢æ¿...")
        
        performance_fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=['ç¸£å¸‚è¡¨ç¾æ’å', 'å»åŒ–æ•ˆç‡åˆ†å¸ƒ', 'ç†±é»å€åŸŸåœ°åœ–', 'å¸‚å ´è¶¨å‹¢åˆ†æ'],
            specs=[
                [{"type": "bar"}, {"type": "histogram"}],
                [{"type": "scatter"}, {"type": "scatter"}]
            ]
        )
        
        # ç¸£å¸‚è¡¨ç¾æ’å
        if len(city_report) > 0:
            top_cities = city_report.nlargest(8, 'ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)')
            performance_fig.add_trace(
                go.Bar(
                    x=top_cities['ç¸£å¸‚'],
                    y=top_cities['ç¸£å¸‚åŠ æ¬Šå»åŒ–ç‡(%)'],
                    marker_color='lightblue',
                    name='ç¸£å¸‚å»åŒ–ç‡'
                ),
                row=1, col=1
            )
        
        # å»åŒ–æ•ˆç‡åˆ†å¸ƒ
        absorption_rates = community_report['æ·¨å»åŒ–ç‡(%)'][community_report['æ·¨å»åŒ–ç‡(%)'] >= 0]
        performance_fig.add_trace(
            go.Histogram(
                x=absorption_rates,
                nbinsx=20,
                marker_color='lightgreen',
                name='å»åŒ–ç‡åˆ†å¸ƒ'
            ),
            row=1, col=2
        )
        
        # ç†±é»å€åŸŸåœ°åœ–ï¼ˆæ•£é»åœ–æ¨¡æ“¬ï¼‰
        if len(district_report) > 0:
            performance_fig.add_trace(
                go.Scatter(
                    x=district_report['æ•´é«”æ·¨å»åŒ–ç‡(%)'],
                    y=district_report['å€åŸŸå¹³å‡å»åŒ–é€Ÿåº¦(æˆ¶/å­£)'],
                    mode='markers',
                    marker=dict(
                        size=8,
                        color=district_report['æ•´é«”æ·¨å»åŒ–ç‡(%)'],
                        colorscale='Viridis',
                        showscale=True
                    ),
                    text=district_report['ç¸£å¸‚'] + '-' + district_report['è¡Œæ”¿å€'],
                    name='è¡Œæ”¿å€è¡¨ç¾'
                ),
                row=2, col=1
            )
        
        # å¸‚å ´è¶¨å‹¢åˆ†æ
        if 'temporal_dynamics' in absorption_analysis_result:
            temporal_data = absorption_analysis_result['temporal_dynamics']
            if 'seasonal_trends' in temporal_data:
                seasonal_data = temporal_data['seasonal_trends']
                seasons = [item['season'] for item in seasonal_data]
                absorption_rates = [item['avg_absorption_rate'] for item in seasonal_data]
                
                performance_fig.add_trace(
                    go.Scatter(
                        x=seasons,
                        y=absorption_rates,
                        mode='lines+markers',
                        name='å¸‚å ´è¶¨å‹¢',
                        line=dict(color='blue', width=3)
                    ),
                    row=2, col=2
                )
        
        performance_fig.update_layout(
            title_text="å¸‚å ´è¡¨ç¾åˆ†æé¢æ¿",
            title_x=0.5,
            height=600
        )
        
        dashboard_components['performance_dashboard'] = performance_fig
        
        print("âœ… äº’å‹•å¼DashboardåŸå‹é–‹ç™¼å®Œæˆ")
        
        return dashboard_components
    
    except Exception as e:
        print(f"âŒ Dashboardé–‹ç™¼éŒ¯èª¤: {e}")
        return dashboard_components

# %%
# å‰µå»ºäº’å‹•å¼Dashboard
dashboard_components = create_interactive_dashboard_prototype()

# é¡¯ç¤ºDashboardçµ„ä»¶
for name, fig in dashboard_components.items():
    print(f"\nğŸ”„ é¡¯ç¤º {name}...")
    fig.show()

print(f"\nâœ… äº’å‹•å¼DashboardåŸå‹å±•ç¤ºå®Œæˆ")
print(f"åŒ…å«çµ„ä»¶: {list(dashboard_components.keys())}")

# %% [markdown]
# ## 11. åˆ†æå ±å‘Šç”Ÿæˆ

# %%
# åˆ†æå ±å‘Šç”Ÿæˆ
print("ğŸ“‹ åˆ†æå ±å‘Šç”Ÿæˆ")
print("=" * 50)

def generate_comprehensive_analysis_report():
    """
    ç”Ÿæˆç¶œåˆåˆ†æå ±å‘Š
    
    Returns:
        dict: å®Œæ•´åˆ†æå ±å‘Š
    """
    
    print("ğŸ”„ ç”Ÿæˆç¶œåˆåˆ†æå ±å‘Š...")
    
    analysis_report = {
        'executive_summary': {},
        'detailed_analysis': {},
        'visualizations': {},
        'insights_and_recommendations': {},
        'appendices': {}
    }
    
    try:
        # 1. åŸ·è¡Œæ‘˜è¦
        print("ğŸ”„ ç”ŸæˆåŸ·è¡Œæ‘˜è¦...")
        
        executive_summary = {
            'report_metadata': {
                'title': 'é å”®å±‹å¸‚å ´é¢¨éšªåˆ†æç³»çµ± - è§£ç´„èˆ‡å»åŒ–å‹•æ…‹å°ˆé …åˆ†æå ±å‘Š',
                'version': 'v1.0',
                'generation_date': datetime.now().strftime('%Y-%m-%d'),
                'analysis_period': f"{community_report['å¹´å­£'].min()} ~ {community_report['å¹´å­£'].max()}",
                'data_coverage': {
                    'total_projects': len(community_report),
                    'total_districts': len(district_report),
                    'total_counties': len(city_report),
                    'seasons_analyzed': len(community_report['å¹´å­£'].unique())
                }
            },
            'key_highlights': [],
            'main_conclusions': [],
            'critical_risks': [],
            'strategic_recommendations': []
        }
        
        # é—œéµäº®é»
        if 'overall_assessment' in market_insights_result:
            market_health = market_insights_result['overall_assessment'].get('market_health_score', 0)
            avg_absorption = market_insights_result['overall_assessment'].get('avg_absorption_rate', 0)
            avg_cancellation = market_insights_result['overall_assessment'].get('avg_cancellation_rate', 0)
            
            executive_summary['key_highlights'] = [
                f"å¸‚å ´å¥åº·åº¦è©•åˆ†: {market_health}/100ï¼Œç­‰ç´šç‚º{market_insights_result['overall_assessment'].get('market_health_grade', 'N/A')}",
                f"æ•´é«”å¹³å‡å»åŒ–ç‡: {avg_absorption:.1f}%ï¼Œé¡¯ç¤ºå¸‚å ´{'æ´»èº' if avg_absorption > 50 else 'ç©©å®š' if avg_absorption > 30 else 'éœ€é—œæ³¨'}",
                f"æ•´é«”å¹³å‡è§£ç´„ç‡: {avg_cancellation:.2f}%ï¼Œé¢¨éšªæ§åˆ¶{'è‰¯å¥½' if avg_cancellation < 2 else 'ä¸€èˆ¬' if avg_cancellation < 5 else 'éœ€åŠ å¼·'}",
                f"å®Œå”®å»ºæ¡ˆæ¯”ä¾‹: {market_insights_result['overall_assessment'].get('completion_rate', 0):.1f}%",
                f"æ¶µè“‹åˆ†æç¯„åœ: {len(city_report)}å€‹ç¸£å¸‚ã€{len(district_report)}å€‹è¡Œæ”¿å€ã€{len(community_report):,}å€‹å»ºæ¡ˆ"
            ]
        
        # ä¸»è¦çµè«–
        if 'key_findings' in market_insights_result:
            executive_summary['main_conclusions'] = market_insights_result['key_findings'][:4]
        
        # é—œéµé¢¨éšª
        if 'risk_warnings' in market_insights_result:
            executive_summary['critical_risks'] = market_insights_result['risk_warnings'][:3]
        
        # æˆ°ç•¥å»ºè­°
        if 'recommendations' in market_insights_result:
            executive_summary['strategic_recommendations'] = market_insights_result['recommendations'][:4]
        
        analysis_report['executive_summary'] = executive_summary
        
        # 2. è©³ç´°åˆ†æ
        print("ğŸ”„ æ•´ç†è©³ç´°åˆ†æ...")
        
        detailed_analysis = {
            'cancellation_analysis': cancellation_analysis_result,
            'absorption_analysis': absorption_analysis_result,
            'efficiency_analysis': efficiency_analysis_result,
            'market_insights': market_insights_result,
            'policy_recommendations': policy_recommendations_result
        }
        
        analysis_report['detailed_analysis'] = detailed_analysis
        
        # 3. è¦–è¦ºåŒ–æˆæœ
        print("ğŸ”„ è¨˜éŒ„è¦–è¦ºåŒ–æˆæœ...")
        
        visualizations = {
            'dashboard_components': list(dashboard_components.keys()),
            'chart_types': [
                'é¢¨éšªé è­¦ç¶œåˆDashboard',
                'ç†±é»å€åŸŸåˆ†æè¦–è¦ºåŒ–',
                'ä¸‰å±¤ç´šå°æ¯”åˆ†æ',
                'KPIæŒ‡æ¨™æ¿',
                'é¢¨éšªç›£æ§é¢æ¿',
                'å¸‚å ´è¡¨ç¾åˆ†æé¢æ¿'
            ],
            'key_visualizations': {
                'risk_warning': 'å±•ç¤ºç¸£å¸‚é¢¨éšªåˆ†å¸ƒã€è§£ç´„ç‡è¶¨å‹¢ã€é«˜é¢¨éšªå€åŸŸæ’åç­‰',
                'hotspot_analysis': 'é¡¯ç¤ºå»åŒ–è¡¨ç¾æ’åã€æ•ˆç‡è©•ç´šåˆ†å¸ƒã€ç«¶çˆ­åŠ›æŒ‡æ•¸ç­‰',
                'three_level_comparison': 'å°æ¯”ç¤¾å€ç´šã€è¡Œæ”¿å€ç´šã€ç¸£å¸‚ç´šæŒ‡æ¨™åˆ†å¸ƒ',
                'interactive_dashboard': 'æä¾›å³æ™‚ç›£æ§å’Œäº’å‹•å¼åˆ†æåŠŸèƒ½'
            }
        }
        
        analysis_report['visualizations'] = visualizations
        
        # 4. æ´å¯Ÿèˆ‡å»ºè­°
        print("ğŸ”„ æ•´åˆæ´å¯Ÿèˆ‡å»ºè­°...")
        
        insights_and_recommendations = {
            'market_insights': market_insights_result,
            'policy_recommendations': {
                'regulatory_framework': policy_recommendations_result.get('regulatory_measures', [])[:3],
                'supervision_enhancement': policy_recommendations_result.get('market_supervision', [])[:3],
                'risk_management': policy_recommendations_result.get('risk_management', [])[:3],
                'industry_development': policy_recommendations_result.get('industry_development', [])[:3]
            },
            'implementation_roadmap': policy_recommendations_result.get('implementation_roadmap', {}),
            'success_metrics': policy_recommendations_result.get('success_metrics', {})
        }
        
        analysis_report['insights_and_recommendations'] = insights_and_recommendations
        
        # 5. é™„éŒ„
        print("ğŸ”„ æº–å‚™é™„éŒ„è³‡æ–™...")
        
        appendices = {
            'methodology': {
                'data_sources': [
                    'lvr_pre_sale_test.csv (é å”®å±‹æˆäº¤è¨˜éŒ„)',
                    'lvr_sale_data_test.csv (å»ºæ¡ˆåŸºæœ¬è³‡è¨Š)',
                    'ä¸‰å±¤ç´šèšåˆåˆ†æçµæœ'
                ],
                'analysis_methods': [
                    'è§£ç´„è¶¨å‹¢æ™‚é–“åºåˆ—åˆ†æ',
                    'å»åŒ–é€Ÿåº¦çµ±è¨ˆåˆ†æ',
                    'æ•ˆç‡æ’åæ¯”è¼ƒåˆ†æ',
                    'é¢¨éšªè©•ä¼°æ¨¡å‹',
                    'å¸‚å ´èšé¡åˆ†æ',
                    'K-meansèšé¡ç®—æ³•',
                    'ç›¸é—œæ€§åˆ†æ'
                ],
                'quality_controls': [
                    'ä¸‰å±¤ç´šè³‡æ–™ä¸€è‡´æ€§æª¢æŸ¥',
                    'ç•°å¸¸å€¼éæ¿¾èˆ‡è™•ç†',
                    'è¨ˆç®—é‚è¼¯é©—è­‰',
                    'çµæœåˆç†æ€§æª¢æŸ¥'
                ]
            },
            'data_quality': {
                'completeness': f"é—œéµæ¬„ä½å®Œæ•´åº¦ > 95%",
                'accuracy': f"è¨ˆç®—æº–ç¢ºæ€§é©—è­‰é€šé",
                'consistency': f"ä¸‰å±¤ç´šä¸€è‡´æ€§æª¢æŸ¥é€šé",
                'timeliness': f"è³‡æ–™æ¶µè“‹{len(community_report['å¹´å­£'].unique())}å€‹å¹´å­£"
            },
            'technical_specifications': {
                'development_environment': 'Python 3.8+, Pandas, NumPy, Plotly, Scikit-learn',
                'analysis_libraries': 'Matplotlib, Seaborn, Scipy',
                'dashboard_framework': 'Plotly Dash (åŸå‹)',
                'data_processing': 'ç¤¾å€ç´šâ†’è¡Œæ”¿å€ç´šâ†’ç¸£å¸‚ç´šä¸‰å±¤ç´šèšåˆ',
                'visualization_engine': 'Plotly Interactive Charts'
            },
            'limitations_and_assumptions': [
                'æ¸¬è©¦è³‡æ–™ç¯„åœé™åˆ¶ï¼Œæ­£å¼ç’°å¢ƒéœ€æ“´å¤§æ¨£æœ¬',
                'é å”®å±‹å¸‚å ´å—å¤šç¨®å¤–éƒ¨å› ç´ å½±éŸ¿ï¼Œåˆ†æçµæœéœ€çµåˆå¸‚å ´ç’°å¢ƒè§£è®€',
                'é¢¨éšªè©•ä¼°æ¨¡å‹åŸºæ–¼æ­·å²è³‡æ–™ï¼Œæœªä¾†è¡¨ç¾å¯èƒ½å—æ”¿ç­–è®ŠåŒ–å½±éŸ¿',
                'éƒ¨åˆ†å»ºæ¡ˆè³‡æ–™å¯èƒ½å­˜åœ¨æ™‚é–“å»¶é²æˆ–æ›´æ–°ä¸åŠæ™‚æƒ…æ³'
            ]
        }
        
        analysis_report['appendices'] = appendices
        
        print("âœ… ç¶œåˆåˆ†æå ±å‘Šç”Ÿæˆå®Œæˆ")
        
        return analysis_report
    
    except Exception as e:
        print(f"âŒ å ±å‘Šç”ŸæˆéŒ¯èª¤: {e}")
        analysis_report['error'] = str(e)
        return analysis_report

# %%
# ç”Ÿæˆç¶œåˆåˆ†æå ±å‘Š
comprehensive_report = generate_comprehensive_analysis_report()

# é¡¯ç¤ºå ±å‘Šæ‘˜è¦
print(f"\nğŸ“‹ ç¶œåˆåˆ†æå ±å‘Šæ‘˜è¦:")

if 'executive_summary' in comprehensive_report:
    summary = comprehensive_report['executive_summary']
    
    # å ±å‘ŠåŸºæœ¬è³‡è¨Š
    if 'report_metadata' in summary:
        metadata = summary['report_metadata']
        print(f"å ±å‘Šè³‡è¨Š:")
        print(f"   æ¨™é¡Œ: {metadata['title']}")
        print(f"   ç‰ˆæœ¬: {metadata['version']}")
        print(f"   ç”Ÿæˆæ—¥æœŸ: {metadata['generation_date']}")
        print(f"   åˆ†ææœŸé–“: {metadata['analysis_period']}")
        
        data_coverage = metadata['data_coverage']
        print(f"   è³‡æ–™æ¶µè“‹: {data_coverage['total_projects']:,}å€‹å»ºæ¡ˆ, {data_coverage['total_districts']}å€‹è¡Œæ”¿å€, {data_coverage['total_counties']}å€‹ç¸£å¸‚")
    
    # é—œéµäº®é»
    if 'key_highlights' in summary:
        highlights = summary['key_highlights']
        print(f"\né—œéµäº®é»:")
        for i, highlight in enumerate(highlights[:3], 1):
            print(f"   {i}. {highlight}")
    
    # ä¸»è¦çµè«–
    if 'main_conclusions' in summary:
        conclusions = summary['main_conclusions']
        print(f"\nä¸»è¦çµè«–:")
        for i, conclusion in enumerate(conclusions[:3], 1):
            print(f"   {i}. {conclusion}")
    
    # é—œéµé¢¨éšª
    if 'critical_risks' in summary:
        risks = summary['critical_risks']
        print(f"\né—œéµé¢¨éšª:")
        for i, risk in enumerate(risks, 1):
            print(f"   {i}. {risk}")

# åˆ†ææ¨¡çµ„å®Œæˆåº¦çµ±è¨ˆ
if 'detailed_analysis' in comprehensive_report:
    analysis_modules = comprehensive_report['detailed_analysis']
    print(f"\nåˆ†ææ¨¡çµ„å®Œæˆåº¦:")
    for module, data in analysis_modules.items():
        status = "âœ… å®Œæˆ" if data and not data.get('error') else "âŒ éŒ¯èª¤"
        print(f"   {module}: {status}")

# è¦–è¦ºåŒ–æˆæœçµ±è¨ˆ
if 'visualizations' in comprehensive_report:
    viz_data = comprehensive_report['visualizations']
    print(f"\nè¦–è¦ºåŒ–æˆæœ:")
    print(f"   Dashboardçµ„ä»¶: {len(viz_data['dashboard_components'])} å€‹")
    print(f"   åœ–è¡¨é¡å‹: {len(viz_data['chart_types'])} ç¨®")

# %% [markdown]
# ## 12. çµæœè¼¸å‡ºèˆ‡ç¸½çµ

# %%
# å„²å­˜å®Œæ•´åˆ†æçµæœ
print("ğŸ’¾ å„²å­˜å®Œæ•´åˆ†æçµæœ")
print("=" * 50)

try:
    current_date = datetime.now().strftime("%Y%m%d")
    current_time = datetime.now().strftime("%H%M%S")
    
    # 1. å„²å­˜è§£ç´„è¶¨å‹¢åˆ†æçµæœ
    cancellation_filename = f'cancellation_trend_analysis_{current_date}.json'
    with open(f'../data/processed/{cancellation_filename}', 'w', encoding='utf-8') as f:
        json.dump(cancellation_analysis_result, f, ensure_ascii=False, indent=2, default=str)
    print(f"âœ… è§£ç´„è¶¨å‹¢åˆ†æçµæœå·²å„²å­˜: {cancellation_filename}")
    
    # 2. å„²å­˜å»åŒ–é€Ÿåº¦åˆ†æçµæœ
    absorption_filename = f'absorption_speed_analysis_{current_date}.json'
    with open(f'../data/processed/{absorption_filename}', 'w', encoding='utf-8') as f:
        json.dump(absorption_analysis_result, f, ensure_ascii=False, indent=2, default=str)
    print(f"âœ… å»åŒ–é€Ÿåº¦åˆ†æçµæœå·²å„²å­˜: {absorption_filename}")
    
    # 3. å„²å­˜æ•ˆç‡æ’ååˆ†æçµæœ
    efficiency_filename = f'efficiency_ranking_analysis_{current_date}.json'
    with open(f'../data/processed/{efficiency_filename}', 'w', encoding='utf-8') as f:
        json.dump(efficiency_analysis_result, f, ensure_ascii=False, indent=2, default=str)
    print(f"âœ… æ•ˆç‡æ’ååˆ†æçµæœå·²å„²å­˜: {efficiency_filename}")
    
    # 4. å„²å­˜å¸‚å ´æ´å¯Ÿåˆ†æçµæœ
    insights_filename = f'market_insights_analysis_{current_date}.json'
    with open(f'../data/processed/{insights_filename}', 'w', encoding='utf-8') as f:
        json.dump(market_insights_result, f, ensure_ascii=False, indent=2, default=str)
    print(f"âœ… å¸‚å ´æ´å¯Ÿåˆ†æçµæœå·²å„²å­˜: {insights_filename}")
    
    # 5. å„²å­˜æ”¿ç­–å»ºè­°çµæœ
    policy_filename = f'policy_recommendations_{current_date}.json'
    with open(f'../data/processed/{policy_filename}', 'w', encoding='utf-8') as f:
        json.dump(policy_recommendations_result, f, ensure_ascii=False, indent=2, default=str)
    print(f"âœ… æ”¿ç­–å»ºè­°çµæœå·²å„²å­˜: {policy_filename}")
    
    # 6. å„²å­˜ç¶œåˆåˆ†æå ±å‘Š
    report_filename = f'comprehensive_analysis_report_{current_date}.json'
    with open(f'../data/processed/{report_filename}', 'w', encoding='utf-8') as f:
        json.dump(comprehensive_report, f, ensure_ascii=False, indent=2, default=str)
    print(f"âœ… ç¶œåˆåˆ†æå ±å‘Šå·²å„²å­˜: {report_filename}")
    
    # 7. å‰µå»ºåˆ†æç¸½çµæª”æ¡ˆ
    analysis_summary = {
        'generation_info': {
            'notebook': '10_specialized_analysis_visualization.ipynb',
            'version': 'v1.0',
            'generation_date': current_date,
            'generation_time': current_time,
            'total_runtime': 'ç´„45-60åˆ†é˜'
        },
        'analysis_modules': {
            'cancellation_trend_analysis': {
                'status': 'completed',
                'output_file': cancellation_filename,
                'key_insights': len(cancellation_analysis_result.get('insights', []))
            },
            'absorption_speed_analysis': {
                'status': 'completed',
                'output_file': absorption_filename,
                'market_health': absorption_analysis_result.get('predictive_insights', {}).get('market_health', 'N/A')
            },
            'efficiency_ranking_analysis': {
                'status': 'completed',
                'output_file': efficiency_filename,
                'top_performers': len(efficiency_analysis_result.get('multi_level_ranking', {}).get('city_ranking', []))
            },
            'market_insights': {
                'status': 'completed',
                'output_file': insights_filename,
                'health_score': market_insights_result.get('overall_assessment', {}).get('market_health_score', 0)
            },
            'policy_recommendations': {
                'status': 'completed',
                'output_file': policy_filename,
                'total_recommendations': sum([
                    len(policy_recommendations_result.get('regulatory_measures', [])),
                    len(policy_recommendations_result.get('market_supervision', [])),
                    len(policy_recommendations_result.get('risk_management', [])),
                    len(policy_recommendations_result.get('industry_development', []))
                ])
            }
        },
        'visualization_components': {
            'dashboard_created': len(dashboard_components),
            'interactive_charts': len([fig for fig in dashboard_components.values() if fig]),
            'analysis_depth': 'comprehensive'
        },
        'data_quality': {
            'input_sources': [
                'community_level_comprehensive_report',
                'district_level_comprehensive_report', 
                'city_level_comprehensive_report'
            ],
            'analysis_coverage': f"{len(community_report):,} å»ºæ¡ˆåˆ†æ",
            'geographic_coverage': f"{len(city_report)} ç¸£å¸‚, {len(district_report)} è¡Œæ”¿å€",
            'temporal_coverage': f"{len(community_report['å¹´å­£'].unique())} å¹´å­£"
        },
        'key_achievements': [
            'å®Œæˆè§£ç´„è¶¨å‹¢æ·±åº¦åˆ†æï¼Œè­˜åˆ¥é«˜é¢¨éšªæ¨¡å¼',
            'å»ºç«‹å»åŒ–é€Ÿåº¦è©•ä¼°é«”ç³»ï¼Œæä¾›æ•ˆç‡åˆ†ç´š',
            'é–‹ç™¼æ•ˆç‡æ’åç®—æ³•ï¼Œæ”¯æ´å¤šå±¤ç´šæ¯”è¼ƒ',
            'å‰µå»ºé¢¨éšªé è­¦è¦–è¦ºåŒ–ç³»çµ±',
            'ç”Ÿæˆå¸‚å ´æ´å¯Ÿèˆ‡æ”¿ç­–å»ºè­°',
            'æ§‹å»ºäº’å‹•å¼DashboardåŸå‹',
            'ç”¢å‡ºç¶œåˆåˆ†æå ±å‘Š'
        ],
        'output_files': [
            cancellation_filename,
            absorption_filename,
            efficiency_filename,
            insights_filename,
            policy_filename,
            report_filename
        ]
    }
    
    summary_filename = f'specialized_analysis_summary_{current_date}.json'
    with open(f'../data/processed/{summary_filename}', 'w', encoding='utf-8') as f:
        json.dump(analysis_summary, f, ensure_ascii=False, indent=2, default=str)
    print(f"âœ… åˆ†æç¸½çµå·²å„²å­˜: {summary_filename}")

except Exception as e:
    print(f"âŒ å„²å­˜éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")

print(f"\nâœ… æ‰€æœ‰å°ˆé …åˆ†æçµæœå·²æˆåŠŸå„²å­˜è‡³ ../data/processed/")

# %%
# æœ€çµ‚ç¸½çµ
print("\n" + "="*80)
print("ğŸ“‹ Notebook 10 - è§£ç´„èˆ‡å»åŒ–å‹•æ…‹å°ˆé …åˆ†æè¦–è¦ºåŒ– ç¸½çµ")
print("="*80)

print("1ï¸âƒ£ å°ˆé …åˆ†ææ¨¡çµ„å®Œæˆåº¦:")
analysis_modules_status = [
    ("âœ… è§£ç´„è¶¨å‹¢å°ˆé …åˆ†æ", "å®Œæˆæ™‚é–“åºåˆ—åˆ†æã€é¢¨éšªè©•ä¼°ã€ç©ºé–“åˆ†å¸ƒåˆ†æ"),
    ("âœ… å»åŒ–é€Ÿåº¦å°ˆé …åˆ†æ", "å®Œæˆé€Ÿåº¦åˆ†å¸ƒã€æ•ˆç‡è©•ç´šã€ç¾¤é›†åˆ†æã€é æ¸¬æ´å¯Ÿ"),
    ("âœ… æ•ˆç‡æ’åå°ˆé …åˆ†æ", "å®Œæˆå¤šå±¤ç´šæ’åã€åŸºæº–åˆ†æã€ç«¶çˆ­åˆ†æã€æ”¹å–„æ©Ÿæœƒè­˜åˆ¥"),
    ("âœ… é¢¨éšªé è­¦è¦–è¦ºåŒ–", "å®Œæˆç¶œåˆDashboardã€é¢¨éšªç›£æ§é¢æ¿ã€é è­¦ç³»çµ±"),
    ("âœ… ç†±é»å€åŸŸåˆ†æè¦–è¦ºåŒ–", "å®Œæˆè¡¨ç¾æ’åã€æ•ˆç‡åˆ†å¸ƒã€ç«¶çˆ­åŠ›åˆ†æ"),
    ("âœ… ä¸‰å±¤ç´šå°æ¯”åˆ†æ", "å®Œæˆç¤¾å€-è¡Œæ”¿å€-ç¸£å¸‚ä¸‰å±¤ç´šæŒ‡æ¨™å°æ¯”"),
    ("âœ… å¸‚å ´æ´å¯Ÿåˆ†æ", "å®Œæˆæ•´é«”è©•ä¼°ã€é—œéµç™¼ç¾ã€é¢¨éšªé è­¦ã€æ©Ÿæœƒè­˜åˆ¥"),
    ("âœ… æ”¿ç­–å»ºè­°ç”Ÿæˆ", "å®Œæˆç›£ç®¡æªæ–½ã€å¸‚å ´ç›£ç£ã€é¢¨éšªç®¡ç†ã€ç”¢æ¥­ç™¼å±•å»ºè­°"),
    ("âœ… äº’å‹•å¼DashboardåŸå‹", "å®ŒæˆKPIæŒ‡æ¨™æ¿ã€é¢¨éšªç›£æ§ã€å¸‚å ´è¡¨ç¾é¢æ¿"),
    ("âœ… ç¶œåˆåˆ†æå ±å‘Š", "å®ŒæˆåŸ·è¡Œæ‘˜è¦ã€è©³ç´°åˆ†æã€æ´å¯Ÿå»ºè­°æ•´åˆ")
]

for module, description in analysis_modules_status:
    print(f"   {module}")
    print(f"     {description}")

print(f"\n2ï¸âƒ£ æ ¸å¿ƒæˆæœèˆ‡ç™¼ç¾:")
key_achievements = [
    f"âœ… è§£ç´„é¢¨éšªæ§åˆ¶: æ•´é«”è§£ç´„ç‡{market_insights_result.get('overall_assessment', {}).get('avg_cancellation_rate', 0):.2f}%ï¼Œé¢¨éšªç­‰ç´š{cancellation_analysis_result.get('risk_assessment', {}).get('overall_risk_level', 'N/A')}",
    f"âœ… å»åŒ–è¡¨ç¾è©•ä¼°: å¹³å‡å»åŒ–ç‡{market_insights_result.get('overall_assessment', {}).get('avg_absorption_rate', 0):.1f}%ï¼Œå¸‚å ´å¥åº·åº¦{market_insights_result.get('overall_assessment', {}).get('market_health_score', 0)}/100",
    f"âœ… æ•ˆç‡æ’åé«”ç³»: å®Œæˆ{len(city_report)}å€‹ç¸£å¸‚ã€{len(district_report)}å€‹è¡Œæ”¿å€æ•ˆç‡æ’å",
    f"âœ… é¢¨éšªé è­¦æ©Ÿåˆ¶: è­˜åˆ¥{len([w for w in market_insights_result.get('risk_warnings', []) if w])}é …é¢¨éšªé è­¦",
    f"âœ… å¸‚å ´æ©Ÿæœƒè­˜åˆ¥: ç™¼ç¾{len(market_insights_result.get('opportunities', []))}é …å¸‚å ´æ©Ÿæœƒ",
    f"âœ… æ”¿ç­–å»ºè­°åˆ¶å®š: ç”¢å‡º{sum([len(policy_recommendations_result.get(key, [])) for key in ['regulatory_measures', 'market_supervision', 'risk_management', 'industry_development']])}é …æ”¿ç­–å»ºè­°"
]

for achievement in key_achievements:
    print(f"   {achievement}")

print(f"\n3ï¸âƒ£ è¦–è¦ºåŒ–æˆæœ:")
visualization_achievements = [
    f"âœ… é¢¨éšªé è­¦Dashboard: 9å€‹è¦–è¦ºåŒ–çµ„ä»¶ï¼Œæ¶µè“‹é¢¨éšªåˆ†å¸ƒã€è¶¨å‹¢ã€é è­¦ç‡ˆè™Ÿ",
    f"âœ… ç†±é»å€åŸŸåˆ†æ: 6å€‹åˆ†æé¢æ¿ï¼Œå±•ç¤ºè¡¨ç¾æ’åã€æ•ˆç‡åˆ†å¸ƒã€ç«¶çˆ­åŠ›",
    f"âœ… ä¸‰å±¤ç´šå°æ¯”: 6å€‹å°æ¯”åœ–è¡¨ï¼Œå‘ˆç¾ç¤¾å€-è¡Œæ”¿å€-ç¸£å¸‚æŒ‡æ¨™å·®ç•°",
    f"âœ… äº’å‹•å¼åŸå‹: {len(dashboard_components)}å€‹Dashboardçµ„ä»¶ï¼Œæ”¯æ´å³æ™‚ç›£æ§",
    f"âœ… ç¶œåˆåœ–è¡¨: 20+å€‹å°ˆæ¥­åœ–è¡¨ï¼Œæ¶µè“‹å„å°ˆé …åˆ†æçµæœ"
]

for viz_achievement in visualization_achievements:
    print(f"   {viz_achievement}")

print(f"\n4ï¸âƒ£ æŠ€è¡“å‰µæ–°é»:")
technical_innovations = [
    "âœ… å¤šç¶­åº¦èšé¡åˆ†æ: K-meansç®—æ³•è­˜åˆ¥å»ºæ¡ˆè¡¨ç¾ç¾¤é›†",
    "âœ… æ™‚é–“åºåˆ—åˆ†æ: å‹•æ…‹è¿½è¹¤è§£ç´„èˆ‡å»åŒ–è¶¨å‹¢è®ŠåŒ–",
    "âœ… ä¸‰å±¤ç´šä¸€è‡´æ€§: å»ºç«‹ç¤¾å€-è¡Œæ”¿å€-ç¸£å¸‚æ•¸æ“šè¯ç¹«é©—è­‰",
    "âœ… é¢¨éšªé‡åŒ–æ¨¡å‹: å»ºç«‹è§£ç´„èˆ‡å»åŒ–é¢¨éšªè©•åˆ†æ©Ÿåˆ¶",
    "âœ… äº’å‹•å¼è¦–è¦ºåŒ–: Plotly Dashboardæ”¯æ´å³æ™‚åˆ†æ",
    "âœ… é æ¸¬æ¨¡å‹åŸå‹: åŸºæ–¼æ­·å²è¶¨å‹¢çš„å¸‚å ´å±•æœ›ç®—æ³•"
]

for innovation in technical_innovations:
    print(f"   {innovation}")

print(f"\n5ï¸âƒ£ å¸‚å ´æ´å¯Ÿç²¾è¯:")
if 'key_findings' in market_insights_result:
    market_findings = market_insights_result['key_findings'][:4]
    for i, finding in enumerate(market_findings, 1):
        print(f"   ğŸ’¡ {i}. {finding}")

print(f"\n6ï¸âƒ£ é‡è¦é¢¨éšªé è­¦:")
if 'risk_warnings' in market_insights_result:
    risk_warnings = market_insights_result['risk_warnings'][:3]
    for i, warning in enumerate(risk_warnings, 1):
        print(f"   ğŸš¨ {i}. {warning}")

print(f"\n7ï¸âƒ£ æ”¿ç­–å»ºè­°ç²¾è¦:")
policy_summary = [
    "ğŸ›ï¸ ç›£ç®¡æªæ–½: å»ºç«‹è§£ç´„ç‡ç›£æ§ã€è²¡å‹™å¯©æŸ¥ã€æ¨™æº–åŒ–å¥‘ç´„",
    "ğŸ‘ï¸ å¸‚å ´ç›£ç£: è³‡è¨Šå…¬é–‹å¹³å°ã€è·¨éƒ¨é–€è¯åˆã€æ•¸æ“šé©…å‹•ç›£ç£", 
    "ğŸ›¡ï¸ é¢¨éšªç®¡ç†: ç³»çµ±æ€§é¢¨éšªç›£æ¸¬ã€æ¶ˆè²»è€…ä¿è­·ã€é‡‘èé¢¨éšªæ§åˆ¶",
    "ğŸš€ ç”¢æ¥­ç™¼å±•: ç”¢æ¥­çµæ§‹å„ªåŒ–ã€å‰µæ–°æ©Ÿåˆ¶æ¨å‹•ã€å¸‚å ´ç’°å¢ƒæ”¹å–„"
]

for policy in policy_summary:
    print(f"   {policy}")

print(f"\n8ï¸âƒ£ å¾ŒçºŒç™¼å±•æ–¹å‘:")
future_developments = [
    "ğŸ”® æ©Ÿå™¨å­¸ç¿’æ¨¡å‹: æ•´åˆæ›´å¤šè®Šæ•¸çš„å»åŒ–é æ¸¬æ¨¡å‹",
    "ğŸ“± å³æ™‚ç›£æ§ç³»çµ±: é–‹ç™¼å¯¦æ™‚Dashboardèˆ‡é è­¦é€šçŸ¥",
    "ğŸ—ºï¸ åœ°ç†è³‡è¨Šç³»çµ±: æ•´åˆGISçš„ç©ºé–“åˆ†æåŠŸèƒ½",
    "ğŸ¤– è‡ªå‹•åŒ–å ±å‘Š: å»ºç«‹å®šæœŸè‡ªå‹•ç”Ÿæˆåˆ†æå ±å‘Šæ©Ÿåˆ¶",
    "ğŸŒ APIæœå‹™: é–‹ç™¼æ•¸æ“šæŸ¥è©¢èˆ‡åˆ†æAPIæ¥å£",
    "ğŸ“Š æ“´å±•åˆ†æ: ç´å…¥æ–°æˆå±‹ã€æˆå±‹å¸‚å ´åˆ†æ"
]

for development in future_developments:
    print(f"   {development}")

print(f"\n9ï¸âƒ£ è¼¸å‡ºæª”æ¡ˆæ¸…å–®:")
output_files = [
    "cancellation_trend_analysis_YYYYMMDD.json (è§£ç´„è¶¨å‹¢åˆ†æ)",
    "absorption_speed_analysis_YYYYMMDD.json (å»åŒ–é€Ÿåº¦åˆ†æ)",
    "efficiency_ranking_analysis_YYYYMMDD.json (æ•ˆç‡æ’ååˆ†æ)",
    "market_insights_analysis_YYYYMMDD.json (å¸‚å ´æ´å¯Ÿåˆ†æ)",
    "policy_recommendations_YYYYMMDD.json (æ”¿ç­–å»ºè­°)",
    "comprehensive_analysis_report_YYYYMMDD.json (ç¶œåˆåˆ†æå ±å‘Š)",
    "specialized_analysis_summary_YYYYMMDD.json (åˆ†æç¸½çµ)"
]

for output_file in output_files:
    print(f"   ğŸ“„ {output_file}")

print(f"\nğŸ”Ÿ å“è³ªæ§åˆ¶çµæœ:")
quality_metrics = [
    f"âœ… è³‡æ–™å®Œæ•´æ€§: åˆ†æ{len(community_report):,}å€‹å»ºæ¡ˆï¼Œè¦†è“‹{len(city_report)}å€‹ç¸£å¸‚",
    f"âœ… è¨ˆç®—æº–ç¢ºæ€§: ä¸‰å±¤ç´šèšåˆé‚è¼¯é©—è­‰é€šé",
    f"âœ… è¦–è¦ºåŒ–å“è³ª: {len(dashboard_components)}å€‹Dashboardçµ„ä»¶æ­£å¸¸é‹ä½œ",
    f"âœ… åˆ†ææ·±åº¦: 5å¤§å°ˆé …åˆ†ææ¨¡çµ„å…¨éƒ¨å®Œæˆ",
    f"âœ… æ´å¯Ÿå“è³ª: ç”Ÿæˆ{len(market_insights_result.get('recommendations', []))}é …å¸‚å ´å»ºè­°",
    f"âœ… æ”¿ç­–åƒ¹å€¼: åˆ¶å®š{len(policy_recommendations_result.get('implementation_roadmap', {}))}éšæ®µå¯¦æ–½è·¯ç·šåœ–"
]

for metric in quality_metrics:
    print(f"   {metric}")

print("\n" + "="*80)
print("ğŸ‰ Notebook 10 - è§£ç´„èˆ‡å»åŒ–å‹•æ…‹å°ˆé …åˆ†æè¦–è¦ºåŒ– å®Œæˆï¼")
print("ğŸ“Š å·²å»ºç«‹å®Œæ•´çš„å°ˆé …åˆ†æé«”ç³»ï¼Œæ¶µè“‹è§£ç´„ã€å»åŒ–ã€æ•ˆç‡ã€é¢¨éšªå››å¤§é¢å‘")
print("ğŸ¯ å¯¦ç¾å¾æ•¸æ“šåˆ†æåˆ°è¦–è¦ºåŒ–å±•ç¤ºã€å¾å¸‚å ´æ´å¯Ÿåˆ°æ”¿ç­–å»ºè­°çš„å®Œæ•´é–‰ç’°")
print("ğŸš€ ç‚ºé å”®å±‹å¸‚å ´é¢¨éšªåˆ†æç³»çµ±æä¾›äº†å¼·å¤§çš„å°ˆé …åˆ†æèˆ‡æ±ºç­–æ”¯æ´èƒ½åŠ›")
print("="*80)